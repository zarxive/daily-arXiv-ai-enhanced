<div id=toc></div>

# Table of Contents

- [physics.optics](#physics.optics) [Total: 9]
- [gr-qc](#gr-qc) [Total: 19]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 6]
- [physics.app-ph](#physics.app-ph) [Total: 4]
- [quant-ph](#quant-ph) [Total: 40]
- [physics.chem-ph](#physics.chem-ph) [Total: 5]
- [nlin.CD](#nlin.CD) [Total: 2]
- [cond-mat.quant-gas](#cond-mat.quant-gas) [Total: 4]
- [cond-mat.mes-hall](#cond-mat.mes-hall) [Total: 11]
- [physics.bio-ph](#physics.bio-ph) [Total: 1]
- [hep-th](#hep-th) [Total: 11]
- [physics.atom-ph](#physics.atom-ph) [Total: 3]


<div id='physics.optics'></div>

# physics.optics [[Back]](#toc)

### [1] [The Surface Orientation Ambiguity for Single Molecules at Dielectric Interfaces](https://arxiv.org/abs/2508.03903)
*E. Dey,M. Elorza,F. W. Foss,J. J. Gomez Cadenas,B. J. P. Jones*

Main category: physics.optics

TL;DR: 文章探讨了通过非聚焦显微镜测量荧光分子取向的挑战。研究表明，当荧光分子靠近电介性界面时，测量存在误差，测得的取向倾向于向界面旋转。文章指出这是由于常见计算中的假设导致的，并提出了利用有限元建模的解决方案。


<details>
  <summary>Details</summary>
Motivation: 该文章结合了物理学和应用化学的领域，重点探讨了荧光分子取向的测量难题及其解决方案，具有重要的理论和应用价值。

Method: 文章的方法包括理论建模和有限元建模，验证了测量中的缺陷并提出了修正方案。

Result: 有限元建模帮助识别并修正了测量误差，确保取向测量的准确性。

Conclusion: 文章提出了精确测量方法，可应用于生物医学等领域的显微尺度取向研究。

Abstract: Fluorescent molecules emit light in a dipole radiation pattern that can be
used to infer their orientation through defocused fluorescence microscopy.
Proper measurement of the orientation requires mathematical modeling of the
radiation pattern expected for a dipole in the geometry of interest, and
subsequent comparison against experimental data. We point out an ambiguity in
common calculations of these patterns that appears to compromise orientation
measurements for molecules that are especially near to dielectric surfaces.
This results in a rotation of the measured emission dipole toward the surface
for near-interface molecules, which can be mistaken for a preferentially
horizontal orientation among the emitters. The proper treatment for on-surface
emitters requires consideration of finite-sized current elements between two
dielectric media, and we show that the theoretical ambiguity can be lifted via
finite-element modeling. A prescription is provided for correcting measured
orientations at arbitrary interfaces.

</details>


### [2] [Holovibes: real-time ultrahigh-speed digital hologram rendering and short-time analysis](https://arxiv.org/abs/2508.03911)
*Marius Dubosc,Maxime Boy-Arnould,Jules Guillou,Titouan Gragnic,Arthur Courselle,Gustave Hervé,Alexis Pinson,Etienne Senigout,Bastien Gaulier,Simon Riou,Chloé Magnier,Noé Topeza,Oscar Morand,Thomas Xu,Samuel Goncalves,Edgar Delaporte,Adrien Langou,Paul Duhot,Julien Nicolle,Sacha Bellier,David Chemaly,Damien Didier,Philippe Bernet,Eliott Bouhana,Fabien Colmagro,Guillaume Poisson,Anthony Strazzella,Ilan Guenet,Nicolas Blin,Quentin Kaci,Theo Lepage,Loïc Bellonnet-Mottet,Antoine Martin,François Te,Ellena Davoine,Clement Fang,Danae Marmai,Hugo Verjus,Eloi Charpentier,Julien Gautier,Florian Lapeyre,Thomas Jarrossay,Alexandre Bartz,Cyril Cêtre,Clement Ledant,Eric Delanghe,Arnaud Gaillard,Geoffrey Le Gourrierec,Jeffrey Bencteux,Thomas Kostas,Pierre Pagnoux,Antoine Dillée,Romain Cancillière,Michael Atlan*

Main category: physics.optics

TL;DR:  paper introduces Holovibes for real-time ultra-high-speed digital hologram rendering using GPU acceleration and efficient data handling, achieving low latency and high throughput suitable for demanding applications.


<details>
  <summary>Details</summary>
Motivation:  researchers and professionals in computational imaging need real-time holographic image reconstruction and processing for applications like microscopy, security, and medical imaging. The demand for high-throughput processing with minimal latency is growing.

Method:  Holovibes combines spatial demodulation techniques like Fresnel transforms and angular spectrum propagation with temporal methods such as STFT and PCA. It uses CUDA-based GPU acceleration, multithreaded parallelism, and efficient buffering to achieve high performance.

Result:  System processes 256x256 pixels at 71,400 frames per second with 30 ms latency, suitable for streaming data without loss in commodity hardware. It supports real-time hologram rendering and simultaneous data recording essential for experimental setups.

Conclusion:  Holovibes provides an unbiased solution for high-performance computational imaging with real-time capabilities, surpassing prior systems and enabling new experimental possibilities.

Abstract: Real-time ultrahigh-speed rendering of digital holograms from high-bitrate
interferogram streams demands robust parallel computing and efficient data
handling with minimal latency. We present Holovibes, a high-performance
software engine that enables real-time holographic image reconstruction and
short-time analysis at unprecedented throughput. Holovibes integrates spatial
demodulation techniques, such as Fresnel transformations and angular spectrum
propagation, with temporal analysis methods including short-time Fourier
transform (STFT) and principal component analysis (PCA) in a unified pipeline.
By leveraging CUDA-based GPU acceleration, multithreaded parallelism, and
efficient buffering, the system achieves high-throughput, low-latency
processing suitable for demanding computational imaging applications. We
demonstrate sustained real-time hologram rendering of 256x256-pixel from
interferograms acquired by a streaming camera at 71,400 frames per second on
commodity hardware with no frame loss, while maintaining an end-to-end latency
of 30 ms. The engine also supports simultaneous recording of raw or processed
data, enabling high-speed acquisition workflows essential for experimental
applications. This work represents a significant advance over prior digital
holography systems and provides a versatile platform for ultra-high-speed,
real-time computational imaging.

</details>


### [3] [Optical absorption of a Cu$_2$SnS$_3$ (CTS) layer trapped by metallic thin films in multilayer configuration](https://arxiv.org/abs/2508.04113)
*Le Tri Dat,Nguyen Duy Vy*

Main category: physics.optics

TL;DR: The paper discusses optimizing thin film layers for energy harvesting by analyzing their absorption via Maxwell's equations and finding that certain materials at specific thicknesses can significantly enhance absorption.


<details>
  <summary>Details</summary>
Motivation: The authors likely want to improve energy harvesting efficiency, which is crucial for sustainable technologies.

Method: They used Maxwell's equations to model absorbing thin films and found optimal material and thickness combinations.

Result: Materials like Au, Ag, Cu, Al at specific thicknesses can boost absorption up to 60%.

Conclusion: Optimal thin film layers enhance energy harvesting systems through precise material and thickness selection.

Abstract: Coating and reflecting thin films for energy harvesting purposes are
interesting topics in both theoretical and experimental research. The thin film
could help to enhance the absorption of the system via its specific optical
properties depending on the optical wavelength and the stacked layer thickness.
Here, by using Maxwell's equations for the electromagnetic fields penetrating
thin films, we examined in detail the absorption of a CTS layer coated by
nanometer-thick thin films of several materials, Au, Ag, Cu, Al, and figured
out the optimal thickness range for the outer layers of the solar cell to
optimize thermal energy harvesting from the light. In particular, the
absorption has been shown to be significantly enhanced thanks to the optical
cavity effect, and the maximal absorption of the system could reach 60\% for
... These results could help in suitably choosing the detailed thickness for
the structure of the solar cell and other energy harvesting objects.

</details>


### [4] [High-Sensitivity Photonic Crystal Biosensors using Topological Light Trapping](https://arxiv.org/abs/2508.04321)
*Zhengzheng Zhai,Sajeev John*

Main category: physics.optics

TL;DR: Photonic crystal biosensors with domain-wall defects exhibit significantly enhanced sensitivity through optimized structural design. Using numerical simulations of Maxwell's equations, they achieve over 8000 nm/RIU sensitivity for detecting both analyte layers and background fluids.


<details>
  <summary>Details</summary>
Motivation: Analyzing the use of photonic crystals with topological defects in biosensing devices, this study explores how defect-induced optical modes can enhance detection sensitivity through structural modifications that promote optical tunneling and mode hybridizations.

Method: The study employs numerical solutions of Maxwell's equations to simulate photonic crystals with square lattices and domain-wall defects. It incorporates a biofluid channel structure with silica walls and evaluates the impact of replacing silicon blocks with thin strips in the domain walls to enhance sensitivity. The analysis includes the study of optical mode hybridization between adjacent defects and its effect on transmission, frequency shifts, and overall biosensing performance.

Result: The designed biosensors demonstrate high sensitivity, with a unique ability to distinguish three analyte bindings and their combinations in a single spectroscopic measurement. The bulk sensitivity for thin analyte layers is near 3000 nm/RIU, and for overall background fluids, it surpasses 8000 nm/RIU. Additionally, the structure exhibits characteristics of photonic band gaps, defect-mediated tunneling, and effective optical mode coupling, showing superiority in sensitivity compared to previous designs.

Conclusion: The research provides a sustainable approach to enhancing biosensor sensitivity through optimized photonic crystal structures and defect-mediated optical effects. It paves the way for more efficient and accurate photonic biosensors with potential applications in healthcare and environmental monitoring.

Abstract: Photonic crystals (PCs) with localized optical cavity modes arising from
topological domain-wall line defects are simulated for optical biosensing by
numerical solution of Maxwell's equations. These consist of a square lattice of
square silicon blocks with a significant photonic band gap (PBG). Optical
transmission through the PBG at specific frequencies occurs by defect-mediated
optical tunneling. Biofluid flows perpendicular to light propagation, through a
channel containing the PC, defined by silica side-walls and an underlying
silica substrate. Replacing the silicon blocks with thin silicon strips
throughout the domain-wall region, analyte binding coincides with regions of
maximal field intensity. As a result, the sensitivity is improved by almost 16
times higher than the previous designs. We analyze optical mode hybridization
of two nearby domain walls and its close relation to the transmission-levels
and correlations in frequency shifts of nearby optical resonances in response
to analyte-bindings. We illustrate three high-sensitivity chips each with three
domain-wall defects, all of which can distinguish three analyte-bindings and
their combinations completely in a single spectroscopic measurement. In a
photonic crystal, consisting of silicon squares embedded in a water background
and a 5-micron lattice spacing, the biosensor sensitivity to a thin analyte
binding layer is nearly 3000 nm/RIU, and to the overall background biofluid is
over 8000 nm/RIU.

</details>


### [5] [Tight-binding photonics](https://arxiv.org/abs/2508.04465)
*Jing Li,Aodong Li,Yutao Chen,Tao Xiao,Renwen Huang,Xiaolu Zhuo,Jun Guan,Zhen Gao,Peng Zhan,Minghui Lu,Biye Xie*

Main category: physics.optics

TL;DR: This paper reviews the application of tight-binding models in photonics, comparing it to numerical methods like finite-element, and highlights its potential for future designs.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of simulating photon behavior in complex media, proposing tight-binding as a more efficient alternative to traditional numerical methods.

Method: The authors use tight-binding theory to model photonic crystals, mapping Maxwell equations to solvable matrix Hamiltonians, and review both experimental results and theoretical aspects.

Result: The tight-binding approach shows promise, offering an efficient computational method and insights into photonic device designs.

Conclusion: The review emphasizes the potential of tight-binding models in advancing photonic technology research and development.

Abstract: Photonics, dealing with the generation, manipulation, and detection of
photons in various systems, lays the foundation of many advanced technologies.
A key task of photonics is to know how photons propagate in complex media such
as periodic and aperiodic photonic crystals. The conventional wisdom is to
numerically solve the Maxwell equations either by dedicated numerical
techniques or brute-force finite-element calculations. Recently, the strict
analogy between photonic crystals and theoretical tight-binding models provides
an unprecedentedly convenient wayof understanding the spectra and wavefunctions
of photonic systems by mapping the complicated differential equationsinto
matrixed Hamiltonians that can be easily solved through the band theory and
exact diagonalization. in this paper, we present a timely review of
tight-binding-like photonics in various platforms, covering fundamental
theories, experimental realizations, unique physical efiects, and their
potential applications. We also provide a brief outlook on the future trends of
this active area. Our review offers an in-depth and comprehensive picture on
this rapidly developing field and may shed light on the future design on
advanced tight-binding-like photonic devices.

</details>


### [6] [Laser Driven Bulk-to-Layered Phase Transition](https://arxiv.org/abs/2508.04544)
*Shuang Liu,Oren Cohen,Ofer Neufeld,Peng Chen*

Main category: physics.optics

TL;DR: 研究通过强激光产生光致变质，将三维晶体转化为二维材料。实验显示通过极化光激发导致特定键断裂，实现了可控的材料转变，启发了光辅助设备和二维材料转换方法。


<details>
  <summary>Details</summary>
Motivation: 探索光激发下的新型相变机制，为材料科学和 '_',

Method: 利用第一性原理模拟分析光激发诱导的键断裂机制，特别考察极化光在ACE中的作用。

Result: 三维晶体通过光致变质变为二维材料，揭示了极化光在键断裂中的关键作用机制。

Conclusion: 实验证实用光可控制材料相变，推荐使用ACE进行相关研究。

Abstract: Laser-induced phase transitions offer pathways of phase transitions that are
inaccessible by conventional stimuli. In this study, we conduct ab initio
simulations to numerically demonstrate a novel laser-induced structural
transformation: converting a bulk crystal into a layered van der Waals material
using intense light pulses. The transition is driven by a nonlinear phononic
mechanism, where selectively exciting polar and anti-polar phonon modes with
polarized terahertz light breaks targeted interlayer bonds while preserving
intralayer ones. We identify that strong anisotropy in bond sensitivity where
interlayer bonds are significantly more susceptible to excitation than
intralayer bonds is the critical prerequisite. Our findings pave the way for on
demand transformations from bulk to 2D materials, facilitate the design of
advanced phase-change devices, and suggest a potential optical exfoliation
method to expand the range of exfoliable 2D materials.

</details>


### [7] [Electrical control of quantum dots in GaAs-on-insulator waveguides for coherent single-photon generation](https://arxiv.org/abs/2508.04584)
*Hanna Salamon,Ying Wang,Arnulf Snedker-Nielsen,Atefeh Shadmani,Rüdiger Schott,Mircea Balauroiu,Nicolas Volet,Arne Ludwig,Leonardo Midolo*

Main category: physics.optics

TL;DR: The paper discusses integrating coherent quantum emitters with silicon photonic platforms, demonstrating a method for creating electrically controlled quantum dots with excellent performance.


<details>
  <summary>Details</summary>
Motivation: The development of scalable quantum technologies is a key goal in quantum computing and photonics, so integrating different quantum systems is crucial.

Method: The study uses electrically controlled self-assembled quantum dots in GaAs waveguides, bonded with a die-to-die adhesive, and bonded to SiO2/Si substrates with p-i-n junctions for improved performance.

Result: The quantum dots exhibit narrow optical linewidths and high single-photon purity, similar to unprocessed GaAs devices.

Conclusion: This approach paves the way for scalable quantum photonic integrated circuits using existing silicon technology.

Abstract: The integration of coherent quantum emitters with silicon photonic platforms
essential for scalable quantum technologies. We demonstrate electrically
controlled self-assembled quantum dots embedded in GaAs waveguides bonded onto
a SiO2/Si substrate and coupled to low-loss SiN waveguides. Our approach uses a
die-to-die adhesive bonding process to realize a GaAs-on-insulator platform
incorporating a p-i-n junction for charge noise suppression and Stark tuning of
excitonic transitions. Resonance fluorescence measurements reveal narrow
optical linewidths below 2 {\mu}eV and high single-photon purity, matching the
performance of unprocessed GaAs devices. These results establish a practical
route to integrate high-coherence quantum light sources with mature silicon
photonics, enabling scalable quantum photonic integrated circuits

</details>


### [8] [Enhancing the Propagation Length of Graphene Surface Plasmon Polaritons using a Metamaterial Substrate with a Near-Zero Refractive Index](https://arxiv.org/abs/2508.04601)
*Zoya Eremenko,Igor Volovichev*

Main category: physics.optics

TL;DR: 该论文通过在所有电介质元结构上叠加石墨烯，研究了如何控制和增强石墨烯表面色散偏振光（SPP）的传播长度。利用波分本人工晶体框架和COMSOL Multiphysics 6.2模拟了光子晶体的共振模式，发现当电偶变数处于零有效折射率（NZERI）区间的Γ点时，就会出现三元退化本征模式，这意味着在这个频段内，石墨烯表面元结构的传播距离可以显著增加。该论文的贡献是首次在所有电介质元结构上作为支撑平台实现SPP增强，提供了一种平衡传播距离和场 confinement 的定量方法，并给出了适用于现代纳米制造的实用设计指引。


<details>
  <summary>Details</summary>
Motivation: 研究石墨烯表面色散偏振光（SPP）的传播特性在不同条件下的变化，尤其是在所有电介质元结构上的实现，具有重要的理论意义和潜在的实验应用价值。

Method: 采用了波分本人工晶体框架，结合COMSOL Multiphysics 6.2进行数值模拟，研究了当all-dielectric metasurface处于零有效折射率（NZERI）区间时，SPP传播长度的控制、增强和调整。

Result: 研究发现，在NZERI条件下，石墨烯表面元结构的传播距离能够显著增加，同时保持场的confine。

Conclusion: 该论文通过在所有电介质元结构上叠加石墨烯，成功实现了控制和增强石墨烯表面色散偏振光的传播长度，在有益的理论基础和实践指导方面都具有重要意义。

Abstract: This paper aims to investigate the conditions necessary to control, enhance,
and modify the propagation length of graphene surface plasmon polaritons (SPPs)
at room temperature, using an all-dielectric metamaterial substrate in
comparison to suspended graphene. The analysis is conducted within a photonic
crystal framework using COMSOL Multiphysics 6.2 to study the resonant modes of
the all-dielectric metamaterial. Our results confirm the existence of an
near-zero effective refractive index (NZERI) regime at the
$\Gamma\text{-point}$ point in the photonic crystal approach. At this NZERI
regime a consequence of triply degenerate eigenmodes in a certain frequency
range occurs when the effective refractive index of the metasurface approaches
zero. Our central idea is that the NZERI regime in the all-dielectric
metasurface of a graphene substrate can be used to control, enhance, and modify
the propagation of SPPs. We applied several independent theoretical methods to
obtain the effective refractive index of the metasurface at NZERI frequency
range for two-dimensional and three-dimensional metasurface structures with a
graphene layer. Simulation results demonstrate that the effective permittivity
and permeability simultaneously attain near-zero values at closely spaced yet
distinct frequencies, thereby establishing spectral regions with an effectively
vanishing refractive index. Key contributions include the first demonstration
of NZERI metasurfaces as graphene-supporting platforms for enhancing SPPs, a
quantitative approach to balancing propagation distance and field confinement,
and practical design guidelines that align with current nanofabrication
capabilities. Our simulations further demonstrate that when graphene is placed
on (or between two) all-dielectric metasurfaces operating in the NZERI regime,
the SPP propagation length can be significantly increased.

</details>


### [9] [Broadband Dipole Absorption in Dispersive Photonic Time Crystals](https://arxiv.org/abs/2508.04619)
*Thomas F. Allard,Jaime E. Sustaeta-Osuna,Francisco J. García-Vidal,Paloma A. Huidobro*

Main category: physics.optics

TL;DR: 研究了光子时间晶格中点偶极子的退化情况，展示了通过时调制可以在较宽频段内将辐射转化为吸收，且无需异常点，同时示了两种极端：抑制和增强。


<details>
  <summary>Details</summary>
Motivation: 该研究探索了光子时间晶格中的动态行为，试图通过时调制解决系统在色散和吸收下的复杂问题，为光子学和量子计算等应用提供新思路。

Method: 通过分析点偶极子在光子时间晶格中的辐射吸收特性，结合对系统模态的理论推导和数值模拟，ciphered通过时调制的频率变化来实现对能量的调控。

Result: 发现虽然系统在某些模态下存在异常点，但通过调制可以有效避免这些点，实现稳定的工作状态，同时在适当条件下，可以显著增强或抑制能量消散。

Conclusion: 光子时间晶格为能量调控提供了新途径，调制可有效避免异常点，实现广域频率的动态调节，具有潜在的应用前景。

Abstract: Photonic media modulated periodically in time, termed photonic time crystals
(PTCs), have attracted considerable attention for their ability to open
momentum bandgaps hosting amplifying modes. These momentum gaps, however,
generally appear only at the system's parametric resonance condition which
constrain many features derived from amplification to a narrow frequency band.
Moreover, they are accompanied by exceptional points (EPs) that render their
analysis more intricate. Here, we show that a careful consideration of
dispersion and absorption can overcome these issues. By investigating the
dissipated power of a point-dipole embedded in a dispersive and absorptive PTC,
we unveil that temporal modulation enables the conversion of dipole emission
into dipole absorption within a broadband frequency window free of EPs. We
demonstrate that this effect is general and occurs from weak modulation
strengths to low modulation frequencies, and can be achieved for various
material platforms. Moreover, we show the possibility of both broadband
inhibition and large increase of dissipated power, depending on the modulated
parameter.

</details>


<div id='gr-qc'></div>

# gr-qc [[Back]](#toc)

### [10] [Dynamical dark energy parameterizations in VCDM](https://arxiv.org/abs/2508.03784)
*Simran Arora,Antonio De Felice,Shinji Mukohyama*

Main category: gr-qc

TL;DR: The paper discusses a cosmological model called VCDM that unifies dark energy with gravity modifications, showing that it is both theoretically sound and compatible with current observations. They test various parameterizations against recent datasets and discuss their implications.


<details>
  <summary>Details</summary>
Motivation: The research seems to aim for a deeper understanding of how modified gravity can explain dark energy. It's likely relevant to ongoing quests to unify gravity and dark energy theories, which are important in modern cosmology.

Method: They use the VCDM theory to substitute different dark energy parameterizations (CPL, BA, JBP, EXP, LOG) and apply them to recent datasets like Planck 2018 and DESI BAO DR2 for statistical analysis.

Result: The findings likely reveal which parameterizations fit the data best, supporting some models over others while maintaining VCDM's consistency. The results could help distinguish viable dark energy models and refine our understanding of gravity's role in the universe.

Conclusion: VCDM successfully incorporates various dark energy models, offering future testability and aligning with observations. This provides a promising framework for further theoretical and experimental exploration of dark energy and gravity modifications.

Abstract: In the context of a theory of minimally modified gravity called VCDM, one can
realize any cosmological behavior at the level of the homogeneous and isotropic
background without introducing fatal instabilities for perturbations.
Therefore, VCDM provides a theoretically-consistent and
observationally-testable framework of dynamical dark energy parameterizations
with or without phantom behaviors. In this paper, we propose the VCDM
realizations of various phenomenological parameterizations present in the
literature: the Chevallier-Polarski-Linder (CPL), Barboza-Alcaniz (BA),
Jassal-Bagla-Padmanabhan (JBP), Exponential (EXP), and Logarithmic (LOG)
models. Using the VCDM equations for cosmological perturbations, we test them
against the recent cosmological datasets, Planck 2018 and DESI BAO DR2, and
then discuss their implications.

</details>


### [11] [Covariant and Gauge-invariant Metric-based Gravitational-waves Extraction in Numerical Relativity](https://arxiv.org/abs/2508.03799)
*Joan Fontbuté,Sebastiano Bernuzzi,Simone Albanesi,David Radice,Alireza Rashti,William Cook,Boris Daszuta,Alessandro Nagar*

Main category: gr-qc

TL;DR: The paper introduces a new method for extracting gravitational waves from numerical relativity simulations using metric perturbation theory, overcoming the limitations of fixed Schwarzschild coordinates. They validate this method with various scenarios, showing accurate waveform extraction and reduced gauge effects. The method allows for robust computation of both even and odd parity modes, achieving high-quality waveforms compatible with existing methods like Cauchy-Characteristic Extraction. The findings are valuable for comparing different extraction techniques and understanding waveform systematics.


<details>
  <summary>Details</summary>
Motivation: Gravitational wave extraction is a critical area in astrophysics and numerical relativity, with various methods each having their strengths and weaknesses. This paper aims to address the shortcomings of existing methods in extracting gravitational wave signals from numerical simulations, potentially improving the accuracy and reliability of gravitational wave modeling.

Method: The researchers use metric perturbation theory in spherical spacetimes to develop a gauge-invariant extraction algorithm. They work within a (3+1) decomposition and test their approach across various numerical scenarios, including neutron stars, spacetime perturbations, black hole mergers, and more. The method avoids assuming Schwarzschild coordinates for the background, enhancing the applicability and robustness of the extraction process.

Result: The results demonstrate that the new extraction method yields accurate strain multipoles for both even and odd parity modes across multiple physical scenarios. The method shows good agreement in the even-parity sector and minimizes gauge effects in the odd-parity sector by choosing appropriate background coordinates. The waveforms produced are of high quality and compatible with those obtained from more complex Cauchy-Characteristic Extraction methods.

Conclusion: The proposed method provides a valuable tool for gravitational wave extraction in numerical relativity, improving the understanding of waveform systematics and reducing ambiguities in strain reconstruction. It offers a balanced approach, combining accuracy with computational efficiency, making it applicable to a wide range of astrophysical systems including neutron stars and black hole mergers. This advancement is significant for enhancing future gravitational wave detections and modeling efforts.

Abstract: We revisit the problem of gravitational-wave extraction in numerical
relativity with gauge-invariant metric perturbation theory of spherical
spacetimes. Our extraction algorithm allows the computation of even-parity
(Zerilli-Moncrief) and odd-parity (Regge-Wheeler) multipoles of the strain from
a (3+1) metric without the assumption that the spherical background is in
Schwarzschild coordinates. The algorithm is validated with a comprehensive
suite of 3D problems including fluid ($f$-modes) and spacetime ($w$-modes)
perturbations of neutron stars, gravitational collapse of rotating neutron
stars, circular binary black holes mergers and black hole dynamical captures
and binary neutron star mergers. We find that metric extraction is robust in
all the considered scenarios and delivers waveforms of overall quality similar
to curvature (Weyl) extraction. Metric extraction is particularly valuable in
identifying waveform systematics for problems in which the reconstruction of
the strain from the Weyl multipoles is ambiguous. Direct comparison of
different choices for the gauge-invariant master functions show very good
agreement in the even-parity sector. Instead, in the odd-parity sector,
assuming the background in Schwarzschild coordinates can minimize gauge effects
related to the use of the $\Gamma$-driver shift. Moreover, for optimal choices
of the extraction radius, a simple extrapolation to null infinity can deliver
waveforms compatible to Cauchy-characteristic extrapolated waveforms.

</details>


### [12] [Normal modes of charged AdS solitons](https://arxiv.org/abs/2508.03951)
*Mengqi Lu,Ming Zhang,Robert B. Mann*

Main category: gr-qc

TL;DR: 研究分析了四维和五维带电反德西特孤子时空上的大量带电标量场扰动，通过局部分析和数值方法确定了规范模式谱，并揭示了其标度规律和渐近行为，这些频率的实数性表明了孤子的动态稳定性，从而支持了渐近局部反德西特空间中的正能猜想。


<details>
  <summary>Details</summary>
Motivation: 研究高维时空中的孤子稳定性对于理解大范围物理学问题，如量子引力和强对称性原理方程有重要意义。

Method: 采用了Horowitz-Hubeny方法和列科列点方法进行数值计算

Result: 规范模式谱的频率是实数的，孤子空间是动态稳定的，支持渐近局部反德西特正能猜想。

Conclusion: 研究结果为渐近局部反德西特时空的正能猜想提供了数值支持。

Abstract: We study massive charged scalar field perturbations in four- and five-
dimensional charged anti-de Sitter soliton spacetimes. Appropriate boundary
conditions are established via a local analysis of the perturbation equations.
The normal mode spectra are then calculated numerically using the
Horowitz-Hubeny method and a collocation method. We reveal scaling laws and
asymptotic behaviors governing the normal mode spectra. The reality of the
normal mode frequencies indicates the dynamic stability of the soliton, which
in turn provides support for the positive energy conjecture in asymptotically
locally anti-de Sitter spacetime.

</details>


### [13] [Hamiltonian analysis of an Effective action coupled to the Palatini action in 4 dimensions](https://arxiv.org/abs/2508.04006)
*Ricardo Escobedo,Roberto Santos-Silva,Claudia Moreno,Rafael Hernández-Jiménez*

Main category: gr-qc

TL;DR: 研究论文G详细分析了七维BF理论降维后与四维Palatini作用的相互作用，重点考察了时空均匀性和各向异性，通过Ostrogradsky方法处理二阶时间导数，寻找一致解，并发现有效作用导致视在消失的引力。


<details>
  <summary>Details</summary>
Motivation: 研究高维理论与四维引力相互作用对宇宙学和量子引力的影响是当前理论物理的重要方向，这篇论文通过降维分析探讨了在均匀和各向同性条件下的引力行为，为理解宇宙结构和量子引力效应提供了新视角。

Method: 论文采用了规范的正则分析方法，将七维BF理论降维并与其四维Palatini作用耦合，引入正则变量处理二阶导数问题，通过一致性条件找出三种一致解方式，最终明确了有效作用在引力消失方面的结论。

Result: 研究发现，在所有三种一致情况中，四维有效作用表现出视在无引力，这为理解宇宙演化和量子引力效应提供了理论支持。

Conclusion: 该研究确认了在特定条件下，高维理论的降维可能导致四维视在没有引力的解，深入阐明了时空维度变化对引力作用的影响。

Abstract: We carry out the canonical analysis of the coupling of a $4$-dimensional
effective action that arises from a dimensional reduction of a $7$-dimensional
BF theory to the Palatini action in $4$-dimensions with cosmological constant,
focusing on homogeneity and isotropy in all involved fields. We employ
Ostrogradsky's methodology because of the presence of second time derivatives.
Through the analysis of consistency conditions, we identify three distinct and
consistent possibilities. In all these scenarios, we explore the solution of
second-class constraints in terms of pairs of canonical variables. Similarly,
Hamiltonian analysis is performed only for the $4$-dimensional effective
theory. The second-class constraints are solved in terms of canonical
coordinates, revealing that this formulation aligns with one of the viable
scenarios explored in the coupling to the $4$-dimensional Palatini action,
entailing that the $4$-dimensional effective action nullifies gravity.

</details>


### [14] [Probing globular clusters using modulated gravitational waves from binary black holes](https://arxiv.org/abs/2508.04021)
*Jie Wu,Yao Xiao,Mengfei Sun,Jin Li*

Main category: gr-qc

TL;DR: 该论文提出了一种利用双星的质量载体（BBH）引力波信号来提高开瓶 cluster的距离和质量测量精度的方法。通过模拟和费舍尔信息矩阵分析，他们得出了显著减小了测量误差。


<details>
  <summary>Details</summary>
Motivation: 研究恒星动力学和宇宙结构的关键对象是开瓶，但距离和质量的测量往往是基于电磁观测存在很多不确定性，该论文通过引入引力波信号，利用双星系统的共同特性来提升测量精度。

Method: 该研究方法利用双星系统产生的引力波信号，通过模拟和费舍尔信息矩阵分析评估参数约束。

Result: 研究结果表明，引入引力波观测可以显著降低开瓶测量的不确定性，在很多情况下改善了测量精度，比之前的方法高了一个数量级。

Conclusion: 这些发现表明，利用双星系统的引力波信号可以作为开瓶的动力学探针，引力波作为研究手段在开瓶研究中具有重要意义，超越了传统电磁方法的局限性。

Abstract: Globular clusters (GCs) are crucial for studying stellar dynamics and
galactic structure, yet precise measurements of their distances and masses are
often limited by uncertainties in electromagnetic (EM) observations. We present
a novel method that leverages gravitational waves (GWs) from stellar-mass
binary black holes (BBHs) orbiting within GCs to enhance the precision of GC
parameter measurements. The BBH's orbital motion imprints characteristic
modulations on the GW waveform, encoding information about the host GC. Using
post-Newtonian waveforms and Lorentz transformations, we simulate modulated GW
signals and evaluate the resulting parameter constraints via a Fisher
information matrix analysis. Our results show that incorporating GW
observations can significantly reduce the uncertainties in GC distance and mass
measurements, in many cases achieving improvements by an order of magnitude.
These findings demonstrate the value of BBHs as dynamical probes and highlight
the power of GWs to advance GC studies beyond the limits of traditional EM
methods.

</details>


### [15] [Rapid parameter estimation with the full symphony of compact binary mergers using meshfree approximation](https://arxiv.org/abs/2508.04172)
*Abhishek Sharma,Lalit Pathak,Soumen Roy,Anand S. Sengupta*

Main category: gr-qc

TL;DR: This paper presents a faster way to do Bayesian inference for gravitational waves, making it possible to handle more data and longer signals with less computational cost.


<details>
  <summary>Details</summary>
Motivation: Gravitational wave detection and analysis are becoming more advanced, requiring more complex models, but the computational cost is rising, making analysis slower and more resource-intensive.

Method: The authors use a meshfree likelihood interpolation method with radial basis functions. They create interpolation nodes within a constant-match metric ellipsoid in the intrinsic parameter space. During sampling, they evaluate likelihoods using these precomputed interpolants, which avoids costly waveform generation and overlap integrals. They also rotate the parameter space to align with the metric ellipsoid's eigenbasis, reducing parameter correlations and speeding up the sampler.

Result: Their method reduces computational cost by up to an order of magnitude for the longest signals and achieves unbiased parameter recovery. It also applies to other compact binary systems and demonstrates a significant speed-up when used with Einstein Telescope data.

Conclusion: This method provides a computationally efficient alternative for Bayesian inference in gravitational wave parameter estimation, making it suitable for the upcoming third-generation detectors.

Abstract: We present a fast Bayesian inference framework to address the growing
computational cost of gravitational-wave parameter estimation. The increased
cost is driven by improved broadband detector sensitivity, particularly at low
frequencies due to advances in detector commissioning, resulting in longer
in-band signals and a higher detection rate. Waveform models now incorporate
features like higher-order modes, further increasing the complexity of standard
inference methods. Our framework employs meshfree likelihood interpolation with
radial basis functions to accelerate Bayesian inference using the IMRPhenomXHM
waveform model that incorporates higher modes of the gravitational-wave signal.
In the initial start-up stage, interpolation nodes are placed within a
constant-match metric ellipsoid in the intrinsic parameter space. During
sampling, likelihood is evaluated directly using the precomputed interpolants,
bypassing the costly steps of on-the-fly waveform generation and
overlap-integral computation. We improve efficiency by sampling in a rotated
parameter space aligned with the eigenbasis of the metric ellipsoid, where
parameters are uncorrelated by construction. This speeds up sampler
convergence. This method yields unbiased parameter recovery when applied to 100
simulated neutron-star-black-hole signals (NSBH) in LIGO-Virgo data, while
reducing computational cost by up to an order of magnitude for the
longest-duration signal. The meshfree framework equally applies to symmetric
compact binary systems dominated by the quadrupole mode, supporting parameter
estimation across a broad range of sources. Applied to a simulated NSBH signal
in Einstein Telescope data, where the effects of Earth's rotation are neglected
for simplicity, our method achieves an O(10^4) speed-up, demonstrating its
potential use in the third-generation (3G) era.

</details>


### [16] [Null infinity as $SU(2)$ Chern-Simons theories and its quantization](https://arxiv.org/abs/2508.04220)
*Hongwei Tan,Kui Xiao,Shoucheng Wang*

Main category: gr-qc

TL;DR: This paper quantizes future null infinity (I⁺) of asymptotically flat spacetimes using the weakly isolated horizon framework and Chern-Simons theory. The quantization leads to an entropy formula consistent with existing results.


<details>
  <summary>Details</summary>
Motivation: The paper contributes to understanding the quantization of spacetime boundaries and calculating their entropy, which is a key aspect in quantum gravity theories.

Method: The authors observe I⁺ as a weakly isolated horizon, adopt its quantization method, show its symplectic structure equivalence to two Chern-Simons theories, and compute entropy by microstates counting.

Result: The entropy calculation using microstates is proportional to the area of a spacelike cross-section of I⁺, matching the universal entropy formula.

Conclusion: The research provides a quantization framework for isolated horizons and a consistent entropy calculation aligning with quantum gravity theories.

Abstract: This paper studies the quantization of the future null infinity
($\mathscr{I}^+$) of an asymptotically flat spacetime. Based on the observation
by Ashtekar and Speziale that $\mathscr{I}^+$ can be regarded as a weakly
isolated horizon, we adopt the quantization framework developed for weakly
horizon to quantize $\mathscr{I}^+$. We first show that the symplectic
structure of $\mathscr{I}^+$ is equivalent to the sum of the symplectic
structures of two $SU(2)$ Chern-Simons theories with opposite levels. Based on
this observation, we apply Chern-Simons quantization approach to quantize
$\mathscr{I}^+$. Finally, we compute the entropy of $\mathscr{I}^+$ by counting
the microstates, showing that it is proportional to the area of
$\tilde{\Delta}$, a spacelike cross-section of $\mathscr{I}^+$. Our result is
consistent with the universal entropy formula in the framework of (weakly)
isolated horizon.

</details>


### [17] [Entanglement and particle production from cosmological perturbations: a quantum optical simulation approach](https://arxiv.org/abs/2508.04249)
*Pramod Kamal Kharel,Mausam Ghimire,Ashish Khanal,Samyam Pudasaini,Nabaraj Khatri,Sayujya Bhandari,Divash Rai,Kiran Adhikari,Rajeev Singh*

Main category: gr-qc

TL;DR: 研究使用高斯形式主义和对称电路表示来研究宇宙涨落。构建了一个框架模拟涨缩器，计算了冯·诺依曼熵和对数负性，与解析的Rényi熵进行了比较，以验证计算的一部分是否正确。研究了热噪声对这些熵的影响。


<details>
  <summary>Details</summary>
Motivation: 对量子信息和宇宙论感兴趣的研究者，特别是研究宇宙学涨落和量子态演化的人。

Method: 使用高斯形式主义和对称电路表示法来模拟宇宙环境中的涨缩器行为，研究冯·诺依曼熵和对数负性。

Result: 模拟结果表明，在不同宇宙背景下的冯·诺依曼熵和对数负性计算准确。添加热噪声后，结果更贴近真实情况。

Conclusion: 该框架有效评估了宇宙涨缩和量子态演化，为研究量子涨缩和宇宙发展提供了方法。

Abstract: In this work, we develop a computational framework based on the Gaussian
formalism and symplectic circuit representation to explore cosmological
perturbations during inflation. These tools offer an efficient means to study
entanglement generation and particle production, particularly when analytical
methods become insufficient and numerical simulations are essential. By
evolving an initial Bunch-Davies vacuum through a two-mode squeezer, we
simulate the behavior of the von Neumann entropy and logarithmic negativity
across a wide range of cosmological backgrounds, each characterized by a
distinct equation of state. The von Neumann entropy obtained via QuGIT
simulations is compared with analytic R\'enyi entropy bounds, thereby
validating the accuracy of our circuit implementation of the cosmological
squeezing Hamiltonian in both accelerating and decelerating scenarios. We
further investigate the role of thermal noise and demonstrate how the von
Neumann entropy and logarithmic negativity are affected by its presence.

</details>


### [18] [Cosmological models with Bounce scenario in f(Q,C)-gravity](https://arxiv.org/abs/2508.04256)
*Bhaswati Mandal,B. C. Paul*

Main category: gr-qc

TL;DR: Summary involves analyzing a bounce universe model in modified f(Q,C) gravity with quadratic C^2 term, comparing power law and exponential gravity forms.


<details>
  <summary>Details</summary>
Motivation: The paper aims to explore alternative gravity theories that could explain early universe dynamics without singularities, such as a bounce universe. This could contribute to resolving cosmological issues like the initial singularity problem and provide new insights into cosmic expansion mechanisms.

Method: The paper uses modified f(Q,C) gravity with a quadratic C^2 term to analyze cosmological models. They explore power law and exponential gravity forms, evaluating energy conditions and stability of bounces.

Result: Apparent expansion behavior, conditions satisfied without contradictions, stable bounce solutions found with numerical methods.

Conclusion: The study suggests modify gravity with f(Q,C) can provide viable bounce cosmology, expanding applicability of modified gravity theories in cosmology.

Abstract: We present a bounce universe in modified $f(Q,C)$ gravity considering linear
as well as exponential form of gravity. Bounce cosmological models are
introduced to remove the singularity problem of the early universe. A new
quadratic boundary term ($C^2$), which is added in the modified gravity to
study different features of the universe in the framework of bouncing
cosmology. Both power law expansion and exponential emergent universe are
explored in linear modified gravity. The energy conditions and stability of
cosmological bounce are investigated. We also compared power law expansion in
linear and exponential form of modified gravity.

</details>


### [19] [Gravitational wave spectra for cosmological phase transitions with non-linear decay of the fluid motion](https://arxiv.org/abs/2508.04263)
*Isak Stomberg,Alberto Roper Pol*

Main category: gr-qc

TL;DR: The paper presents a theoretical framework for gravitational wave production during first-order phase transitions, using a UETC model for bulk fluid motion. The method generalizes the sound-shell model for non-linear fluid dynamics and validates it with Higgsless simulations in the CosmoGW package.


<details>
  <summary>Details</summary>
Motivation: Understanding gravitational waves from cosmological phase transitions is crucial for cosmology and early universe physics.

Method: Uses a UETC model for bulk fluid motion, generalizes the sound-shell model for non-linear evolution, and implements templates in CosmoGW.

Result: Establishes templates based on their model and integrates them into CosmoGW for experimental use.

Conclusion: The work provides a framework that bridges cosmology and GW physics, aiding in parameter estimation and experimental forecasts.

Abstract: We summarize the theoretical framework of gravitational wave (GW) production
by bulk fluid motion induced by expanding broken-phase bubbles during a
first-order phase transition. Using a locally stationary unequal-time
correlator (UETC) to model the decay of the source due to non-linearities, we
provide templates for the resulting GW background that have been validated
against data from Higgsless simulations. This UETC generalizes the stationary
one considered in the sound-shell model, appropriate for linear sound waves
whose kinetic-energy decay is negligible, to encompass the non-linear evolution
of the compressional fluid motion beyond the sound-wave regime. We demonstrate
the implementation of templates based on this theoretical description and the
results from the Higgsless simulations in the public Python package CosmoGW,
facilitating their use in experimental forecasts and parameter-estimation
studies. The GW spectrum is delivered as a function of the key phase transition
parameters: the wall velocity $v_w$, the strength $\alpha$, the nucleation rate
$\beta$, and the source duration $\delta \eta_{\rm fin}$.

</details>


### [20] [D-dimensional black holes in extended Gauss-Bonnet gravity](https://arxiv.org/abs/2508.04292)
*Jia-Zhou Liu,Si-Jiang Yang,Chun-Chun Zhu,Yu-Xiao Liu*

Main category: gr-qc

TL;DR: 该论文研究了d维空间（d≥5）中带有电荷的反德西特黑洞解，基于扩展的高斯-博内引力。通过扩展高斯-博内项的维度正则化，还能得到三维和四维时空中的反德西特黑洞解。此外，还找到了三维旋转黑洞解。这些解在不同参数空间下表现出不同的性质，可以拥有一个、两个甚至三个视界。尽管如此，它们在无穷远处的行为与广义相对论中的黑洞保持一致。


<details>
  <summary>Details</summary>
Motivation: 该论文扩展了广义相对论中的爱伦方程，提出新的引力理论模型，并通过求解爱伦方程在高维空间中的解，研究了黑洞的结构和性质，丰富了爱伦引力理论的应用和解的多样性。

Method: 作者使用了扩展的高斯-博内引力理论，在d维空间中研究了带有电荷的反德西特黑洞解。通过正则化处理扩展的高斯-博尼项，得出了不同维度下的黑洞解，还找到了三维旋转黑洞解。

Result: 作者在不同维度的反德西特空间中发现了一系列具有不同参数的黑洞解，这些解在视界行为和无穷远处行为上与广义相对论一致。

Conclusion: 作者的研究显示，扩展的高斯-博尼引力在不同维度下可以生成多项黑洞解，这些解的性质在不同参数空间下各具特色，但具有统一的渐进行为。该研究为广义相对论的扩展模型提供了新的见解。

Abstract: In this work, we present charged spherically symmetric anti-de Sitter black
hole solutions in $d$ dimensions ($d \geq 5$) within the framework of extended
Gauss--Bonnet gravity. Moreover, by employing dimensional regularization of the
extended Gauss--Bonnet term, we further obtain charged anti-de Sitter black
hole solutions in three- and four-dimensional spacetimes. Furthermore, we also
obtain a three-dimensional rotating black hole solution in a special case.
These solutions exhibit markedly different properties compared to their
counterparts in standard Gauss--Bonnet gravity. Depending on the parameter
space, the black hole may possess one, two, or even three horizons.
Nonetheless, their asymptotic behavior at spatial infinity remains consistent
with that of the corresponding black holes in general relativity.

</details>


### [21] [Kullback-Leibler Divergence as a Measure of Irreversible Information Loss Near Black Hole Horizons](https://arxiv.org/abs/2508.04348)
*Tatsuaki Tsuruyama*

Main category: gr-qc

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We present a unified theoretical framework that integrates information
theory, thermodynamics, and general relativity to analyze the fundamental limit
of decoding time-encoded signals in curved spacetime. In particular, we
introduce the Kullback-Leibler divergence (KLD) as a quantitative measure of
the mismatch between the transmitted and received symbol distributions induced
by gravitational time dilation. Using a minimal communication model, we derive
the critical radius at which information decoding becomes thermodynamically
impossible due to the divergence of the KLD. We show that this radius
approaches the Schwarzschild horizon in the limit where the information entropy
cost becomes negligible relative to the transmission energy. This result
provides a novel information-theoretic interpretation of the event horizon as a
boundary of irreversible information loss governed by universal thermodynamic
principles. Our framework offers new insights into the entropic and energetic
constraints on communication in strong gravitational fields and may extend to
general relativistic and quantum information settings.

</details>


### [22] [Black hole thermodynamics from Iyer-Wald formalism with variable Newton's constant](https://arxiv.org/abs/2508.04446)
*Xuan-Rui Chen,Bin Wu,Zhen-Ming Xu*

Main category: gr-qc

TL;DR: This paper explores how restricted phase space thermodynamics can consistently apply Iyer-Wald formalism to black hole thermodynamics. They focus on varying Newton's constant and establish a thermodynamic system that includes both the first law and Euler relation using diffeomorphism-invariant gravitational theories.


<details>
  <summary>Details</summary>
Motivation: The paper introduces a new approach to black hole thermodynamics by considering variations in Newton's gravitational constant within the restricted phase space framework. This could provide a more robust foundation for understanding thermodynamic properties of black holes, especially in the context of varying constants which may be relevant in certain cosmological or quantum gravity scenarios.

Method: The authors use the Iyer-Wald formalism within the framework of general diffeomorphism-invariant gravitational theories. They focus on the restricted phase space approach, varying Newton's gravitational constant, and construct a self-consistent thermodynamic system incorporating both the first law and the Euler relation.

Result: They successfully demonstrate that the Iyer-Wald formalism is applicable to restricted phase space thermodynamics. This allows the construction of an extensive black hole thermodynamic system that includes the first law and the Euler relation. The approach is generalized to any diffeomorphism-invariant gravitational theory.

Conclusion: This work establishes the Iyer-Wald formalism as a geometric foundation for restricted phase space black hole thermodynamics, providing a new method to study black hole thermodynamics in gravitational theories with variable Newton's constant. This advancement ensures consistency and generality in the thermodynamic description of black holes within this framework.

Abstract: Recent advances in black hole thermodynamics have intensified efforts to
investigate its thermodynamic framework analogues to that of classical thermal
systems. Departing from the extended phase space approach which involves a
variable cosmological constant, the restricted phase space formalism focusing
on the variations of Newton's gravitational constant in black hole
thermodynamics is proposed. This approach enables the construction of a
self-consistent thermodynamic structure that features both the first law and
the Euler relation. In this paper, we demonstrate that for any
diffeomorphism-invariant gravitational theory, the Iyer-Wald formalism is
applicable to restricted phase space thermodynamics and construct a
self-consistent extensive black hole thermodynamic system. Our work thereby
establishes the Iyer-Wald approach as the geometric foundation for restricted
phase space black hole thermodynamics.

</details>


### [23] [Interacting Dark Sector: An Isobaric Approximation](https://arxiv.org/abs/2508.04475)
*Bob Osano*

Main category: gr-qc

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: What if the dark sector is not a static entity but rather a dynamic entity
with interactive components of the universe? This intriguing hypothesis raises
important questions regarding the phenomenological behaviour of such an
evolving system. In this study, we explore the simultaneous evolution and
interaction of two hypothetical components within the context of an interacting
dark sector, examining their implications for our understanding of cosmological
dynamics.

</details>


### [24] [Periapsis shifts in the electric and magnetic Kiselev black hole spacetimes](https://arxiv.org/abs/2508.04577)
*Marina-Aura Dariescu,Vitalie Lungu,Cristian Stelea*

Main category: gr-qc

TL;DR: This paper studies periapsis shifts of charged test particles in Kiselev black holes with electric and magnetic charges. Exact solutions for charged black holes surrounded by charged anisotropic fluids are derived. Motion analysis shows periapsis precession for uncharged particles, while for charged particles it can shift retrograde in both electrically and magnetically charged black holes.


<details>
  <summary>Details</summary>
Motivation: The paper contributes to understanding orbital dynamics around charged black holes, specifically focusing on periapsis precession. This is relevant to both theoretical physics and potentially future observational studies of black holes and particle motion in strong gravitational fields.

Method: Exact solutions of Einstein's equations for charged anisotropic fluids surrounding Kiselev black holes are derived. Motion of charged test particles is analyzed to determine periodic precession directions (prograde or retrograde).

Result: For uncharged particles, periapsis precesses prograde. For charged particles, periapsis shifts can be retrograde in both cases of electric and magnetic charges.

Conclusion: It is demonstrated that electromagnetic fields cause significant changes in orbital dynamics, leading to periapsis shifts that may differ from classical expectations. This challenges existing theories and opens new research directions in black hole mechanics and particle motion.

Abstract: In this work we consider the periapsis shift in the motion of charged test
particles in the charged Kiselev black holes. First, we present a new exact
solution of Einstein's equations describing an electrically charged Kiselev
black hole surrounded by a charged anisotropic fluid and we consider the motion
of charged particles in this background. In the second part of this paper we
consider the recently obtained magnetized Kiselev black hole. In both cases we
found that for uncharged particles the periapsis shifts for bounded orbits is
always prograde. However, for charged test particles the periapsis shifts can
become retrograde in both cases, for electrically charged or magnetized Kiselev
black holes.

</details>


### [25] [Extension of the Einstein-Dirac-axion-aether theory based on an effective metric with a spinor kernel](https://arxiv.org/abs/2508.04636)
*Alexander B. Balakin,Anna O. Efremova*

Main category: gr-qc

TL;DR: 研究扩展后的爱因斯坦-迪拉克-埃 hypothesis 理论，利用有效的度量，将伪标量场的动能项进行矢旋转量修改，研究了自旋场对轴质暗物质的反作用效应。默认使用守恒对称性获得指导函数的方程式，并构建了具有新来源项的方程组。获得了均匀而各向同性的宇宙模型的精确解，讨论了自旋场对轴质暗物质演变的机制。研究提供了新方法对这类问题进行分析。


<details>
  <summary>Details</summary>
Motivation: 研究有潜力的扩展模型，可能对理解暗物质和暗能量等基本物理现象提供见解。

Method: 使用了变分法构建有效度量，考虑伪标量与伪矢量的互动，推导了新的微分方程组。

Result: 获得精确解，展示了反作用机制，有助于分析类似问题。

Conclusion: 扩展理论提供了对轴质暗物质反作用效应的全新机制，未来可应用到更多宇宙学问题中。

Abstract: We consider an axionic extension of the Einstein-Dirac-aether theory, which
is based on the spinor modification of the kinetic term of the pseudoscalar
field and describes the backreaction of the spinor field on the axionic dark
matter. The main instrument of this extension is the effective metric
constructed using the aether velocity four-vector and a kernel, which depends
on the basic spinor scalar and on the square of the basic spinor pseudoscalar.
The periodic potential of the axion field includes a guiding function, which
regulates the dynamics of axions and predetermines the properties of their
equilibrium states. This guiding function and the kernel of the effective
metric, as well, are considered to be functions of the expansion scalar of the
aether flow. The master equation for the guiding function is obtained as a
consequence of the Lagrangian invariance with respect to the discrete
transformations prescribed by the axion field shift symmetry. The
self-consistent set of coupled master equations is derived, which includes new
source-terms in the modified master equations for the spinor, axion, vector and
gravitational fields. Cosmological applications of the extended theory are
considered; new exact solutions of these equations are presented for the
isotropic homogeneous model of the Universe evolution. Discussion is focused on
the mechanism of backreaction of the spinor field on the axionic dark matter
evolution.

</details>


### [26] [Bell states for fermions in loop quantum gravity](https://arxiv.org/abs/2508.04704)
*Hanno Sahlmann,Martin Zeiß*

Main category: gr-qc

TL;DR: The paper explores fermion entanglement in loop quantum gravity, attempting to define and measure it. After finding some methods ineffective, it uses spin components as an alternative observable. It successfully violates the Bell-CHSH inequality, suggesting quantum gravity effects might make Bell inequalities irrelevant.


<details>
  <summary>Details</summary>
Motivation: The paper aims to examine entanglement in loop quantum gravity, inspired by using gravity-mediated entanglement as a quantum gravity test.

Method: Aim to define fermionic entanglement in LQG, test methods, use spin components observable, compare to QM, show Bell violation with quantum geometry states.

Result:  successful demonstration of a quantum gravity effect, fermionic Bell-CHSH violation, which endorses quantum gravity impact on Bell inequalities.

Conclusion: Loop quantum gravity can lead to Bell inequality violations, highlighting potential impact on quantum theory.

Abstract: Fermion fields are fundamental for the description of nature and also fit
very naturally into the framework of loop quantum gravity. Motivated partially
by proposals to use gravitationally mediated entanglement of matter as a
witness for the quantum nature of gravity, we investigate how such entanglement
can be defined and investigated in loop quantum gravity. In particular, we ask
how a pair of fermions in a Bell state could be described in loop quantum,
gravity.
  We demonstrate that the notion of fermionic entanglement in loop quantum
gravity is subtle, by showing that some potential ways to define it fail. We
then investigate a kinematical observable involving both, fermionic and
gravitational degrees of freedom, the component of the fermion spin normal to a
surface. We study its properties, and compare it to the standard operator for
components of spin in a given direction in quantum mechanics. Using these
normal components of spin, we define a kinematical observable that measures the
correlation between space-like separated fermions which closely mirrors the
CHSH observable. Finally, we exhibit states of the fermions coupled to quantum
geometry that violate the Bell-CHSH inequality.

</details>


### [27] [Innermost stable circular orbit of Kerr-Bertotti-Robinson black holes and inspirals from it: Exact solutions](https://arxiv.org/abs/2508.04684)
*Tower Wang*

Main category: gr-qc

TL;DR: 研究者在Kerr-Bertotti-Robinson时空下找到了两种独特轨道，一种是顺时针和逆时针的内层稳定圆形轨道，无论是否包含电荷，其内外半径都可以用两极的小和大半径表达，显示出当Kerr-Bertotti-Robinson黑洞具有三个参数时，结果与Kerr黑洞类似。另一种是测试粒子从无限遥远过去靠近黑洞的闭式解析解，这两种精确结果可以为未来一般解和天体物理应用提供基础。


<details>
  <summary>Details</summary>
Motivation: 该研究有助于深入理解强引力区域中的粒子运动，这对于测试引力理论和天体物理模型至关重要。

Method: 该研究通过精确求解相关微分方程和使用凯斯半径的概念来推导轨道参数。

Result: 发现了两种独特的轨道，包括内层稳定圆形轨道及其解析解。

Conclusion: 该研究扩展了Kerr黑洞理论，并为未来的研究提供了精确的基础。

Abstract: For an uncharged test particle in the Kerr-Bertotti-Robinson spacetime, two
classes of remarkable orbits are worked out, both in exact forms. First, for
both prograde and retrograde motions, the radii of innermost stable circular
orbits are expressed fully in terms of the outer and inner horizon radii just
like Kerr black holes, despite the fact that Kerr-Bertotti-Robinson black holes
have three parameters. Second, closed analytic solutions are given to the
problem of a test particle inspiraling toward the Kerr-Bertotti-Robinson black
hole from innermost stable circular orbits at the infinitely distant past.
These exact solutions can serve as a springboard for more general solutions and
astrophysical applications in the future.

</details>


### [28] [Controlled regularity at future null infinity from past asymptotic initial data: the wave equation](https://arxiv.org/abs/2508.04690)
*Jordan Marajh,Grigalius Taujanskas,Juan A. Valiente Kroon*

Main category: gr-qc

TL;DR: 研究了Minkowski时空中渐近特征初始数据与解在未来Null无穷处的正则性之间的关系。通过构建Cauchy矩形内的估计，证明了解在Null和空间无穷附近的行为，并具备消光性质，适用于非紧支的数据。使用了Friedrich的共形表示方法，获得了精确的Gronwall估计。探讨了解与数据在共形与物理坐标下的关系。


<details>
  <summary>Details</summary>
Motivation: 了解波方程在Minkowski空间中的解在不同无穷远处的行为如何互相影响，特别是渐近数据如何决定解的正则性，是理论物理和数学分析中的重要课题。

Method: 通过构建Cauchy矩形内的估计并使用Friedrich的共形表示方法，获得了精确的Gronwall估计，探讨了解与数据的共形与物理坐标关系。

Result: 解在Null和空间无穷的表现，且具备消光行为，适用于非紧支数据，是非常精确的正则性控制。

Conclusion: 渐近数据的正则性决定了解在无穷远处的消光行为，这种关系通过精确的Coercive估计在共形框架下建立，满足了消光行为的需求。此外，解与数据之间在不同坐标系下的对应关系也被详细描述。

Abstract: We study the relationship between asymptotic characteristic initial data for
the wave equation at past null infinity and the regularity of the solution at
future null infinity on the Minkowski spacetime. By constructing estimates on a
causal rectangle reaching the conformal boundary, we prove that the solution
admits an asymptotic expansion near null and spatial infinity whose regularity
is controlled quantitatively in terms of the regularity of the data at past
null infinity. In particular, our method gives rise to solutions to the wave
equation in a neighbourhood of spatial infinity satisfying the peeling
behaviour, for data on past null infinity with non-compact support. Our
approach makes use of Friedrich's conformal representation of spatial infinity
in which we prove delicate non-degenerate Gr\"onwall estimates. We describe the
relationship between the solution and the data both in terms of Friedrich's
conformal coordinates and the usual physical coordinates on Minkowski space.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [29] [Longitudinal magnons in large-$S$ easy-axis magnets](https://arxiv.org/abs/2508.03899)
*A. El Mendili,T. Ziman,M. E. Zhitomirsky*

Main category: cond-mat.str-el

TL;DR: 研究讨论了长磁on在各种相互作用下的激发谱。通过不同的方法，如多玻色数展开、链接簇展开和精确解，得出了长磁的衰减率和激发谱随弱轴向性能变化的演变。


<details>
  <summary>Details</summary>
Motivation: 研究长磁on激发谱对材料性能的影响，尤其是在不同相互作用下的表现。这可能对于未来开发具有特定磁性特性的材料有帮助。

Method: 通过多玻色数展开、链接簇展开和精确求解等方法，计算长磁的激发谱。

Result: 不同方法得出多玻色数展开证明了磁的衰减率，并描述了激发谱如何随着弱轴向性能的变化而变异。

Conclusion: 对多玻色数展开的有效性和不同方法之间的对比提供了新的见解，有助于后续研究。外推结果到实际材料，支持开发具有特定磁性特性的材料。

Abstract: Longitudinal magnons are a novel class of multipolar quantum excitations in
magnetic materials with large spins $S\ge 1$ and strong easy-axis anisotropy.
These excitations have angular momentum $S^z = \pm 2S$ and can be viewed as
propagating spin reversals. We study a simple model for longitudinal magnons: a
square lattice of spins $S$ coupled by the neareast-neighbor exchange, ferro-
or antiferromagnetic, in the presence of a single-ion anisotropy. We calculate
the excitation spectra in the large-$D$ limit by using a strong-coupling
expansion. In the specific case of $S=1$ we compare the results for several
analytical approaches that include the linked-cluster expansion, the multiboson
representation of spin operators, and also, for a ferromagnetic ground state,
the exact solution of the two-particle bound states. Among these different
approaches, the multiboson theory gives the decay rate of longitudinal magnons
and describes the evolution of the excitation spectra from strong to moderate
and weak anisotropy.

</details>


### [30] [Composite Fermion Theory of Fractional Chern Insulator Stability](https://arxiv.org/abs/2508.03915)
*Xiaodong Hu,Ying Ran,Di Xiao*

Main category: cond-mat.str-el

TL;DR: 研究开发了分数Chern绝缘体的平均场理论，基于复合费米子的梯度 Picture，构造了CF的单粒子哈密顿量，适用于像扭转 MoTe₂ 这样的材料，计算出的相图与精确对角化结果高度契合，许多体波函数也具有高重叠度。理论提供了微观理解与高效计算工具。


<details>
  <summary>Details</summary>
Motivation: 研究者希望开发一个适用于计算材料特性，如分数Chern绝缘体的平均场理论，以提高计算效率并准确预测材料行为。

Method: 基于复合费米子的梯度 picture，构造了CF的单粒子哈密顿量，考虑了*vortex*与Bloch电子的束缚，导出了一个在扩大后的CF Hilbert空间中的哈密顿量，结合霍夫施塔特问题，特别在小*q*极限下自然导出了trace条件。

Result: 计算获得的CF相图与精确对角化结果一致，且许多体波函数具有高重叠度，证明了该方法的有效性。

Conclusion: 该理论不仅提供了微观层面的物理解释，还为高效计算分数Chern绝缘体提供了可靠工具。研究结论对于理解此类材料的电子行为具有重要意义，且在实验设计与材料开发中具有广阔前景。

Abstract: We develop a mean-field theory of the stability of fractional Chern
insulators based on the dipole picture of composite fermions (CFs). We
construct CFs by binding vortices to Bloch electrons and derive a CF
single-particle Hamiltonian that describes a Hofstadter problem in the enlarged
CF Hilbert space, with the well-known trace condition emerging naturally in the
small-$q$ limit. Applied to twisted MoTe$_2$, the calculated CF phase diagram
matches closely with that from exact diagonalization, and the projected
many-body wavefunctions achieve exceptionally high overlaps with the latter.
Our theory provides both a microscopic understanding and a computationally
efficient tool for identifying fractional Chern insulators.

</details>


### [31] [Angle-resolved photoemission intensity for multi-orbital bands: Complex interplay between the self-energy matrix and the optical matrix elements](https://arxiv.org/abs/2508.03995)
*Yau Chuen Yam,Mona Berciu,George A. Sawayzky*

Main category: cond-mat.str-el

TL;DR: 研究利用单带模型无法有效提取多带系统的自能矩阵，讨论了自能矩阵对ARPES分析的影响。


<details>
  <summary>Details</summary>
Motivation: angler-resolved photoemission spectroscopy (ARPES)分析在理解带结构材料中的电子态中非常重要。然而，当前的分析方法往往假设只存在一个电子态，实际中多带系统可能有多个电子态存在于同一能层附近，导致自能更为复杂，甚至需要考虑矩阵形式的自能。

Method: 该研究使用了一个一维两带模型，考虑电子-声子耦合，来分析多带系统中从单带系统扩展出来的复杂性。研究者通过比较Holstein和Peierls的电子-声子耦合模型，展示了局部和非局部自能矩阵在结果上的差异。

Result: 结果表明，在多带系统中，自能本质上是一个矩阵，而非标量，且ARPES分析结果依赖于多个自能矩阵元素的复杂组合。这些分析可以帮助更好地理解ARPES数据中的贡献因素，有助于改进分析方法。

Conclusion: 结论强调了研究多带系统中自能矩阵的重要性，建议未来研究要更加仔细地处理多带系统的自能结构，并结合矩阵形式的分析方法来提取可靠的信息。

Abstract: We use a simple one-dimensional two-band model with electron-phonon coupling
to illustrate some of the complications that arise in multi-band systems when
trying to extract a self-energy using the typical approach used for single-band
systems when analyzing angle-resolved photoemission spectroscopy (ARPES) data.
The underlying reason is that in multi-band models the self-energy is a matrix,
not a scalar, and the result obtained from the ARPES analysis is a complicated
function of all these self-energy matrix elements, weighted by different dipole
matrix elements of the relevant Wannier orbitals. We contrast the results for
Holstein and Peierls electron-phonon couplings to further illustrate
differences between models with a local versus non-local self-energy matrix.

</details>


### [32] [Symmetric versus antisymmetric strain tuning of the valence transition in Yb(In$_{1-x}$Ag$_x$)Cu$_4$](https://arxiv.org/abs/2508.04212)
*Caitlin I. O'Neil,Michelle Ocker,Kristin Kliemt,Cornelius Krellner,Elena Gati*

Main category: cond-mat.str-el

TL;DR: 研究发现，压应力比斜切应力对价态转变更有用。结果支持价态转变可能引起接近临界点的弹性临界。


<details>
  <summary>Details</summary>
Motivation: 研究价态转变与晶体结构的关系，探索压力如何影响这种转变，有助于理解材料的动态行为和相变特性。

Method: 通过实验和理论分析，使用对称分解法比较压应力和斜切应力对价态转变的影响。

Result: 压应力比斜切应力更有效率，价态转变主要受对称应变影响，从而体积变化。

Conclusion: 价态转变可能与弹性临界相关，预示着材料临界行为的潜在应用。

Abstract: Similar to transitions in a range of correlated quantum materials, the
valence transition exhibits a strong coupling to the crystal lattice, rendering
it highly sensitive to stress tuning. In the present work, we determine the
effect of uniaxial stress, which breaks the lattice symmetry, on the valence
transition temperature and its crossover temperature in pure and Ag-substituted
YbInCu$_4$. Our key result is that hydrostatic stress is more effective in
tuning this transition than uniaxial stress. Based on a symmetry decomposition
of the stress-induced strains, we argue that this observation can be
quantitatively understood, given that the valence transition is mostly
sensitive to symmetric strains and thus volume changes of the lattice. These
results support the notion that the valence transition can give rise to
critical elasticity close to its critical endpoint.

</details>


### [33] [Cooperative Jahn-Teller dynamics of boron clusters in the infrared conductivity of heavy fermion metal CeB6 and unconventional superconductor ZrB12](https://arxiv.org/abs/2508.04238)
*Gennady Komandin,Elena Zhukova,Boris Gorshunov,Andrey Azarevich,Andrey Muratov,Yurii Aleshchenko,Nikolay Sluchanko*

Main category: cond-mat.str-el

TL;DR: 研究了CeB6和ZrB12的频率范围较大的动态导电率和介电函数谱，分离出Drude型和过阻尼激发，发现 JWT动力学在两个材料中都表现明显，并且非平衡电子在传输中起主要作用，支持了局域模式解释。


<details>
  <summary>Details</summary>
Motivation: 研究这些材料的电性质对于理解新奇态物质的形成机制具有重要意义。

Method: 通过频率范围较广的光致放电和共聚粘度测量，分离Drude型和过阻尼激发，分析能量吸收和AND Gunn效应对 Vet Jahn-Teller动力学的影响。

Result:  Drude型和局域激发共存，Drude占比不超过37%在CeB6，23%在ZrB12，局域模式解释了量子 Hall效应 Hall电子数与光求和法则不符的现象。

Conclusion: CeB6和ZrB12中的局域振动主导导电和光学特性，局域模式解释了两相矛盾的电子数结果，未来研究应探索局域振动与异质性之间的关系。

Abstract: A thorough study of the wide-range (40-35000 cm-1) dynamic conductivity and
permittivity spectra of the archetypal heavy fermion metal CeB6 and
unconventional superconductor ZrB12 was carried out at room temperature. Both
the Drude-type components and overdamped excitations were separated and
analyzed. An additional absorption band observed above 200 cm-1 was attributed
to the cooperative Jahn-Teller dynamics of the boron complexes in CeB6 and
ZrB12. It was shown that nonequilibrium electrons participating in the
formation of the collective JT modes dominate in charge transport, and fraction
of Drude-type electrons does not exceed 37% in CeB6 and 23% in ZrB12. We
discuss also the additional Drude-type component in ZrB12 in terms of
far-infrared conductivity from the sliding charge density wave, and suggest the
localized mode scenario reconciles the strong difference between the number of
conduction electrons obtained from the Hall effect and optical sum rule
analysis in CeB6.

</details>


### [34] [Edge modes of topological Mott insulators and deconfined quantum critical points](https://arxiv.org/abs/2508.04455)
*Yuhai Liu,Toshihiro Sato,Disha Hou,Zhenjiu Wang,Wenan Guo,Fakher F. Assaad*

Main category: cond-mat.str-el

TL;DR: 研究发现了在双曲奇点周围存在明确的边缘态，在奇怪超导体和保角群体之间有相变，通过蒙特卡罗模拟和Kane-Mele-Hubbard模型的分析验证，发现边缘态在相变点表现出明锐的特征。


<details>
  <summary>Details</summary>
Motivation: 研究哈JKLMNOP分界点的相变和共存态，和边缘态的演化机制，对于理解拓扑材料和量子相变具有重要意义。

Method: 通过拓扑材料的除非共性相变点构建一个模型，结合实空间重正化群和蒙特卡罗数值模拟方法，研究系统在不同边界条件下的动态行为，特别是相变处的局域化和电荷传导特征。

Result: 在相变点附近表现出明确的长波边缘态和局域化特征，计算得出缺陷电荷迁移率在相变点表现出非典型行为，说明可能存在隐藏的奇点。

Conclusion: 确认了量子相变过程中存在调节指标的突然跳跃，表明相变点具有特殊的奇点，-edge模式的出现与系统维度和流动不变的性质紧密相关。

Abstract: Topology and anomalies lead to edge modes that can interact with critical
bulk fluctuations. To study this setup, pertaining to boundary criticality, we
consider a model exhibiting a deconfined quantum critical point (DQCP) between
a dynamically generated quantum spin Hall state (i.e.a topological Mott
insulator) and an s-wave superconductor. For the topological Mott insulator,
the bulk Goldstone modes are shown to be irrelevant at the helical Luttinger
liquid fixed points. The deconfined quantum critical point is an instance of an
emergent anomaly, and we observe a sharp localized edge state at this point.
The sharpness of the edge mode is consistent with an ordinary phase in which
electronic edge modes decouple from critical edge bosonic fluctuations. At the
DQCP, the scaling dimension of the edge electron shows a jump, a feature argued
to be a signature of the emergent anomaly. Our results are based on large-scale
auxiliary-field quantum Monte Carlo simulations.We also carry out calculations
for the Kane-Mele-Hubbard model to confirm spectral features of the ordinary
and extraordinary-log phases in the vicinity of the bulk critical point.

</details>


<div id='physics.app-ph'></div>

# physics.app-ph [[Back]](#toc)

### [35] [Bioinspired Synergistic Texture and Color Modulation Enabled by Surface Instability of Cholesteric Liquid Crystal Elastomers](https://arxiv.org/abs/2508.03870)
*Xiao Yang,Jay Sim,Wenbin Huang,Ruike Renee Zhao*

Main category: physics.app-ph

TL;DR: Abstract discusses a bilayer made of cholesteric liquid crystal elastomers that can change both texture and color in response to stimuli, with applications in creating dynamic optical materials and intelligent surfaces.


<details>
  <summary>Details</summary>
Motivation: The abstract is about developing advanced materials that use biological inspiration and liquid crystal elastomers to achieve dynamic optical properties, which is a significant advancement in material science and engineering.

Method: The researchers used a bilayer structure of CLCE-LCE materials, employing programmable wrinkling, UV curing, and chemical patterning to control texture and color. They tuned fabrication parameters to achieve desired effects, and used UV curing selectively to permit localized effects.

Result: The bilayer successfully modulates both texture and color through wrinkle morphologies and UV-curing patterns. They also showed applications in dynamic thermal regulation and creating materials with programmable optical responses.

Conclusion: This innovative approach offers a new platform for developing materials with tunable optical and mechanical properties, inspired by biological systems, with potential uses in robotics and intelligent surfaces.

Abstract: Certain cephalopods can dynamically camouflage by altering both skin texture
and color to match their surroundings. Inspired by this capability, we present
a cholesteric liquid crystal elastomer-liquid crystal elastomer (CLCE-LCE)
bilayer capable of simultaneous, reversible modulation of surface texture and
structural color through programmable wrinkling. By tuning the bilayer's
fabrication parameters, on-demand wrinkle morphologies and color combinations
are achieved. Spatially selective UV curing allows localized surface textures,
while chemical patterning of the CLCE layer enables region-specific color
responses, expanding the design space for multifunctional, spatially encoded
optical materials. The CLCE-LCE bilayer enables dynamic thermal regulation by
tuning light absorption through synergistically modulating surface morphology
and color. Notably, this system achieves strain-dependent multiscale encoding
via multistep selective UV curing, revealing distinct visual content under
different applied strains. This work establishes a versatile platform that
merges surface instabilities with tunable structural coloration, advancing
intelligent materials with programmable, strain-responsive surface and optical
properties.

</details>


### [36] [Towards terahertz nanomechanics](https://arxiv.org/abs/2508.03933)
*Jiacheng Xie,Weifeng Wu,Mohan Shen,Patrick Fay,Hong X. Tang*

Main category: physics.app-ph

TL;DR: The paper presents advancements in electromechanical resonators achieving terahertz frequencies via ultrathin piezoelectric films, showing that thinner films can enhance resonant frequencies but also increase acoustic losses, suggesting future work needs to address these challenges.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop high-frequency mechanical resonators for quantum phononics, which require ultralow thermal noise and compact devices. Terahertz frequencies are a step towards such applications but present challenges in miniaturization and material properties.

Method: The study involved reducing the thickness of lithium niobate from 300 nm to 67 nm in multiple stages and fabricating suspended Lamb-wave resonators at each level to measure their resonant frequencies.

Result: The method successfully achieved resonant frequencies as high as 220 GHz, with thinner films increasing the frequency compared to the previous record but also increasing acoustic losses. The findings highlight the trade-off between frequency gains and material losses at sub-100 nm thicknesses.

Conclusion: The work concludes that while thinner films offer frequency enhancements, minimizing surface defects is crucial for future terahertz nanomechanics applications to address the observed losses and improve device performance.

Abstract: Advancing electromechanical resonators towards terahertz frequencies opens
vast bandwidths for phononic signal processing. In quantum phononics,
mechanical resonators at these frequencies can remain in their quantum ground
state even at kelvin temperatures, obviating the need for millikelvin cooling
typically required for GHz resonators. However, electrical actuation and
detection of mechanical motion at such high frequencies present significant
challenges, primarily due to the need for device miniaturization to support
acoustic waves with nanometer-scale wavelengths. One effective strategy is to
aggressively thin down piezoelectric thin films, ideally to a thickness on the
order of the acoustic wavelength, which is in the tens of nanometers. In this
work, we aggressively reduce the thickness of lithium niobate from 300 nm to 67
nm through several stages, and fabricate suspended Lamb-wave resonators at each
thickness level. These resonators achieve resonant frequencies as high as 220
GHz, doubling the previous record and approaching the terahertz frequency
threshold. While ultrathin films exhibit a clear advantage in frequency gains,
they also experience increased acoustic losses. Our results suggest that future
advances in terahertz nanomechanics will critically rely on mitigating surface
defects in sub-100 nm thin films.

</details>


### [37] [Eavesdropping Risk in Terahertz Channels by Covered Wavy Surfaces](https://arxiv.org/abs/2508.04114)
*Peian Li,Wenbo Liu,Jiabiao Zhao,Jiayuan Cui,Yapeng Ge,Qiang Niu,Yuping Yang,Xiangzhu Meng,Jianjun Ma*

Main category: physics.app-ph

TL;DR: The paper discusses how THz channels with covered non-line-of-sight relays pose significant security challenges, showing that covering materials like wallpaper and intimidated the mitigation of eavesdropping, indicating the need for better security measures.


<details>
  <summary>Details</summary>
Motivation: The study aims to address the vulnerabilities and security concerns in THz communications, specifically focusing on non-line-of-sight relays covered with common building materials, which is crucial for next-generation wireless networks.

Method: The research employs an experimental approach, testing THz channel characteristics across various frequencies and materials to evaluate security risks.

Result: The experiments demonstrate that covering with materials such as wallcovering and wall plaster does not eliminate eavesdropping but instead complicates detection, leading to persistent interception scenarios.

Conclusion: The findings highlight the need for advanced security mechanisms tailored for THz systems with covered reflecting surfaces, essential for robust communication networks.

Abstract: Terahertz communications offer unprecedented data rates for next-generation
wireless networks but suffer blockage susceptibility that restrict coverage and
introduce physical-layer security vulnerabilities. Non-line-of-sight relay
schemes using metallic wavy surfaces (MWS) address coverage limitations but
require concealment beneath indoor materials for practical deployment. This
work investigates THz channel characteristics and security vulnerabilities when
MWS surfaces are covered with wallpaper, curtain, and wall plaster across
113-170 GHz. Results reveal that covering materials redistribute rather than
eliminate eavesdropping threats, with persistent feasible interception
scenarios remaining undetectable through conventional backscattering
monitoring. These findings underscore the need for enhanced mechanisms designed
for covered reflecting elements.

</details>


### [38] [X-ray thermal diffuse scattering as a texture-robust temperature diagnostic for dynamically compressed solids](https://arxiv.org/abs/2508.04525)
*P. G. Heighway,D. J. Peake,T. Stevens,J. S. Wark,B. Albertazzi,S. J. Ali,L. Antonelli,M. R. Armstrong,C. Baehtz,O. B. Ball,S. Banerjee,A. B. Belonoshko,C. A. Bolme,V. Bouffetier,R. Briggs,K. Buakor,T. Butcher,S. Di Dio Cafiso,V. Cerantola,J. Chantel,A. Di Cicco,A. L. Coleman,J. Collier,G. Collins,A. J. Comley,F. Coppari,T. E. Cowan,G. Cristoforetti,H. Cynn,A. Descamps,F. Dorchies,M. J. Duff,A. Dwivedi,C. Edwards,J. H. Eggert,D. Errandonea,G. Fiquet,E. Galtier,A. Laso Garcia,H. Ginestet,L. Gizzi,A. Gleason,S. Goede,J. M. Gonzalez,M. G. Gorman,M. Harmand,N. Hartley,C. Hernandez-Gomez,A. Higginbotham,H. Höppner,O. S. Humphries,R. J. Husband,T. M. Hutchinson,H. Hwang,D. A. Keen,J. Kim,P. Koester,Z. Konopkova,D. Kraus,A. Krygier,L. Labate,A. E. Lazicki,Y. Lee,H-P. Liermann,P. Mason,M. Masruri,B. Massani,E. E. McBride,C. McGuire,J. D. McHardy,D. McGonegle,R. S. McWilliams,S. Merkel,G. Morard,B. Nagler,M. Nakatsutsumi,K. Nguyen-Cong,A-M. Norton,I. I. Oleynik,C. Otzen,N. Ozaki,S. Pandolfi,A. Pelka,K. A. Pereira,J. P. Phillips,C. Prescher,T. Preston,L. Randolph,D. Ranjan,A. Ravasio,J. Rips,D. Santamaria-Perez,D. J. Savage,M. Schoelmerich,J-P. Schwinkendorf,S. Singh,J. Smith,R. F. Smith,A. Sollier,J. Spear,C. Spindloe,M. Stevenson,C. Strohm,T-A. Suer,M. Tang,M. Toncian,T. Toncian,S. J. Tracy,A. Trapananti,T. Tschentscher,M. Tyldesley,C. E. Vennari,T. Vinci,S. C. Vogel,T. J. Volz,J. Vorberger,J. T. Willman,L. Wollenweber,U. Zastrau,E. Brambrink,K. Appel,M. I. McMahon*

Main category: physics.app-ph

TL;DR: The paper introduces an improved TDS model using Warren's approach, demonstrating its accuracy with experimental data from compressed copper foils. The model shows robustness against texture variations, making TDS a reliable temperature diagnostic.


<details>
  <summary>Details</summary>
Motivation: The study aims to enhance the accuracy and applicability of x-ray thermal diffuse scattering (TDS) for temperature measurements, particularly in dynamic conditions like compressed materials.

Method: The authors developed a texture-aware TDS model based on Warren's method, comparing it with experimental data obtained from high-energy compressed copper foils at the HED instrument of EuXFEL.

Result: The texture-aware model outperforms conventional methods, shows minimal changes in TDS signals despite sample orientation and compression, and shot-to-shot fluctuations remain low.

Conclusion: TDS proves robust against texture variations, making it a versatile tool for various material samples.

Abstract: We present a model of x-ray thermal diffuse scattering (TDS) from a cubic
polycrystal with an arbitrary crystallographic texture, based on the classic
approach of Warren. We compare the predictions of our model with femtosecond
x-ray diffraction patterns obtained from ambient and dynamically compressed
rolled copper foils obtained at the High Energy Density (HED) instrument of the
European X-Ray Free-Electron Laser (EuXFEL), and find that the texture-aware
TDS model yields more accurate results than does the conventional powder model
owed to Warren. Nevertheless, we further show that: with sufficient angular
detector coverage, the TDS signal is largely unchanged by sample orientation
and in all cases strongly resembles the signal from a perfectly random powder;
shot-to-shot fluctuations in the TDS signal resulting from grain-sampling
statistics are at the percent level, in stark contrast to the fluctuations in
the Bragg-peak intensities (which are over an order of magnitude greater); and
TDS is largely unchanged even following texture evolution caused by
compression-induced plastic deformation. We conclude that TDS is robust against
texture variation, making it a flexible temperature diagnostic applicable just
as well to off-the-shelf commercial foils as to ideal powders.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [39] [The Cost of Nonlocality: A Dynamical Performance Equation of Energy-Entanglement-Complexity](https://arxiv.org/abs/2508.03781)
*HongZheng Liu,YiNuo Tian,Zhiyue Wu*

Main category: quant-ph

TL;DR: This paper focuses on quantifying the physical cost of generating non-local entanglement using energy and local interactions. It unifies concepts like quantum speed limits and Lieb-Robinson bounds to create an energy-entanglement performance equation, linking computational complexity metrics with measurable experimental quantities, thus revealing trade-offs in energy, interaction strength, and efficiency. It provides both a performance benchmark and a diagnostic tool for identifying bottlenecks.


<details>
  <summary>Details</summary>
Motivation: The paper aims to bridge the gap between theoretical quantum limits and experimental observables, particularly in the context of entanglement generation which is crucial for quantum computing tasks.

Method: The authors use a combination of quantum speed limit theory and Lieb-Robinson bounds to derive the performance equation. They introduce a new proxy for computational complexity based on measurable quantities to analyze the interactions and performance trade-offs.

Result: The key result is the formulation of the energy-entanglement performance equation, which connects energy variance, entanglement product, and local interaction strength, demonstrating trade-offs in these factors that influence process efficiency.

Conclusion: The paper successfully provides a framework for linking theoretical quantum principles with practical experimental measurements, offering both a performance benchmark and a diagnostic for identifying entanglement generation bottlenecks in local interaction systems.

Abstract: This work aims to quantify the physical cost of generating non-local
entanglement in systems governed by local interactions. By unifying the quantum
speed limit and Lieb-Robinson bounds, we establish an "energy-entanglement
performance equation." This framework connects theoretical computational
complexity with experimental observables by introducing a measurable proxy for
complexity, thereby revealing a performance trade-off among the "energy
variance-entanglement product," the strength of local interactions, and
dynamical efficiency. Our work not only defines a "performance
frontier"-constrained by theoretical bounds and amenable to experimental
benchmarking-but also provides a novel diagnostic tool for identifying the
performance bottlenecks of a process.

</details>


### [40] [Do GNN-based QEC Decoders Require Classical Knowledge? Evaluating the Efficacy of Knowledge Distillation from MWPM](https://arxiv.org/abs/2508.03782)
*Ryota Ikeda*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: The performance of decoders in Quantum Error Correction (QEC) is key to
realizing practical quantum computers. In recent years, Graph Neural Networks
(GNNs) have emerged as a promising approach, but their training methodologies
are not yet well-established. It is generally expected that transferring
theoretical knowledge from classical algorithms like Minimum Weight Perfect
Matching (MWPM) to GNNs, a technique known as knowledge distillation, can
effectively improve performance. In this work, we test this hypothesis by
rigorously comparing two models based on a Graph Attention Network (GAT)
architecture that incorporates temporal information as node features. The first
is a purely data-driven model (baseline) trained only on ground-truth labels,
while the second incorporates a knowledge distillation loss based on the
theoretical error probabilities from MWPM. Using public experimental data from
Google, our evaluation reveals that while the final test accuracy of the
knowledge distillation model was nearly identical to the baseline, its training
loss converged more slowly, and the training time increased by a factor of
approximately five. This result suggests that modern GNN architectures possess
a high capacity to efficiently learn complex error correlations directly from
real hardware data, without guidance from approximate theoretical models.

</details>


### [41] [Probing and Enhancing the Robustness of GNN-based QEC Decoders with Reinforcement Learning](https://arxiv.org/abs/2508.03783)
*Ryota Ikeda*

Main category: quant-ph

TL;DR: 这项研究使用图卷积网络对量子错误校正进行解码，通过强化学习评估 decoded 的鲁棒性，发现模型存在易受攻击的漏洞并进行对抗训练以提高可靠性和容错能力。


<details>
  <summary>Details</summary>
Motivation: 提升量子计算中错误纠正方法的鲁棒性，特别是在面对潜在的对抗性干扰时，确保量子计算机能够可靠地运作，这至关重要。

Method: 该研究使用图注意力网络（GAT）作为解码器，通过强化学习训练一个对抗的代理（adversary agent）来发现并标记 decoder 中的关键易受漏洞。代理的目标是最小化对错误码修改量的同时，使 decoder 错误分类。研究还展示了通过对抗训练来增强 decoder 的鲁棒性。

Result: 研究得出，使用强化学习发现的易受攻击的特定错误码修改量能够有效提高 decoder 的鲁棒性。总量监督方法结合对抗训练，使 Quantum Error Correcting Codes (QECC) 的容错能力明显提升。特别是，通过对抗训练，模型在应对有lopit noise 和 subtle noise 时表现出更高的解码准确率。此外，这项研究还提供了一种系统性的方法，可以将这种思想扩展到其他类型的神经网络架构，为未来研究提供了一个普遍的框架。

Conclusion: 这项研究提供了一种用于检测和提升量子错误校正解码器鲁棒性的新方法。通过强化学习自动发现潜在的易受攻击漏洞，并通过目标驱动的对抗训练来增强模型的鲁棒性，最终显著提高了 decode 的效率和可靠性。这一发现对于实现可靠、容错性强的量子计算系统至关重要。这表明，结合机器学习和容错编码理论，我们可以更有效地开发出用于大规模量子计算机中的解码技术。未来的研究可以进一步探索其他类型的神经网络架构和去-noise 方法，以进一步提升 Decoder 的鲁棒性和容错能力。此外，这种系统性的框架也有助于理解现有模型的鲁棒性问题，有助于优化现有架构的设计。

Abstract: Graph Neural Networks (GNNs) have emerged as a powerful, data-driven approach
for Quantum Error Correction (QEC) decoding, capable of learning complex noise
characteristics directly from syndrome data. However, the robustness of these
decoders against subtle, adversarial perturbations remains a critical open
question. This work introduces a novel framework to systematically probe the
vulnerabilities of a GNN decoder using a reinforcement learning (RL) agent. The
RL agent is trained as an adversary with the goal of finding minimal syndrome
modifications that cause the decoder to misclassify. We apply this framework to
a Graph Attention Network (GAT) decoder trained on experimental surface code
data from Google Quantum AI. Our results show that the RL agent can
successfully identify specific, critical vulnerabilities, achieving a high
attack success rate with a minimal number of bit flips. Furthermore, we
demonstrate that the decoder's robustness can be significantly enhanced through
adversarial training, where the model is retrained on the adversarial examples
generated by the RL agent. This iterative process of automated vulnerability
discovery and targeted retraining presents a promising methodology for
developing more reliable and robust neural network decoders for fault-tolerant
quantum computing.

</details>


### [42] [Fault-tolerant Fusion-based Quantum Computing with the Four-legged Cat Code](https://arxiv.org/abs/2508.03796)
*Harshvardhan K. Babla,James D. Teoh,Jahan Claes,Daniel K. Weiss,Shraddha Singh,Robert J. Schoelkopf,Shruti Puri*

Main category: quant-ph

TL;DR: The paper introduces a new 2D fault-tolerant architecture for bosonic quantum error correction using the four-legged cat code concatenated with XZZX code, achieving significant performance improvements without complicating hardware requirements.


<details>
  <summary>Details</summary>
Motivation: The paper aims to enhance quantum error correction techniques in bosonic modes, which are critical for quantum computing with continuous variables. Existing methods may not be optimally scalable or may require complex hardware, so the goal is to propose a more efficient and practical architecture.

Method: The authors concatenated the four-legged cat code with the XZZX code using fusion-based error correction. They utilized standard circuit-QED techniques to implement necessary operations. The analytical and numerical methods showed that hardware-level errors are corrected, and the fault tolerance is significantly improved with a doubled fault distance due to residual errors being quadratically suppressed.

Result: The architecture successfully reduces hardware complexity and avoids issues like self-Kerr nonlinearities, achieving better fault tolerance than previous designs.

Conclusion: The proposed 2D architecture provides a scalable and efficient solution for fault-tolerant quantum error correction in bosonic systems, demonstrating practicality for future quantum technologies.

Abstract: The four-legged cat code is a quantum error-correcting code designed to
address the predominant error in bosonic modes: single-photon loss. It was the
first such code to surpass the break-even point, thereby demonstrating the
practical utility of quantum error correction. In this work, we propose a
planar fault-tolerant architecture for this code by concatenating it with the
XZZX code via fusion-based error-correction. To the best of our knowledge, this
is the first 2D nearest-neighbor architecture for fault-tolerant fusion-based
error-correction. We demonstrate how all the required operations, namely
resource state preparation and Bell measurements, can be carried out using
standard circuit-QED techniques, such as intercavity beam-splitter coupling,
cavity displacements, cavity-transmon dispersive coupling, and transmon drives.
We show analytically and numerically that all dominant hardware errors in the
bosonic modes and control ancillae are corrected, to first-order, at the
hardware level. Consequently, the outer XZZX code only needs to address smaller
residual errors, which are quadratically suppressed, effectively doubling the
architecture's fault-distance. Moreover, the performance of our architecture is
not limited by unwanted nonlinearities such as cavity self-Kerr, and it avoids
demanding coupling techniques like $\chi$-matching or high-order coupling.
Overall, our architecture substantially reduces the hardware complexity needed
to achieve fault tolerance with the four-legged cat code.

</details>


### [43] [Graphical Calculus for Fermionic Tensors](https://arxiv.org/abs/2508.03976)
*Yuanjie Ren,Kaifeng Bu,Andreas Bauer*

Main category: quant-ph

TL;DR: The paper introduces a graphical calculus for fermionic many-body physics using fermionic tensors and extends the ZX calculus.


<details>
  <summary>Details</summary>
Motivation: The need for a visual and algebraic framework for complex fermionic systems in quantum computing and condensed matter physics.

Method: Developed fermionic tensors with diagrams, qubits, and fixed odd-parity states, extending ZX calculus.

Result: Represented objects like Gaussian states, Majorana modes, and fermionic codes diagrammatically.

Conclusion: Framework aids in visualizing and computing in fermionic systems, useful for quantum algorithms and simulations.

Abstract: We introduce a graphical calculus, consisting of a set of fermionic tensors
with tensor-network equations, which can be used to perform various
computations in fermionic many-body physics purely diagrammatically. The
indices of our tensors primarily correspond to fermionic modes, but also
include qubits and fixed odd-parity states. Our graphical calculus extends the
ZX calculus for systems involving qubits. We apply the calculus in order to
represent various objects, operations, and computations in physics, including
fermionic Gaussian states, the partial trace of Majorana modes, purification
protocols, fermionization and bosonization maps, and the construction of
fermionic codes.

</details>


### [44] [QPing: a Quantum Ping Primitive for Quantum Networks](https://arxiv.org/abs/2508.03806)
*Jorge Miguel-Ramiro,Jessica Illiano,Francesco Mazza,Alexander Pirker,Julia Freund,Angela Sara Cacciapuoti,Marcello Caleffi,Wolfgang Dür*

Main category: quant-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We introduce the concept of Quantum Ping (QPing) as a diagnostic primitive
for future quantum networks, designed to assess whether two or more end nodes
can establish practical quantum entanglement with efficient resource
consumption, limited overhead, and time-adaptive fidelity thresholds. Unlike
classical ping, which probes network-layer connectivity through ICMP messages,
our proposed quantum version is adapted to the unique features of quantum
networks, where connectivity depends on the availability and quality of shared
entanglement. We develop a formal framework for QPing and leverage different
tools such as sequential hypothesis testing to probe quantum connectivity. We
present several strategies, including active strategies, with path-based and
segment-based variants, and passive strategies that utilize pre-shared
entangled resources. QPing can serve as a flexible diagnostic building block
for quantum networks, designed to work alongside fundamental network
operations, while remaining suitable to different architectural and protocol
design approaches.

</details>


### [45] [Nonreciprocity in Quantum Technology](https://arxiv.org/abs/2508.03945)
*Shabir Barzanjeh,André Xuereb,Andrea Alù,Sander A. Mann,Nikita Nefedkin,Vittorio Peano,Peter Rabl*

Main category: quant-ph

TL;DR: 该论文探讨了非互惠性在量子技术中的重要性，展示了其在低损耗集成器件中的应用，如量子计算、量子网络和传感器中的应用。


<details>
  <summary>Details</summary>
Motivation: 量子技术的快速发展推动了相关研究的深入，非互惠性在其中扮演了关键角色。

Method: 论文介绍了工程非互惠性的方法，并讨论了其在量子计算、量子网络和量子传感器中的具体应用。

Result: 实验结果展示了非互惠性在不同量子技术领域的成功实现和应用潜力。

Conclusion: 非互惠性为量子技术的 next-gen 设备提供了基础，是未来研究和应用的重要方向。

Abstract: Nonreciprocity-the ability to transmit signals in one direction while
blocking them in the reverse-has become a powerful resource in quantum
technologies, enabling directional amplification, routing of quantum
information, and topologically protected quantum states. Recent experimental
advances have demonstrated nonreciprocal behavior in low-loss, fully integrated
devices operating with weak or no magnetic bias, enabled by synthetic gauge
fields, optomechanical interactions, and chiral light-matter coupling. These
achievements overcome the limitations of more traditional approaches, making
nonreciprocity compatible with superconducting circuits and scalable quantum
photonic architectures as well as an integral part of the next generation of
modular quantum computers, distributed quantum networks, and precision
metrology. Here we highlight the key concepts for engineering nonreciprocity in
quantum systems and describe how this functionality can be employed for
high-fidelity qubit readout, robust quantum state transfer, and boosting the
sensitivity of quantum sensors.

</details>


### [46] [One-dimensional quantum droplets under linear gravitational-like trap](https://arxiv.org/abs/2508.03825)
*Saurab Das,Jayanta Bera,Ajay Nath*

Main category: quant-ph

TL;DR: 研究了一维量子气溶滴在恒定和时间依赖的线性引力势下的行为，发现速度主要由引力势决定，可应用于引力测量。不同时间的引力势导致动力学变化，验证过利用纠缠态特性。


<details>
  <summary>Details</summary>
Motivation: 研究量子气溶滴在引力作用下的行为，应用在引力测量和量子传感中。

Method: 在扩展GPE模型中分析气溶滴的波函数，考虑引力势的影响，计算熵和威格纳函数来验证结果。

Result: 引力势大小决定气溶滴速度，时间变化的引力势改变轨迹，纠缠态特性用于高精度测量。

Conclusion: 引力势影响量子气溶滴，可应用于高精度引力测量和量子传感。

Abstract: We investigate the influence of a constant and time-dependent linear
gravitational-like potential on one-dimensional quantum droplets (QDs),
governed by an extended GPE incorporating a repulsive cubic effective
mean-field (EMF) term and an attractive quadratic beyond-mean-field (BMF)
correction. Within a tailored external confinement, we analytically
characterize the QDs wavefunction and derive the effective interaction
contributions. Analogous to classical Newtonian dynamics, the falling velocity
of the droplet within a finite domain is found to depend solely on the strength
of the linear gravitational like potential, remaining independent of both the
total atom number and the magnitude of EMF nonlinearity. When the linear
potential is temporally modulated, deviations in the trajectory of the droplet
emerge relative to the static case, indicating potential applicability in
precision gravimetry. To further probe the dynamical coherence properties, we
compute the Shannon entropy and the Wigner quasi-probability distribution. Both
measures reveal distinct signatures of the constant and time varying linear
potential, with the modulation strength directly influencing the phase-space
localization and coherence structure of the droplet. Numerical simulations
substantiate the stability of the analytical solutions, demonstrating their
robustness. These findings suggest promising implications for quantum sensing
and metrological applications using ultradilute quantum fluids.

</details>


### [47] [Calculating Vibronic Spectra with a linear algorithm based on Gaussian Boson Sampling](https://arxiv.org/abs/2508.03943)
*I. Konyshev,R. Pradip,O. Page,C. Ünlüer,R. T. Nasibullin,V. V. Rybkin,W. Pernice,S. Ferrari*

Main category: quant-ph

TL;DR: The paper introduces a scalable method using Gaussian boson sampling to simulate molecular vibronic spectra with high accuracy.


<details>
  <summary>Details</summary>
Motivation: Simulating molecular vibronic spectra computationally is challenging due to exponential scaling, which this paper aims to overcome.

Method: Uses linear coupling model within Gaussian boson sampling framework; implemented for three approaches: classical simulation with different optical setups using SNSPD and SPAD detectors.

Result: Achieved high fidelity in Franck-Condon profiles; simulations for naphthalene and anthracene systems show accurate reproduction of spectral data.

Conclusion: The method is scalable and accurate, making it suitable for simulating larger molecular systems without requiring additional experimental setups.

Abstract: Accurately simulating molecular vibronic spectra remains computationally
challenging due to the exponential scaling of required calculations. Here, we
show that employing the linear coupling model within the gaussian boson
sampling framework effectively addresses this limitation. We implement the
algorithm for simulating the pentacene molecule through three distinct
approaches, using numerical simulation on a classical computer and
experimentally using two optical setups equipped with different photon
detectors (SNSPD and SPAD). High fidelity $(F>0.999)$ was achieved between the
simulated Franck-Condon profiles and analytically calculated profiles obtained
by enumerating all possible transitions within the linear coupling model.
Furthermore, simulations were performed for larger molecular systems using 48
vibrational modes of naphthalene and 64 vibrational modes of anthracene.
Comparison with experimental data confirms that the simulated spectra
accurately reproduce both the positions and shapes of the measured spectral
bands. A notable advantage of our algorithm is its scalability, requiring only
a fixed minimal set of optical components irrespective of the size of the
studied system.

</details>


### [48] [The Covariant Relativistic Derivation of De Broglie Relation](https://arxiv.org/abs/2508.03908)
*Samuel Bueno Soltau*

Main category: quant-ph

TL;DR: This paper examines the de Broglie relation, tracing its historical roots and deriving it using special relativity. It compares two approaches, highlighting the relativistic method's strength and significance in wave-particle duality. The paper also uses quantum field theory to reinforce its findings.


<details>
  <summary>Details</summary>
Motivation: The paper delves into the foundational aspects of quantum theory, specifically focusing on wave-particle duality and its mathematical underpinnings. It's motivated by the desire to understand the relationship between classical mechanics and quantum mechanics, particularly through the de Broglie relation.

Method: The paper uses a historical approach, tracing the origins of the de Broglie relation, and a comparative method to analyze two derivation approaches: Planck and Einstein's quantum hypotheses versus special relativity-based derivation. The primary method is the four-momentum formalism in special relativity to derive the de Broglie relation.

Result: The covariant derivation in special relativity is found to be more general and conceptually sound, as the paper demonstrates that it provides a solid foundation for wave-particle duality. The comparison shows that the relativistic approach is more robust and indispensable in quantum theory.

Conclusion: The paper concludes that the relativistic derivation of the de Broglie relation is crucial for building a coherent foundation for wave-particle duality, further solidifying its importance in quantum mechanics and quantum field theory.

Abstract: This paper provides an examination of the de Broglie relation, tracing its
historical development from the quantum hypotheses proposed by Planck and
Einstein to its covariant relativistic derivation. The discussion begins by
situating de Broglie's seminal insight within the early framework of quantum
theory. We then reconstruct his original heuristic derivation. The primary
focus of this work, however, is the derivation of the de Broglie relation
directly from the principles of special relativity, employing the four-momentum
formalism. A comparative analysis between the heuristic and relativistic
approaches underscores the universality and conceptual coherence of the latter.
The paper concludes by highlighting the significance of relativistic mechanics
in establishing a consistent foundation for wave-particle duality, further
reinforcing this through a quantum field theoretical perspective.

</details>


### [49] [Hybrid Quantum--Classical Machine Learning Potential with Variational Quantum Circuits](https://arxiv.org/abs/2508.04098)
*Soohaeng Yoo Willow,D. ChangMo Yang,Chang Woo Myung*

Main category: quant-ph

TL;DR: 论文探讨了利用量子计算辅助的经典机器学习模型对液态硅模拟的性能，结果显示在较热环境下的结构与热力学性质可以较精准地被VQC实现的混合模型捕捉，意味着在近期内可能通过量子计算获得性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究者希望在不牺牲精度的前提下，利用量子计算的优势，为液态硅等复杂分子系统提供更高效、更灵活的模拟工具。

Method: 采用了混合量子-经典模型，结合了神经网络和变分量子电路，针对液态硅的密度泛函理论性质进行了分子动力学模拟，将VQC替代了传统的经典消息传递层。

Result: 实验结果证明，在较高温度下，混合模型在捕捉结构和热力学性质方面表现优异，尤其是计算效率提升显著。

Conclusion: 该研究展示了在NISQ硬件下，通过将量子计算引入机器学习模型，可以在材料建模中实现量子计算带来的实际应用价值，为未来量子计算在材料科学中的应用铺平了道路。

Abstract: Quantum algorithms for simulating large and complex molecular systems are
still in their infancy, and surpassing state-of-the-art classical techniques
remains an ever-receding goal post. A promising avenue of inquiry in the
meanwhile is to seek practical advantages through hybrid quantum-classical
algorithms, which combine conventional neural networks with variational quantum
circuits (VQCs) running on today's noisy intermediate-scale quantum (NISQ)
hardware. Such hybrids are well suited to NISQ hardware. The classical
processor performs the bulk of the computation, while the quantum processor
executes targeted sub-tasks that supply additional non-linearity and
expressivity. Here, we benchmark a purely classical E(3)-equivariant
message-passing machine learning potential (MLP) against a hybrid
quantum-classical MLP for predicting density functional theory (DFT) properties
of liquid silicon. In our hybrid architecture, every readout in the
message-passing layers is replaced by a VQC. Molecular dynamics simulations
driven by the HQC-MLP reveal that an accurate reproduction of high-temperature
structural and thermodynamic properties is achieved with VQCs. These findings
demonstrate a concrete scenario in which NISQ-compatible HQC algorithm could
deliver a measurable benefit over the best available classical alternative,
suggesting a viable pathway toward near-term quantum advantage in materials
modeling.

</details>


### [50] [Moveless: Minimizing Overhead on QCCDs via Versatile Execution and Low Excess Shuttling](https://arxiv.org/abs/2508.03914)
*Sahil Khan,Suhas Vittal,Kenneth Brown,Jonathan Baker*

Main category: quant-ph

TL;DR: This paper proposes a specialized quantum error correction compiler for QEC based on QCCD, which reduces physical error and improves logical error rates by exploiting structural regularities of QEC circuits, achieving up to 20× error rate enhancement with realistic physical error rates.


<details>
  <summary>Details</summary>
Motivation: The need for fault-tolerant quantum computing drives the necessity for error correction, and optimizing its implementation for scalable hardware is crucial. The paper addresses compiler optimizations for QEC, seeking effective ways to reduce error rates and improve execution speed on trapped ion systems.

Method: The authors developed a compiler tailored for QEC in QCCD by identifying key structural properties, such as allowingAncilla reuse, dynamic stabilizer execution, and parallel operations within hardware constraints. This method optimizes circuit execution by utilizing Ancillaindistinguishability and flexibly scheduling stabilizer measurements.

Result: The compiler improves QEC execution by 3.38x on average and achieves up to two orders of magnitude in logical error reduction, with realistic physical error rates, making it highly effective for scalable quantum computing architectures.

Conclusion: By exploiting the regularity of QEC circuits, the paper introduces a compiler that significantly enhances the efficiency and reliability of quantum error correction in trapped ion systems, paving the way for more robust large-scale quantum computation.

Abstract: One of the most promising paths towards large scale fault tolerant quantum
computation is the use of quantum error correcting stabilizer codes. Just like
every other quantum circuit, these codes must be compiled to hardware in a way
to minimize the total physical error introduced into the system, for example
either due to high latency execution or excessive gates to meet connectivity
limitations of the target hardware. However, unlike arbitrary quantum circuits,
all syndrome extraction circuits have several common properties, for example
they have a bipartite connectivity graph, consist only of commuting
subcircuits, among other properties. For the most part, compilation methods
have aimed at being generic, able to map any input circuit into executables on
the hardware, and therefore cannot appropriately exploit these properties and
result in executables which have higher physical error. In the case of modular
trapped ion systems, specifically QCCDs, this corresponds to the insertion of
excessive shuttling operations necessary to realize arbitrary qubit
interactions. We propose a compilation scheme explicitly tailored for the
structural regularity of QEC circuits based on several key observations: 1.
only ancilla or data (but not both) should be shuttled, 2. stabilizers can be
executed in any order meaning we can dynamically modify circuit execution on a
per-cycle basis 3. ancilla are indistinguishable meaning any can be selected to
begin a stabilizer measurement and retain a fixed-point mapping between cycles,
and 4. QCCD hardware limits the number of parallel operations equal to the
number traps in the system, meaning fewer ancilla are necessary and can be
reused. Our resulting compiler, leads to QEC circuits which are on average
3.38x faster to execute, and lead to up to two orders of magnitude of
improvement in logical error rates with realistic physical error rates.

</details>


### [51] [Quantum chemistry for solids made simple with the Clifford formalism](https://arxiv.org/abs/2508.03917)
*Amer Alrakik,Gian Luigi Bendazzoli,Stefano Evangelisti,J. Arjan Berger*

Main category: quant-ph

TL;DR: This paper presents a novel method using Clifford torus and periodic Gaussian basis sets for quantum-chemistry calculations of periodic solids, validated through hydrogen chain calculations and shown to work in the thermodynamic limit.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the challenge of performing quantum-chemistry calculations on periodic solids, which has been difficult with existing methods that require direct product configurations and cannot work in the thermodynamic limit.

Method: The method involves modeling solids as Clifford tori, which are both periodic and flat, and introduces a periodic Gaussian basis set compatible with this topology. The approach is tested using a 1D hydrogen chain model with Hartree-Fock and coupled-cluster methods. The thermodynamic limit is achieved by comparing the results to a ring-like calculation, showing the method's validity for studying solids without the need for finite-sized approximations.

Result: The method correctly predicts the ground-state energy in the thermodynamic limit, making it a viable alternative for quantum-chemistry calculations on periodic solids, especially in 3D where other approaches are infeasible.

Conclusion: The insights from this research open up new possibilities for using quantum-chemistry methods on the study of periodic solids. The Clifford formalism simplifies integration with current quantum-chemistry implementations, paves the way for treating extended systems, and provides methodologies for studying the electronic properties of solids without relying on finite-period boundary conditions, thus advancing materials science and condensed matter physics.

Abstract: We present a general theory to treat periodic solids with quantum-chemistry
methods. It relies on two main developments: 1) the modeling of a solid as a
Clifford torus which is a torus that is both periodic and flat and 2) the
introduction of a periodic gaussian basis set that is compatible with the
topology of the Clifford torus. We illustrate our approach by calculating the
ground-state energy of a periodic chain of hydrogen atoms within both
Hartree-Fock and coupled cluster theory. We demonstrate that our approach
yields the correct ground-state energy in the thermodynamic limit by comparing
it to the ground-state energy of a ring of hydrogen atoms in the same limit.
Since equivalent ring-like calculations for three-dimensional solids are
impossible, our approach is an excellent alternative to perform
quantum-chemistry calculations of solids. Our Clifford formalism can be
seamlessly combined with current implementations of quantum-chemistry methods
designed for atoms and molecules to make them applicable to solids.

</details>


### [52] [Charge sensitivity in the transmon regime](https://arxiv.org/abs/2508.03973)
*Rocio Gonzalez-Meza,Vito Iaia,Anika Zaman,Hiu-Yung Wong,Yujin Cho,Kristin Beck,Yaniv J. Rosen*

Main category: quant-ph

TL;DR: 本文指出Transmons尽管对电荷噪声表现出较好的耐受性，但由于依赖于电荷环境的快速变化（如parity switch），其去相位时间T_phi会显著波动，尤其是在E_j/E_c比值较低的区域内，因此在设计和优化时应考虑parity flip率的影响。


<details>
  <summary>Details</summary>
Motivation: Transmons在量子计算中因其耐受电荷噪声的优势被广泛采用，但由于它们在不同设备和同一设备中去相位时间波动大，这种稳定性问题尚未得到充分关注。本文试图通过研究去相位时间与电荷偏置关系以及检测parity switch事件来解决这一问题。

Method: 本文通过模拟和实验两种方式。首先构建T_phi在不同电荷偏置下的模型，研究其依赖关系。然后在实验中使用单次测量方法捕获parity switch事件，结合这类事件对去相位时间进行分析。

Result: 实验证实，在E_j/E_c比值较大时Transmons的T_phi较为稳定，但在比值较低时依赖于电荷偏置变化；引入parity switch检测后，同相位和不同相位下的去相位时间显著不同；令人意外的是即使E_j/E_c较高，去相位时间仍受到parity switch的影响显著.

Conclusion: Transmons在去相位方面并非无残留不敏感性，仅依赖电荷偏置便表现出较好的稳定性；parity switch影响不可忽视，需作为设备参数之一考量。未来应在实验设计中加入parity switch检测，并优化结构以减少去相位时间的变异。

Abstract: Transmons are widely adopted in quantum computing architectures for their
engineered insensitivity to charge noise and correspondingly long relaxation
times. Despite this advantage, transmons often exhibit large fluctuations in
dephasing times across different devices and also within qubits on the same
device. Existing transmon qubits are assumed to be insensitive to charge noise.
However, very little recent attention has been paid to the dependence of
dephasing on the local charge environment. In this study, we see fluctuations
in the dephasing time, $T_{\phi}$, which correlate to charge offset. While
charge offset fluctuations are slow, parity switches are fast processes tied to
the charge offset and can affect $T_{\phi}$ in Ramsey experiments. We implement
a protocol to detect parity switching events using single-shot methods, which
are interleaved within a Ramsey measurement. We find that events that remain in
the same parity state have a higher $T_2$ than measurements averaged over both
parities. Our results show that transmons can be limited by charge-noise, even
with $E_\text{J}/E_\text{C} \approx 50$. Consequently, parity flip rates must
be considered as a device characterization metric.

</details>


### [53] [Efficient detection of spectrally multimode squeezed light through optical parametric amplification](https://arxiv.org/abs/2508.04502)
*Mahmoud Kalash,Ui-Nyung Han,Young-Sik Ra,Maria V. Chekhova*

Main category: quant-ph

TL;DR: This paper demonstrates the first experimental detection of spectrally multimode squeezed states using optical parametric amplification (OPA), achieving simultaneous detection across more than 60 spectral modes with nearly uniform squeezing levels. The results highlight OPA's capability in high-dimensional photonic quantum technologies.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by the potential of OPA in high-dimensional quantum technologies, particularly in overcoming challenges in detecting multimode quantum states.

Method: The authors used OPA to detect the squeezing in a broadband squeezed vacuum state, measuring more than 60 spectral modes and achieving uniform squeezing levels across all modes.

Result: The OPA method successfully detected spectrally multimode squeezing, demonstrating high sensitivity and the ability to handle large numbers of modes simultaneously.

Conclusion: The work extends OPA's applications to spectral detection, enhancing its utility in advanced photonic quantum technologies.

Abstract: Multimode squeezed light is a key resource for high-dimensional photonic
quantum technologies, enabling applications in quantum-enhanced sensing,
quantum communication, and quantum computing. Efficient detection of such a
multimode squeezed state is essential for unlocking its full potential. Optical
parametric amplification (OPA) has recently gained attention as a powerful
technique offering loss-tolerant, direct broadband detection, and multimode
operation. While OPA has been used to characterize spatially multimode
squeezing, its application to spectrally multimode squeezing has not yet been
demonstrated. Here, we report on the first experimental demonstration of
spectrally multimode squeezing detection using OPA. We achieve simultaneous
detection of squeezing across more than 60 spectral modes of a broadband
squeezed vacuum state. The observed squeezing is nearly uniform, ranging from
-6.5 to -7 dB, which makes the source particularly suitable for constructing
continuous-variable cluster states, and indicates the multimode capability of
the OPA. The results extend the capabilities of OPA detection into the spectral
domain, advancing spectral-mode-based high-dimensional photonic quantum
technologies.

</details>


### [54] [A simpler Gaussian state-preparation](https://arxiv.org/abs/2508.03987)
*Parker Kuklinski,Benjamin Rempfer,Kevin Obenland,Justin Elenewski*

Main category: quant-ph

TL;DR: This paper introduces a more efficient method for state-preparing Gaussian distributions, reducing the resource overhead of the Kitaev-Webb algorithm and achieving linear T-depth optimizations.


<details>
  <summary>Details</summary>
Motivation: The paper aims to improve the efficiency of Gaussian state preparation, which is crucial for quantum algorithms, by introducing a new method that reduces resource overhead and optimizes T-depth.

Method: The method uses $n-1$ rotations, $(n-1)(n-2)/2$ two-qubit controlled rotations, and $loor((n-1)/2)$ ancnovation to prepare an $n$-qubit Gaussian state, which is then optimized to have linear T-depth.

Result: The method reduces resource overhead and optimizes T-depth, making Gaussian state preparation more practical for quantum algorithms.

Conclusion: The proposed method makes Gaussian state preparation more efficient and practical for quantum algorithms with reduced resources and optimized T-depth.

Abstract: The ability to efficiently state-prepare Gaussian distributions is critical
to the success of numerous quantum algorithms. The most popular algorithm for
this subroutine (Kitaev-Webb) has favorable polynomial resource scaling,
however it faces enormous resource overheads making it functionally
impractical. In this paper, we present a new, more intuitive method which uses
exactly $n-1$ rotations, $(n-1)(n-2)/2$ two-qubit controlled rotations, and
$\lfloor(n-1)/2\rfloor$ ancilla to state-prepare an $n$-qubit Gaussian state.
We then apply optimizations to the circuit to render it linear in T-depth. This
method can be extended to state-preparations of complex functions with
polynomial phase.

</details>


### [55] [Graph theory-based automated quantum algorithm for efficient querying of acyclic and multiloop causal configurations](https://arxiv.org/abs/2508.04019)
*Salvador A. Ochoa-Oregon,Juan P. Uribe-Ramírez,Roger J. Hernández-Pinto,Selomit Ramírez-Uribe,Germán Rodrigo*

Main category: quant-ph

TL;DR: The paper presents an optimized quantum algorithm for causal structure in high-energy physics using multiloop Feynman diagrams by analogy to clique partitioning, and evaluates it via quantum circuit metrics.


<details>
  <summary>Details</summary>
Motivation: Quantum computing offers potential in exploring complex high-energy physics problems like causal configurations, making this research significant for advancing computational methods in physics analysis.

Method: The MCA algorithm is an automated quantum approach inspired by Minimum Clique Partitioning, employing graph theory for efficient querying of causal structures, evaluated through circuit depth and area.

Result: The MCA algorithm is implemented and its performance in terms of quantum circuit metrics is analyzed, showing potential efficiency improvements over current methods.

Conclusion: The MCA algorithm represents a step forward in applying quantum computing to high-energy physics, suggesting its effectiveness in solving causal structure problems in Feynman diagrams.

Abstract: Quantum algorithms provide a promising framework in high-energy physics, in
particular, for unraveling the causal configurations of multiloop Feynman
diagrams by identifying Feynman propagators with qubits, a challenge analogous
to querying directed acyclic graphs in graph theory. In this paper, we present
the Minimum Clique-optimised quantum Algorithm (MCA), an automated quantum
algorithm designed to efficiently query the causal structures within the
Loop-Tree Duality. The MCA quantum algorithm is optimised by exploiting graph
theory techniques, specifically, by analogy with the Minimum Clique Partition
problem. The evaluation of the MCA quantum algorithm is exhibited by analysing
the transpiled quantum circuit depth and quantum circuit area.

</details>


### [56] [Thermalization with partial information](https://arxiv.org/abs/2508.03993)
*Philippe Faist,Sumeet Khatri*

Main category: quant-ph

TL;DR: 研究了一种新的最大渠道熵原则，用于描述开放量子系统中的动力学，包括热浴和复杂动力学，该原则通过最大化渠道熵来确定系统的动态，替代了传统的方法。


<details>
  <summary>Details</summary>
Motivation: 研究多体系统的动力学行为，尤其是在开放条件下，寻找更一般的框架来描述系统的变化。

Method: 提出了最大渠道熵原则，通过数学推导和微canonical方法的扩展，推导出渠道的结构，并提出了学习算法。

Result: 通过推导，得出了渠道结构，并构造了学习算法;延长了微canonical态的推导到渠道，并证明了新的典型性结果和从输入状态中发现某些约束关系。

Conclusion: 此原则为理解开放系统提供了新的框架，为复杂量子动力学研究提供了理论支持。

Abstract: A many-body system, whether in contact with a large environment or evolving
under complex dynamics, can typically be modeled as occupying the thermal state
singled out by Jaynes' maximum entropy principle. Here, we find analogous
fundamental principles identifying a noisy quantum channel $\mathcal{T}$ to
model the system's dynamics, going beyond the study of its final equilibrium
state. Our maximum channel entropy principle states that $\mathcal{T}$ should
maximize the channel's entropy, suitably defined, subject to any available
macroscopic constraints. These may correlate input and outputs, and may lead to
restricted or partial thermalizing dynamics including thermalization with
average energy conservation. This principle is reinforced by an independent
extension of the microcanonical derivation of the thermal state to channels,
which leads to the same $\mathcal{T}$. Our technical contributions include a
derivation of the general mathematical structure of $\mathcal{T}$, a custom
postselection theorem relating an arbitrary permutation-invariant channel to
nearby i.i.d. channels, as well as novel typicality results for quantum
channels for noncommuting constraints and arbitrary input states. We propose a
learning algorithm for quantum channels based on the maximum channel entropy
principle, demonstrating the broader relevance of $\mathcal{T}$ beyond
thermodynamics and complex many-body systems.

</details>


### [57] [Maximum channel entropy principle and microcanonical channels](https://arxiv.org/abs/2508.03994)
*Philippe Faist,Sumeet Khatri*

Main category: quant-ph

TL;DR: 研究引入了最大通道熵原则，用于构建热通道，并应用于量子计算等多领域。


<details>
  <summary>Details</summary>
Motivation: 该论文将热态从量子态扩展到量子通道，具有重要的理论和应用价值。

Method: 研究者通过凸优化、非交换算子的典型理论、定制后选择方法和舒尔-韦尔对偶性来开发热通道概念。

Result: thermal channels遵循指数形式，并提供了用于量子用语的学习算法。

Conclusion: 热通道的概念为多学科提供了新的分析工具，具有广泛应用前景。

Abstract: The thermal state plays a number of significant roles throughout physics,
information theory, quantum computing, and machine learning. It arises from
Jaynes' maximum-entropy principle as the maximally entropic state subject to
linear constraints, and is also the reduced state of the microcanonical state
on the system and a large environment. We formulate a maximum-channel-entropy
principle, defining a thermal channel as one that maximizes a channel entropy
measure subject to linear constraints on the channel. We prove that thermal
channels exhibit an exponential form reminiscent of thermal states. We study
examples including thermalizing channels that conserve a state's average
energy, as well as Pauli-covariant and classical channels. We propose a quantum
channel learning algorithm based on maximum channel entropy methods that
mirrors a similar learning algorithm for quantum states. We then demonstrate
the thermodynamic relevance of the maximum-channel-entropy channel by proving
that it resembles the action on a single system of a microcanonical channel
acting on many copies of the system. Here, the microcanonical channel is
defined by requiring that the linear constraints obey sharp statistics for any
i.i.d. input state, including for noncommuting constraint operators. Our
techniques involve convex optimization methods to optimize recently introduced
channel entropy measures, typicality techniques involving noncommuting
operators, a custom channel postselection technique, as well as Schur-Weyl
duality. As a result of potential independent interest, we prove a constrained
postselection theorem for quantum channels. The widespread relevance of the
thermal state throughout physics, information theory, machine learning, and
quantum computing, inspires promising applications for the analogous concept
for quantum channels.

</details>


### [58] [Generalized Quantum Hadamard Test for Machine Learning](https://arxiv.org/abs/2508.04065)
*Vivek Mehta,Arghya Choudhury,Utpal Roy*

Main category: quant-ph

TL;DR: 论文提出了一种广义量子Hadamard测试，用于计算有界输入空间中的内积，并将其应用于机器学习模型。


<details>
  <summary>Details</summary>
Motivation: 量子机器学习在量子计算中提升模型性能是一个重要的研究方向。这篇论文关注了量子Hadamard测试在不同输入标准化方法下的应用，扩展了其功能。

Method: 提出了广义量子Hadamard测试，结合了L2正则化和Min-max正则化，并通过数值模拟实现量子电路设计。

Result: 实验结果表明，广义量子Hadamard测试在机器学习模型中表现良好，尤其是在处理有界输入时效率更高。

Conclusion: 该研究推广了量子Hadamard测试的适用性，为量子机器学习模型的实现提供了新方法。

Abstract: Quantum machine learning models are designed for performing learning tasks.
Some quantum classifier models are proposed to assign classes of inputs based
on fidelity measurements. Quantum Hadamard test is a well-known quantum
algorithm for computing these fidelities. However, the basic requirement for
deploying the quantum Hadamard test maps input space to L2-normalize vector
space. Consequently, computed fidelities correspond to cosine similarities in
mapped input space. We propose a quantum Hadamard test with the additional
capability to compute the inner product in bounded input space, which refers to
the Generalized Quantum Hadamard test. It incorporates not only
L2-normalization of input space but also other standardization methods, such as
Min-max normalization. This capability is raised due to different quantum
feature mapping and unitary evolution of the mapped quantum state. We discuss
the quantum circuital implementation of our algorithm and establish this
circuit design through numerical simulation. Our circuital architecture is
efficient in terms of computational complexities. We show the application of
our algorithm by integrating it with two classical machine learning models:
Logistic regression binary classifier and Centroid-based binary classifier and
solve four classification problems over two public-benchmark datasets and two
artificial datasets.

</details>


### [59] [A Lazy Resynthesis Approach for Simultaneous T Gate and Two-Qubit Gate Optimization of Quantum Circuits](https://arxiv.org/abs/2508.04092)
*Mu-Te Lau,Hsiang-Chun Yang,Hsin-Yu Chen,Chung-Yang,Huang*

Main category: quant-ph

TL;DR: 该论文提出了一种高效的 Lazy Resynthesis 技术来优化量子电路中的两比特门的数量，显著减少了 T-计数优化带来的两比特门的增加。结果表明，相比于现有的方法，Lazy Resynthesis 能够减少两比特门的54.8%至68%的开销，并且在运行时相比基表方法提供了高达13.1倍的加速。研究结果表明，该方法不仅提升了基表方法的效率和性能，还比ZX和路径求和方法更加高效和可扩展。


<details>
  <summary>Details</summary>
Motivation: 提升量子计算中的电路效率是关键。当前的T-计数优化虽然有效，但会导致两比特门数量剧增，这对硬件设备的限制较大。因此，寻找有效减少两比特门开销的方法非常必要。

Method: 作者提出了一种 Lazy Resynthesis 技术，适用于现代基表式量子电路优化流程。该技术能够有效抑制T-计数优化中引入的两比特门激增问题。

Result: 实验结果显示，Lazy Resynthesis相比基表、ZX和路径求和方法，分别减少了54.8%、15.3%和68.0%的两比特门开销。同时其运行时间相比基表方法提升了1.81倍，比ZX方法提升了13.1倍，与路径求和方法相当。

Conclusion: Lazy Resynthesis方法显著提升了基表式量子电路优化的效率和性能，是解决两比特门激增问题的有效选择，具有良好的扩展性。

Abstract: State-of-the-art quantum circuit optimization (QCO) algorithms for T-count
reduction often lead to a substantial increase in two-qubit gate count
(2Q-count) -- a drawback that existing 2Q-count optimization techniques
struggle to address effectively. In this work, we propose a novel lazy
resynthesis approach for modern tableau-based QCO flows that significantly
mitigates the 2Q-gate surges commonly introduced during T-count optimization in
Clifford+T circuits. Experimental results show that our approach reduces
2Q-count overhead by 54.8%, 15.3%, and 68.0% compared to tableau-based,
ZX-calculus-based, and path-sum-based QCO algorithms, respectively. In terms of
runtime, our method achieves speedups of 1.81$\times$ and 13.1$\times$ over the
tableau-based and ZX-calculus-based methods, while performing comparably to the
path-sum-based approach. In summary, the proposed lazy resynthesis technique
not only enhances the quality and performance of tableau-based QCO algorithms
but also demonstrates superior efficiency and scalability compared to
alternative QCO approaches such as ZX-calculus and path-sum-based techniques.

</details>


### [60] [Trapping an Atomic Ion without Dedicated Digital-to-analog Converters](https://arxiv.org/abs/2508.04093)
*Ryutaro Ohira,Masanari Miyamoto,Shinichi Morisaka,Ippei Nakamura,Atsushi Noguchi,Utako Tanaka,Takefumi Miyoshi*

Main category: quant-ph

TL;DR: This paper presents a method to control multiple electrodes using fewer DACs and simpler wiring by using TDM. They tested it on a 10-channel system and showed it can be used for trapping a single ion, which is great for scalable quantum systems.


<details>
  <summary>Details</summary>
Motivation: The challenge in controlling quantum devices with many electrodes is a big hurdle for scalable hardware. This paper shows a way to overcome it using TDM, which could be important for quantum computing advancements.

Method: The authors used TDM with a single high-rate DAC to generate control signals for multiple electrodes. They tested a 10-channel system with only two DACs. Real-time imaging confirmed successful ion trapping.

Result: They demonstrated a resource-efficient system requiring fewer DACs and wiring compared to traditional methods, successful in trapping a single ion, which validates the method's effectiveness.

Conclusion: This solution offers a scalable approach for controlling quantum devices, which is significant for advancing quantum computing systems based on trapped ions.

Abstract: Independent control of numerous electrodes in quantum charge-coupled device
architectures presents a significant challenge for wiring and hardware
scalability. To address this issue, we demonstrate a voltage control method
based on time-division multiplexing (TDM). This approach utilizes a single
high-update-rate digital-to-analog converter (DAC) to sequentially generate
control signals for multiple electrodes, thereby reducing both the number of
required DACs and associated wiring. We experimentally validate this concept by
developing a 10-channel system that operates with only two DACs. The developed
TDM-based voltage control system is applied to a surface-electrode trap, where
we successfully trap a single $^{40}\mathrm{Ca}^+$ ion. This approach offers a
resource-efficient and scalable solution for advanced quantum computing systems
based on trapped ions.

</details>


### [61] [Advantages of Co-locating Quantum-HPC Platforms: A Survey for Near-Future Industrial Applications](https://arxiv.org/abs/2508.04171)
*Daigo Honda,Yuta Nishiyama,Junya Ishikawa,Kenichi Matsuzaki,Satoshi Miyata,Tadahiro Chujo,Yasuhisa Yamamoto,Masahiko Kiminami,Taro Kato,Jun Towada,Naoki Yoshioka,Naoto Aoki,Nobuyasu Ito*

Main category: quant-ph

TL;DR: The paper discusses the benefits of co-locating quantum and HPC systems for improving hybrid algorithms and solving large-scale problems.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the unclarity in industrial applications of integrated quantum-HPC platforms by examining specific effects like latency reduction and job scheduling.

Method: The research uses systematic survey methods, focusing on latency, bandwidth, and job scheduling impacts, as well as HPC capability enhancements for hybrid algorithms.

Result: Co-located systems improve hybrid job throughput and enable efficient handling of large-scale problems through HPC resources.

Conclusion: Co-location successfully integrates quantum and HPC for better performance in hybrid applications.

Abstract: We conducted a systematic survey of emerging quantum-HPC platforms, which
integrate quantum computers and High-Performance Computing (HPC) systems
through co-location. Currently, it remains unclear whether such platforms
provide tangible benefits for near-future industrial applications. To address
this, we examined the impact of co-location on latency reduction, bandwidth
enhancement, and advanced job scheduling. Additionally, we assessed how
HPC-level capabilities could enhance hybrid algorithm performance, support
large-scale error mitigation, and facilitate complex quantum circuit
partitioning and optimization. Our findings demonstrate that co-locating
quantum and HPC systems can yield measurable improvements in overall hybrid job
throughput. We also observe that large-scale real-world problems can require
HPC-level computational resources for executing hybrid algorithms.

</details>


### [62] [Dynamic Solutions for Hybrid Quantum-HPC Resource Allocation](https://arxiv.org/abs/2508.04217)
*Roberto Rocco,Simone Rizzo,Matteo Barbieri,Gabriella Bettonte,Elisabetta Boella,Fulvio Ganz,Sergio Iserte,Antonio J. Peña,Petter Sandås,Alberto Scionti,Olivier Terzo,Chiara Vercellino,Giacomo Vitali,Paolo Viviani,Jonathan Frassineti,Sara Marzella,Daniele Ottaviani,Iacopo Colonnelli,Daniele Gregori*

Main category: quant-ph

TL;DR: The paper discusses challenges and solutions for integrating quantum computing into traditional HPC. It proposes a dynamic resource management strategy involving classical and quantum resources, with experiments showing improved efficiency through dynamic allocations.


<details>
  <summary>Details</summary>
Motivation: Using quantum computers as accelerators in HPC is promising, but requires efficient resource management. This paper addresses that gap by providing practical approaches for optimizing resource utilization across hybrid workloads.

Method: The authors present a dynamic resource allocation method involving workflows. They likely designed and tested strategies where classical and quantum resources are dynamically released and reallocated based on computation needs.

Result: Experiments demonstrate that this dynamic approach leads to better efficiency and resource utilization, highlighting its potential for real-world applications.

Conclusion: The work bridges a gap in resource management for HPC-quantum integration, offering practical solutions that can enhance performance in hybrid environments.

Abstract: The integration of quantum computers within classical High-Performance
Computing (HPC) infrastructures is receiving increasing attention, with the
former expected to serve as accelerators for specific computational tasks.
However, combining HPC and quantum computers presents significant technical
challenges, including resource allocation. This paper presents a novel
malleability-based approach, alongside a workflow-based strategy, to optimize
resource utilization in hybrid HPC-quantum workloads. With both these
approaches, we can release classical resources when computations are offloaded
to the quantum computer and reallocate them once quantum processing is
complete. Our experiments with a hybrid HPC-quantum use case show the benefits
of dynamic allocation, highlighting the potential of those solutions.

</details>


### [63] [Challenges in Applying Variational Quantum Algorithms to Dynamic Satellite Network Routing](https://arxiv.org/abs/2508.04288)
*Phuc Hao Do,Tran Duc Le*

Main category: quant-ph

TL;DR: The paper examines the use of quantum algorithms for satellite network routing. It evaluates VQE and QAOA for static routing and QRL for dynamic routing. Simulations show these methods face significant challenges, with static algorithms struggling with even simple routing problems and QRL agents failing to learn effective strategies. The negative results highlight key issues like barren plateaus and instability, suggesting areas where future research could improve quantum algorithms for network routing.


<details>
  <summary>Details</summary>
Motivation: Research into quantum computing applications in network routing is growing; understanding the limitations of current quantum algorithms is crucial for advancing the field.

Method: The study uses simulations of quantum algorithms (VQE, QAOA, QRL) on both static and dynamic network routing problems. It evaluates their performance under ideal, noise-free conditions and identifies challenges such as optimization complexity, learning instability, and the presence of barren plateaus.

Result: The simulations reveal that traditional quantum algorithms struggle with solving even simple routing problems, and basic QRL agents perform no better than random guessing. These findings suggest that more research is needed to overcome algorithmic limitations for practical quantum computing applications.

Conclusion: The paper concludes that while quantum algorithms have potential for network routing, significant challenges exist that require improvement in algorithm design and understanding to achieve real-world advantages.

Abstract: Applying near-term variational quantum algorithms to the problem of dynamic
satellite network routing represents a promising direction for quantum
computing. In this work, we provide a critical evaluation of two major
approaches: static quantum optimizers such as the Variational Quantum
Eigensolver (VQE) and the Quantum Approximate Optimization Algorithm (QAOA) for
offline route computation, and Quantum Reinforcement Learning (QRL) methods for
online decision-making. Using ideal, noise-free simulations, we find that these
algorithms face significant challenges. Specifically, static optimizers are
unable to solve even a classically easy 4-node shortest path problem due to the
complexity of the optimization landscape. Likewise, a basic QRL agent based on
policy gradient methods fails to learn a useful routing strategy in a dynamic
8-node environment and performs no better than random actions. These negative
findings highlight key obstacles that must be addressed before quantum
algorithms can offer real advantages in communication networks. We discuss the
underlying causes of these limitations, including barren plateaus and learning
instability, and suggest future research directions to overcome them.

</details>


### [64] [The decohered ZX-calculus](https://arxiv.org/abs/2508.04296)
*Titouan Carette,Daniela Cojocaru,Renaud Vilmart*

Main category: quant-ph

TL;DR: The paper introduces a fragment of discard ZX-calculus focusing on decohered generators, showing it's universal and complete for affinely supported probability distributions. This helps handle hybrid classical-quantum processes and paves the way for more general probabilistic processes.


<details>
  <summary>Details</summary>
Motivation: Discard ZX-calculus has been studied, but limited work was done on the classical side. This paper explores decohered ZX-calculus to address hybrid processes and probabilistic modeling.

Method: The method involves decohering ZX-calculus generators, establishing a normal form by combining graphical linear algebra and diagrammatic Fourier transforms, aiming to show universality and completeness for certain probability distributions.

Result: The fragment is shown to be universal and complete for affinely supported probability distributions, demonstrating how to handle hybrid classical-quantum processes and providing a basis for more general probabilistic processes.

Conclusion: The study bridges a gap in ZX-calculus by focusing on classical aspects, offering tools for modeling hybrid systems and general probabilistic processes more effectively.

Abstract: The discard ZX-calculus is known to be complete and universal for mixed-state
quantum mechanics, allowing for both quantum and classical processes. However,
if the quantum aspects of ZX-calculus have been explored in depth, little work
has been done on the classical side. In this paper, we investigate a fragment
of discard ZX-calculus obtained by decohering the usual generators of
ZX-calculus. We show that this calculus is universal and complete for affinely
supported probability distributions over $\mathbb{F}_{2}^{n}$. To do so, we
exhibit a normal form, mixing ideas from the graphical linear algebra program
and diagrammatic Fourier transforms. Our results both clarify how to handle
hybrid classical-quantum processes in the discard ZX-calculus and pave the way
to the picturing of more general random variables and probabilistic processes.

</details>


### [65] [Coupling phase enabled level transitions in pseudo-Hermitian magnon-polariton systems](https://arxiv.org/abs/2508.04298)
*Huang Xin,Liu Jingyu,Lin Shirong*

Main category: quant-ph

TL;DR: 论文讨论了腔性和Magnon（磁性）的混合激发，发现传统方法因阻尼问题效率低下， recently引入了可调的外加增益，研究转向平衡耗散的非厄米系统。他们提出一个伪厄米模型，涉及两个Magnon和两个腔模式，通过相位依赖的相互作用耦合。研究能量谱与相位转变的关系，发现了当伪厄米对称性破坏时的例外点，还观察到了能级吸引和排斥现象。能级吸引对应四个转变点，形成双Z形能级结构；排斥对应两个转变点，排斥间隙依赖于耦合相位。最后，在非厄米性和耦合相位定义的相图中，伪厄米对称破坏与耦合模式转变密切相关，为控制混合量子态提供了新策略。


<details>
  <summary>Details</summary>
Motivation: 研究 cavity-magnon 混合激发及其在自旋电子学中的应用，寻求解决耗散问题，探索新方法。

Method: 提出了伪厄米模型，通过相位依赖的相互作用和研究能级转变观察到吸引和排斥现象。

Result: 发现了能级例外点、吸引和排斥现象及其与相位转变的关系，并构建了相图展示了伪厄米对称破坏的动态。

Conclusion: 基于伪厄米模型，提出了控制混合量子态的新策略，有助于实现更长寿命的自旋电子学器件。

Abstract: While cavity-magnon hybridization offers intriguing physics, its practical
implementation is hindered by intrinsic damping in both cavity and magnon
modes, leading to short coherence times and constrained applications. Recently,
with the emergence of tunable external gain at the macroscopic scale, the
research focus has shifted from purely lossy systems to gain-loss balanced
non-Hermitian systems. Here, we propose a pseudo-Hermitian model with two
magnon and two cavity modes coupled via phase-dependent interaction. We link
the energy spectrum to phase transitions, observing exceptional points when
pseudo-Hermitian symmetry breaks. We also observed level attraction and level
repulsion. The former corresponds to four phase transitions and manifests as a
double Z-shaped energy spectrum, the latter corresponds to two phase
transitions, with the repulsive gap depending on the coupling phase. In the
phase diagram defined by non-Hermiticity and coupling phase, we reveal a
distinctive correspondence: pseudo-Hermitian symmetry breaking is intrinsically
linked to coupling mode transitions, enabling new strategies for controlling
hybrid quantum states in spintronic systems.

</details>


### [66] [Quantum Advantage in Identifying the Parity of Permutations with Certainty](https://arxiv.org/abs/2508.04310)
*Arnau Diebra,Santiago Llorens,David González-Lociga,Albert Rico,John Calsamiglia,Mark Hillery,Emili Bagan*

Main category: quant-ph

TL;DR: The paper demonstrates a quantum advantage in determining the parity of an unknown permutation with a specific number of particles, using fewer resources than classical methods without any oracles or contrived setups.


<details>
  <summary>Details</summary>
Motivation: Understanding quantum computational advantages in specific tasks is critical for advancing quantum computing, especially for practical applications in cryptography, algorithm design, and beyond. This paper focuses on a fundamental quantum computing task, demonstrating quantum supremacy in parity determination.

Method: The researchers used entangled states to achieve the task, relying on quantum mechanics' principles like superposition and entanglement to reduce the required number of distinguishable states per particle. They proved that with at least sqrt(n) distinguishable states, perfect parity identification is possible, whereas below this threshold, it's limited to classical guessing probabilities.

Result: The study shows that quantum mechanics can determine the parity of a permutation with certainty using only sqrt(n) distinguishable states per particle, a number much lower than classical approaches. This quantum advantage is significant for n ≥ 3, providing a clear example of quantum supremacy in a practical computational task.

Conclusion: This breakthrough offers a solid foundation for future quantum algorithms and computations, highlighting that quantum systems can perform specific tasks more efficiently than classical counterparts without relying on complex oracles or impractical assumptions, thus making quantum advantage more accessible and tangible in real-world applications.

Abstract: We establish a sharp quantum advantage in determining the parity (even/odd)
of an unknown permutation applied to any number $n \ge 3$ of particles.
Classically, this is impossible with fewer than~$n$ labels, being the success
limited to random guessing. Quantum mechanics does it with certainty with as
few as $\lceil \sqrt{n}\, \rceil$ distinguishable states per particle, thanks
to entanglement. Below this threshold, not even quantum mechanics helps: both
classical and quantum success are limited to random guessing. For small $n$, we
provide explicit expressions for states that ensure perfect parity
identification. We also assess the minimum entanglement these states need to
carry, finding it to be close to maximal, and even maximal in some cases. The
task requires no oracles or contrived setups and provides a simple, rigorous
example of genuine quantum advantage.

</details>


### [67] [Hydrodynamic Effects in Cryogenic Buffer Gas Cells: Design Insights from Hybrid Simulations](https://arxiv.org/abs/2508.04364)
*Nick Vogeley,Bernd Bauerhenne,Daqing Wang*

Main category: quant-ph

TL;DR: The paper examines the performance of a cryogenic buffer gas beam cell with a spherical geometry, particularly focusing on hydrodynamic effects like vortex formation and their impact on helium buffer gases. They used numerical simulations and experiments to find that vortex creation enhances molecule extraction when certain parameters are met.


<details>
  <summary>Details</summary>
Motivation: The motivation behind the paper is to address the need for improved cryogenic beam sources, which are crucial for cold molecular beam experiments. The current challenge is optimizing these sources with limited numerical studies due to complex parameter ranges.

Method: The method employed includes steady-state slip-flow simulations using Hydrodynamic Discrete Boltzmann Equation for helium buffer gas and Direct Simulation Monte Carlo for particle trajectories. The simulations are compared across different buffer gas throughputs and injection angles to analyze performance and identify optimal parameter regimes.

Result: The results demonstrate that vortex formation in the spherical cell enhances molecule extraction under specific parameter conditions, allowing the effects to be verified experimentally via velocity and time-of-flight measurements.

Conclusion: The conclusion is that the optimized spherical cryogenic buffer gas beam cell design, accounting for hydrodynamic effects and optimal parameter selections, can enhance the efficiency and performance of cold molecular beam experiments, offering a promising approach for future beam source improvements.

Abstract: Cryogenic buffer gas beam sources have become an essential tool for
experiments requiring cold molecular beams with low forward velocities.
Although recent experimental advances have led to significant progress in
source optimization, numerical studies remain limited due to the challenges
posed by the large parameter ranges required to describe both the dense buffer
gas and the dilute seed molecules. In this work, we report a numerical
evaluation of cryogenic buffer gas beam cells operating in the hydrodynamic
extraction regime. While most prior studies focused on box-like or cylindrical
cells, we investigated hydrodynamic effects including vortex formation in a
spherical cell and assessed whether these could be utilized to enhance the
performance in molecule cooling and extraction. To achieve this, we performed
steady-state slip-flow simulations for helium buffer gas and employed a
direct-simulation Monte Carlo diffusion routine to track particle trajectories.
We compared the performance of the source across different buffer gas
throughputs and injection angles and identified parameter regimes where vortex
formation enhances molecule extraction. From the simulations, we extracted
experimental observables, which allow these effects to be verified through
velocity or time-of-flight measurements on the molecular beam.

</details>


### [68] [Universal Configuration for Optimizing Complexity in Variational Distributed Quantum Circuits](https://arxiv.org/abs/2508.04464)
*J. Montes,F. Borondo,Gabriel G. Carlo*

Main category: quant-ph

TL;DR: Distributed quantum computing presents a promising approach for scaling quantum processors, but the optimal circuit distribution configuration remains a challenge. This paper demonstrates the existence of a universal optimal configuration based on a complexity measure using Markov matrices and validates it with the majorization criterion. The findings could significantly improve the efficiency and scalability of quantum computing systems.


<details>
  <summary>Details</summary>
Motivation: The paper addresses a critical challenge in quantum computing - achieving scalability through distributed architecture. Identifying the optimal configuration is essential for maximizing circuit complexity while minimizing communication depth, which directly impacts the efficiency of quantum processors. The study introduces a novel approach using Markov matrices to prove the existence of an optimal configuration, providing a theoretical foundation for designing scalable quantum systems.

Method: The authors employ a rigorous mathematical approach, utilizing Markov matrices and complexity measures based on the convergence rate toward the Haar measure, to derive their findings. They combine analytical proofs with numerical simulations using the majorization criterion to validate their results, ensuring both theoretical robustness and practical applicability.

Result: The key result is the proof of a universal optimal configuration for distributed quantum circuits, supported by numerical evidence. This configuration optimally balances circuit complexity and communication efficiency, offering a pathway to enhance the scalability and performance of quantum computing systems.

Conclusion: This research provides a significant advancement in understanding the optimal distribution of quantum circuits in distributed quantum computing architectures. By establishing a universal optimal configuration, the study paves the way for future advancements in the scalability and performance of quantum systems, which is crucial for the development of large-scale quantum computing technologies. The insights are valuable for both hardware design and algorithm optimization in quantum computing.

Abstract: Distributed quantum computing represents at present one of the most promising
approaches to scaling quantum processors. Current implementations typically
partition circuits into multiple cores, each composed of several qubits, with
inter-core connectivity playing a central role in ensuring scalability.
Identifying the optimal configuration -- defined as the arrangement that
maximizes circuit complexity with minimal depth -- thus constitutes a
fundamental design challenge. In this work, we demonstrate, both analytically
and numerically, the existence of a universal optimal configuration for
distributing single and two qubit gates across arbitrary intercore
communication topologies in variational distributed circuits. Our proof is
based on a complexity measure based on Markov matrices, which quantifies the
convergence rate toward the Haar measure, as introduced by Weinstein et al.
Finally, we validate our predictions through numerical comparisons with the
well established majorization criterion proposed in Ref 2.

</details>


### [69] [Simulation and Benchmarking of Real Quantum Hardware](https://arxiv.org/abs/2508.04483)
*T. Piskor,M. Schöndorf,M. Bauer,D. Smith,T. Ayral,S. Pogorzalek,A. Auer,M. Papič*

Main category: quant-ph

TL;DR: 研究论文讨论了量子计算中的噪声问题，提出了一个适用于超级量子计算机的噪声模型，并通过模拟进行了验证，结果显示模型精度有所提升。


<details>
  <summary>Details</summary>
Motivation: 量子计算在Noisy Intermediate-Scale Quantum (NISQ)时代面临噪声干扰，如何建模和预测噪声对算法性能的影响是关键。这篇论文提出了噪声模型，评估了其准确性，结果发现模型性能得到改善，对实际应用有帮助。

Method: 论文的方法包括构建一个适用于超级量子计算的噪声模型，并通过模拟20个量子位的系统进行验证。比较了该模型与其他文献中的方法，在模拟中发现模型预测精度更高。

Result: 通过模拟，测试了该模型的有效性，结果显示模型预测的准确性有所提高。

Conclusion: 论文表明，建设可靠的量子计算机需要细致的噪声建模和仿真研究，以优化算法并减少误差。提出了一个有效的噪声模型，能够更好地预测量子计算的表现并指导硬件改进。特别是在超级量子计算机中，该模型验证了更高的预测精度，有助于提升算法的可靠性和性能。未来的研究应进一步探索如何将该模型应用到其他类型的量子硬件架构中，为更广泛的量子计算应用场景提供支持。

Abstract: The effects of noise are one of the most important factors to consider when
it comes to quantum computing in the noisy intermediate-scale quantum computing
(NISQ) era that we are currently in. Therefore, it is important not only to
gain more knowledge about the noise sources appearing in current quantum
computing hardware in order to suppress and mitigate their contributions, but
also to evaluate whether a given quantum algorithm can achieve reasonable
results on a given hardware. To accomplish this, we need noise models that can
describe the real hardware with sufficient accuracy. Here, we present a noise
model that has been evaluated on superconducting hardware platforms and could
be adapted to other common architectures such as trapped-ion or neutral atom
devices. We then benchmark our model by simulating a 20-qubit superconducting
quantum computer, and compare the accuracy of our model to similar approaches
from the literature and demonstrate an improvement in the overall prediction
accuracy.

</details>


### [70] [Quantum circuit complexity and unsupervised machine learning of topological order](https://arxiv.org/abs/2508.04486)
*Yanming Che,Clemens Gneiting,Xiaoguang Wang,Franco Nori*

Main category: quant-ph

TL;DR: This paper bridges quantum circuit complexity with unsupervised machine learning for topological order in quantum materials, proposing new kernels for clustering quantum phases, outperforming classical methods and connecting quantum concepts with machine learning tools.


<details>
  <summary>Details</summary>
Motivation: The paper aims to exploit the connection between Kolmogorov complexity and unsupervised ML, leveraging it for understanding quantum topological order using quantum circuit complexity as a framework.

Method: They establish quantum circuit complexity theorems relating to fidelity and entanglement change, use these to create new kernel measures for unsupervised clustering, and validate through numerical experiments on various quantum systems.

Result: The kernels outperform existing classical methods in clustering quantum phases, including topological orders from Kitaev's code and random states.

Conclusion: The approach effectively merges quantum computation concepts with machine learning to analyze and classify quantum phases, providing a new practical toolset for quantum many-body systems analysis.

Abstract: Inspired by the close relationship between Kolmogorov complexity and
unsupervised machine learning, we explore quantum circuit complexity, an
important concept in quantum computation and quantum information science, as a
pivot to understand and to build interpretable and efficient unsupervised
machine learning for topological order in quantum many-body systems. To span a
bridge from conceptual power to practical applicability, we present two
theorems that connect Nielsen's quantum circuit complexity for the quantum path
planning between two arbitrary quantum many-body states with fidelity change
and entanglement generation, respectively. Leveraging these connections,
fidelity-based and entanglement-based similarity measures or kernels, which are
more practical for implementation, are formulated. Using the two proposed
kernels, numerical experiments targeting the unsupervised clustering of quantum
phases of the bond-alternating XXZ spin chain, the ground state of Kitaev's
toric code and random product states, are conducted, demonstrating their
superior performance. Relations with classical shadow tomography and shadow
kernel learning are also discussed, where the latter can be naturally derived
and understood from our approach. Our results establish connections between key
concepts and tools of quantum circuit computation, quantum complexity, and
machine learning of topological quantum order.

</details>


### [71] [Benchmarking Quantum and Classical Sequential Models for Urban Telecommunication Forecasting](https://arxiv.org/abs/2508.04488)
*Chi-Sheng Chen,Samuel Yen-Chi Chen,Yun-Cheng Tsai*

Main category: quant-ph

TL;DR: 该研究比较了经典和量子启发式模型在预测单变量短信活动(SMS-in)时间序列中的表现。研究采用米兰电信活动数据集作为数据源，并对五个不同的模型进行了评估，包括LSTM、量子LSTM、量子自适应注意力、量子接收ance加权关键值方法和量子快速权重模型。实验结果表明，不同模型对序列长度的敏感度不同，量子改进并非适用于所有情况。量子增强的有效性取决于具体的任务和架构设计，反映了模型规模、参数化策略和时序建模能力之间的内在权衡。


<details>
  <summary>Details</summary>
Motivation: 研究者可能希望了解传统机器学习模型和量子启发式模型在时间序列预测中的相对表现，特别是在短信活动数据上的应用。这可能由于量子计算在某些任务中表现出色，尽管目前仍处于实验阶段。

Method: 该研究采用了传统的LSTM模型作为基准，然后开发了基于量子启发的五个变体模型，分别在不同长度的输入序列上进行了比较。实验数据来自 Milan Telecommunication Activity Dataset，模型的预测能力在不同序列长度下进行了评估。

Result: 不同模型对不同长度的输入序列表现出不同的预测效果，量子启发模型在某些特定情况下可能提供优势，但在其他情况下则没有显著提升。这表明量子改进不是万能的，而是取决于模型设计和任务的具体性。

Conclusion: 研究结论指出，量子启发式的增强效果并不是在所有情况下都显著优于经典模型，且其效果因任务和架构的不同而有所变化。因此，在时间序列预测中，传统的LSTM模型仍然表现出强大的适用性。此外，进一步研究如何优化量子模型的架构以更广泛地提高其预测性能可能是有必要的。

Abstract: In this study, we evaluate the performance of classical and quantum-inspired
sequential models in forecasting univariate time series of incoming SMS
activity (SMS-in) using the Milan Telecommunication Activity Dataset. Due to
data completeness limitations, we focus exclusively on the SMS-in signal for
each spatial grid cell. We compare five models, LSTM (baseline), Quantum LSTM
(QLSTM), Quantum Adaptive Self-Attention (QASA), Quantum Receptance Weighted
Key-Value (QRWKV), and Quantum Fast Weight Programmers (QFWP), under varying
input sequence lengths (4, 8, 12, 16, 32 and 64). All models are trained to
predict the next 10-minute SMS-in value based solely on historical values
within a given sequence window. Our findings indicate that different models
exhibit varying sensitivities to sequence length, suggesting that quantum
enhancements are not universally advantageous. Rather, the effectiveness of
quantum modules is highly dependent on the specific task and architectural
design, reflecting inherent trade-offs among model size, parameterization
strategies, and temporal modeling capabilities.

</details>


### [72] [Efficient classical computation of the neural tangent kernel of quantum neural networks](https://arxiv.org/abs/2508.04498)
*Anderson Melchor Hernandez,Davide Pastorello,Giacomo De Palma*

Main category: quant-ph

TL;DR: 该论文提出了一种高效的经典算法来估计量子神经网络的神经切线核（NTK），并展示了其在量子计算中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究者们已经深入研究了量子神经网络的高效性，尤其是通过神经切线核来理解这些网络的行为。该论文旨在开发一种高效的方法来计算NTK，从而评估量子神经网络是否能够提供量子优势。

Method: 论文提出了一个基于经典算法的方法，将初始化参数的平均计算简化为四个离散值的平均，从而高效模拟量子神经网络。这种方法结合了量子计算的理论，特别是将宽量子神经网络与高斯过程等价的观点。

Result: 通过该方法，作者展示了如何高效计算宽量子神经网络的期望输出，进而得出结论：这些网络无法实现量子优势。

Conclusion: 该研究填补了量子神经网络高效性分析的空白，证明了其在量子计算领域不具备优势。因此，对于潜在的量子计算应用，量子神经网络不可靠。这为未来的研究提供了重要的指导。

Abstract: We propose an efficient classical algorithm to estimate the Neural Tangent
Kernel (NTK) associated with a broad class of quantum neural networks. These
networks consist of arbitrary unitary operators belonging to the Clifford group
interleaved with parametric gates given by the time evolution generated by an
arbitrary Hamiltonian belonging to the Pauli group. The proposed algorithm
leverages a key insight: the average over the distribution of initialization
parameters in the NTK definition can be exactly replaced by an average over
just four discrete values, chosen such that the corresponding parametric gates
are Clifford operations. This reduction enables an efficient classical
simulation of the circuit. Combined with recent results establishing the
equivalence between wide quantum neural networks and Gaussian processes
[Girardi \emph{et al.}, Comm. Math. Phys. 406, 92 (2025); Melchor Hernandez
\emph{et al.}, arXiv:2412.03182], our method enables efficient computation of
the expected output of wide, trained quantum neural networks, and therefore
shows that such networks cannot achieve quantum advantage.

</details>


### [73] [Entanglement distribution in quantum networks via swapping of partially entangled states](https://arxiv.org/abs/2508.04536)
*Henrique Guerra,Tailan S. Sarubi,Rafael Chaves,Jonas Maziero*

Main category: quant-ph

TL;DR: The paper explores entanglement swapping in quantum networks with various topologies, focusing on partial entanglement and success probabilities.


<details>
  <summary>Details</summary>
Motivation: Understanding entanglement distribution in quantum networks with initial partial entanglement is key for robust communication. This paper extends the protocol to different network topologies, aiming to provide practical guidelines for communication strategies.

Method: The study uses quantum state transformations under Bell measurements for different network configurations, evaluating success probabilities.

Result: The paper reveals how entanglement dynamics differ across network types and offers design guidelines for maximizing entanglement distribution despite initial partial states.

Conclusion: By analyzing ESP in networks with linear, star, and hybrid topologies, the paper enhances our understanding of entanglement distribution and provides strategies for improving communication in realistic quantum networks.

Abstract: The entanglement swapping protocol (ESP) is a fundamental primitive for
distributing quantum correlations across distant nodes in a quantum network.
Recent studies have demonstrated that even when the involved qubit pairs are
only partially entangled, it is still possible to concentrate and transmit
entanglement via Bell-basis measurements. In this work, we extend these ideas
to quantum networks with various topologies - including linear, star, and
hybrid configurations - by analyzing the application of the ESP to initially
partially entangled states. We investigate how entanglement evolves under such
protocols by examining the transformations of the initial states and evaluating
the success probabilities for generating maximally entangled states at the
output. Our results offer new insights into the dynamics of the entanglement
distribution in quantum networks and provide practical guidelines for designing
robust quantum communication strategies under realistic conditions.

</details>


### [74] [Spectro-temporally tailored Non-Gaussian Quantum Operations in Thin-Film Waveguides](https://arxiv.org/abs/2508.04578)
*Peter Namdar,Patrick Folge,Carlos E. Lopetegui,Silia Babel,Benjamin Brecht,Christine Silberhorn,Valentina Parigi*

Main category: quant-ph

TL;DR: The paper presents a novel method using thin-film lithium niobate waveguides for mode-selective non-Gaussian quantum operations in telecom wavelength, demonstrating high-fidelity operations essential for quantum networks.


<details>
  <summary>Details</summary>
Motivation: Advancements in photonic platforms enable precise light control, crucial for scalable quantum systems. This work aims to address mode-selective non-Gaussian quantum operations in telecom, which are essential for next-gen quantum photonic networks.

Method: The method involves designing waveguide-based platforms for single-photon subtraction and addition using an inverse-design optimization scheme with Joint Spectral Amplitude and Transfer Function modeling. They tested on metallic and thin-film waveguides with dispersion engineering.

Result: The approach achieves high-fidelity non-Gaussian operations through tailored nonlinear processes like parametric down- and up-conversion.

Conclusion: This work provides a scalable solution for photonic quantum networks by demonstrating reliable non-Gaussian operations in telecom wavelength using their optimized waveguide platforms.

Abstract: Advancements in photonic platforms have enabled the precise control of
light's spectral and temporal degrees of freedom, a capability crucial for the
development of scalable quantum information systems. In this work, we address
the challenge of implementing spectro-temporal mode-selective non-Gaussian
quantum operations, specifically single-photon subtraction (SPS) and addition
(SPA), in the telecom wavelength regime. Building on prior experimental
demonstrations of mode-selective near-infrared SPS, we present the first design
framework for achieving mode-selective SPA and SPS using thin-film lithium
niobate nonlinear waveguide platforms. We introduce an inverse-design
optimization scheme by modeling the quantum-optical response via the Joint
Spectral Amplitude and Transfer Function, in order to identify optimal
waveguide and pump parameters that maximize mode selectivity and state purity.
This approach is first tested on a metallic waveguide design. We then exploit
the dispersion engineering capabilities of thin-film waveguides, which offer
enhanced nonlinear interactions through tighter light confinement. Our findings
demonstrate that tailored nonlinear processes, particularly parametric
down-conversion and frequency up-conversion, can support high-fidelity
non-Gaussian operations essential for next-generation quantum photonic
networks.

</details>


### [75] [Optimizing quantum transport via the quantum Doob transform](https://arxiv.org/abs/2508.04622)
*Dolores Esteve,Carlos Pérez-Espigares,Ricardo Gutiérrez,Daniel Manzano*

Main category: quant-ph

TL;DR: 研究提出了一种通过系统生成元的单对角化方法，在量子网络中优化传输特性，结合广义Doob变换经典网络优化，展示了在保持物理特征不变的前提下，可以显著提升传输效率。


<details>
  <summary>Details</summary>
Motivation: 量子输运在量子技术开发中有重要作用，如何优化其传递特性成为关键问题，该研究提供了一种新的优化方法。

Method: 该研究基于最近的广义Doob变换在经典网络优化的成果，引入了单对角化方法，同时兼顾系综和耗散贡献，优化传输相关指标。

Result: 研究展示了该方法在提升传输性能方面有效性，计算的最优性能来自对相干和非相干动力学的非平凡调整，并且该优化过程保持了系统的特定物理特征。

Conclusion: 该研究开发了量子网络传输优化的高效方法，拓展了经典网络优化的思路，而这种优化方法在实际应用中具有广泛潜力。

Abstract: Quantum transport plays a central role in both fundamental physics and the
development of quantum technologies. While significant progress has been made
in understanding transport phenomena in quantum systems, methods for optimizing
transport properties remain limited, particularly in complex quantum networks.
Building on recent advances in classical network optimization via the
generalized Doob transform, we introduce a novel method that extends this
approach to quantum networks. Our framework leverages a single diagonalization
of the system generator to efficiently tailor both the Hamiltonian and
dissipative contributions, optimizing transport observables such as currents
and activities. We demonstrate the method's effectiveness through extensive
numerical explorations, showing that optimal performance arises from
non-trivial modifications to both coherent and incoherent dynamics. We also
assess the robustness of the optimization under constraints that preserve
specific physical features, such as fixed dissipative structures and
input-output interactions. Finally, we discuss the connection between optimized
transport and centrosymmetry, highlighting the relevance of this property for
enhanced transport efficiency in quantum systems.

</details>


### [76] [Experimental device-independent certification of indefinite causal order](https://arxiv.org/abs/2508.04643)
*Dengke Qu,Quan Lin,Lei Xiao,Xiang Zhan,Peng Xue*

Main category: quant-ph

TL;DR: The paper demonstrates a device-independent method to verify indefinite causal order in quantum mechanics using entangled photons, achieving a significant statistical violation of the causal inequality.


<details>
  <summary>Details</summary>
Motivation: Quantum mechanics allows for indefinite causal orders, which are not possible in classical physics, and this paper provides a method to verify such orders experimentally without needing to know the device details.

Method: The authors used spacelike-separated entangled photons in a quantum switch, with one photon acting as a control qubit and the other as an observer. They performed local measurements and statistics to violate the causal inequality.

Result: They observed a 24 standard deviation violation of the causal inequality, demonstrating the feasibility of device-independent certification.

Conclusion: This work provides evidence for a device-independent method, opening new possibilities in quantum information processing related to indefinite causal orders.

Abstract: Understanding the physical world fundamentally relies on the assumption that
events are temporally ordered, with past events serving as causes for future
ones. However, quantum mechanics permits events to occur in a superposition of
causal orders, providing new types of quantum resources for quantum information
tasks. Previous demonstrations of indefinite causal order have relied on a
process known as quantum switch and depended on specific assumptions about the
devices used in the laboratory. Recently, a theoretical scheme for the
certification of indefinite causal order in the quantum switch has been
obtained solely from the output statistics of the devices, analogous to the
device-independent proofs of nonlocality through violations of the Bell
inequality. Here, we report an experimental verification of the causal
inequality using spacelike-separated entangled photons, where one photon
functions as the control qubit in a quantum switch and the other serves as an
additional observer. Through local measurement statistics, we observe a
violation of the causal inequality by 24 standard deviations. This work
provides evidence for a device-independent certification of indefinite causal
order, relying solely on observed correlations without requiring device
characterization. Our results pave the way toward a complete understanding of
indefinite causal order and its potential applications in quantum information
processing.

</details>


### [77] [Cybersecurity of Quantum Key Distribution Implementations](https://arxiv.org/abs/2508.04669)
*Ittay Alfassi,Ran Gelles,Rotem Liss,Tal Mor*

Main category: quant-ph

TL;DR: 这项研究提出了一系列工具和方法，将经典的漏洞分析、术语和概念引入量子密钥分发（QKD）的实施安全中，从而填补了这一领域的空白。研究者开发了量子漏洞分析、“量子全方位攻击”以及“量子旁路攻击”等方法，用于分析现有QKD攻击方法。实验表明，虽然余辉攻击（Bright Illumination）仅需有限设备知识，但仍能被完整构造。这些工具有效地提高了QKD产品的实现安全性，并增强了其在实际系统中的实用性。


<details>
  <summary>Details</summary>
Motivation: 随着QKD在更多实际应用中的推进，确保其实现实现的安全性变得至关重要。现有的经典漏洞分析方法可能无法完全适应或描述量子实施中的漏洞，因此开发新的分析工具和方法成为必要。

Method: 研究者使用了将经典术语与量子漏洞相结合的方法，设计了三个创新工具：量子漏洞分析、量子全方位攻击和量子旁路攻击，用于评估和构造QKD攻击。此外，还引入了量子侧道攻击的量子化定义，使其与经典类型区分开来。

Result: 研究利用新工具分析了多种现有QKD攻击，证明余辉攻击仅需有限设备知识即可被完整构造，从而强调了理论安全协议在实现层面的标准漏洞的存在。

Conclusion: 这项研究为量子密钥分发的实施安全提供了前所未有的工具，填补了经典漏洞分析和量子领域之间的空白。通过结合经典术语和量子方法，该研究有效地提升了QKD产品的实现安全性，并展现了其在实际系统中应用的实用价值。

Abstract: Practical implementations of Quantum Key Distribution (QKD) often deviate
from the theoretical protocols, exposing the implementations to various attacks
even when the underlying (ideal) protocol is proven secure. We present new
analysis tools and methodologies for quantum cybersecurity, adapting the
concepts of vulnerabilities, attack surfaces, and exploits from classical
cybersecurity to QKD implementation attacks. We present three additional
concepts, derived from the connection between classical and quantum
cybersecurity: "Quantum Fuzzing", which is the first tool for black-box
vulnerability research on QKD implementations; "Reversed-Space Attacks", which
are a generic exploit method using the attack surface of imperfect receivers;
and a concrete quantum-mechanical definition of "Quantum Side-Channel Attacks",
meaningfully distinguishing them from other types of attacks. Using our tools,
we analyze multiple existing QKD attacks and show that the "Bright
Illumination" attack could have been fully constructed even with minimal
knowledge of the device implementation. This work begins to bridge the gap
between current analysis methods for experimental attacks on QKD
implementations and the decades-long research in the field of classical
cybersecurity, improving the practical security of QKD products and enhancing
their usefulness in real-world systems.

</details>


### [78] [A probabilistic quantum algorithm for Lyapunov equations and matrix inversion](https://arxiv.org/abs/2508.04689)
*Marcello Benedetti,Ansis Rosmanis,Matthias Rosenkranz*

Main category: quant-ph

TL;DR: 摘要中的量子概率算法用于准备混合态，适用于解Lyapunov方程，期望次数较低。


<details>
  <summary>Details</summary>
Motivation: 研究混合态准备和Lyapunov方程求解的量子算法，目的是提升计算效率。

Method: 基于Zhang等人的工作，引入了带停机规则的量子算法，优化了期望次数。

Result: 算法在解Lyapunov方程时期望次数较低，适用于矩阵加权和的近似。

Conclusion: 该算法提供了高效解决相关问题的新方法。

Abstract: We present a probabilistic quantum algorithm for preparing mixed states
which, in expectation, are proportional to the solutions of Lyapunov equations
-- linear matrix equations ubiquitous in the analysis of classical and quantum
dynamical systems. Building on previous results by Zhang et al.,
arXiv:2304.04526, at each step the algorithm either returns the current state,
applies a trace non-increasing completely positive map, or restarts depending
on the outcomes of a biased coin flip and an ancilla measurement. We introduce
a deterministic stopping rule which leads to an efficient algorithm with a
bounded expected number of calls to a block-encoding and a state preparation
circuit representing the two input matrices of the Lyapunov equations. We also
consider approximating the normalized inverse of a positive definite matrix $A$
with condition number $\kappa$ up to trace distance error $\epsilon$. For this
special case the algorithm requires, in expectation, at most $\lceil
\kappa\ln(1/\epsilon) \rceil+1$ calls to a block-encoding of $\sqrt{A/\|A\|}$.
This matches the optimal query complexity in $\kappa$ and $\epsilon$ of the
related, but distinct, quantum linear system solvers. In its most general form,
the algorithm generates mixed states which approximate matrix-valued weighted
sums and integrals.

</details>


<div id='physics.chem-ph'></div>

# physics.chem-ph [[Back]](#toc)

### [79] [H$_2$O and CO$_2$ sorption in ion exchange sorbents: distinct interactions in amine versus quaternary ammonium materials](https://arxiv.org/abs/2508.03909)
*Golnaz Najaf Tomaraei,Sierra Binney,Ryan Stratton,Houlong Zhuang,Jennifer L. Wade*

Main category: physics.chem-ph

TL;DR: 研究比较了两种阳离子交换阴离子载体材料在H₂O和CO₂吸附性能方面的差异，发现带(QA)基团的载体在CO₂分离中表现更好，但其热分解特性限制了热再生的可能性，而采用低温MoS水分解法有效恢复其吸附能力。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过分子建模、热分析以及气体分析等方法评估两种阳离子载体材料在CO₂分离中的性能，尤其适用于直接空气捕获中的低能量分离需求。

Method: 通过热重分析、热力学分析、气体动态分析和分子建模评估两种载体材料的吸附特性，比较它们在不同温度下的失活情况以及水分解过程中的能量变化。

Result: QA基团的阳离子载体在与CO₂和H₂O的吸附强度更高，但在中温下容易失活，而采用低温水分解再生路径使其再生能力得到恢复。此外，水分解过程中的CO₂释放和吸收表现出水分管理的独立性，有助于降低整体能量消耗。

Conclusion: 综合结果表明，QA基团阳离子交换阴离子载体在CO₂分离中展现出显著优势，其优势在于强大的电静力吸引力和其水分解路径的可行解决方案 " hybrid(低温)水分解再生 "。这一发现为直接空气捕获提供了新的阴离子交换材料选择。

Abstract: This study investigates the H$_2$O and CO$_2$ sorption behavior of two ion
exchange sorbents: a primary amine and a permanently charged strong base
quaternary ammonium (QA) groups with (bi)carbonate counter-anions. We compare
their distinct interactions with H$_2$O and CO$_2$ through simultaneous thermal
gravimetric, calorimetric, gas analysis and molecular modeling to evaluate
their performance for dilute CO$_2$ separations like direct air capture.
Thermal and hybrid (heat + low-temperature hydration) desorption experiments
demonstrate that the QA-based sorbent binds both water and CO$_2$ more strongly
than the amine counterparts but undergoes degradation at moderate temperatures,
limiting its compatibility with thermal swing regeneration. However, a
low-temperature moisture-driven regeneration pathway at is uniquely effective
for the QA-based sorbent. To inform the energetics of a moisture-based CO$_2$
separation, we compare calorimetric water sorption enthalpies to isosteric
enthalpies. To our knowledge, this includes the first direct measurement of
water sorption enthalpy in the QA-based sorbent. Molecular modeling supports
this observation, showing higher water sorption energies and denser charge
distributions in the QA-based sorbent. Mixed gas experiments in QA-based
sorbent show that not only does water influence CO$_2$ binding, but CO$_2$
influences water uptake through counterion-dependent hydration states, and that
moisture swing responsiveness in this material causes hydration-induced CO$_2$
release and drying-induced CO$_2$ uptake, an important feature for low-energy
CO$_2$ separation under ambient conditions. Overall, the two classes of
sorbents offer distinct pathways for CO$_2$ separation. Primary amine-based
sorbent relies on weaker hydrogen bonding and CO$_2$-amine interactions, while
QA-based sorbent leverages stronger electrostatic coupling between water and
QA-reactive anion pairs.

</details>


### [80] [Constructing Generalized Sample Transition Probabilities with Biased Simulations](https://arxiv.org/abs/2508.03977)
*Yanbin Wang,Jakub Rydzewski,Ming Chen*

Main category: physics.chem-ph

TL;DR: 研究论文提出了一种新的方法，GSTP，用于从有偏抽样数据中恢复无偏的转移概率和动力学信息。该方法利用核密度估计生成势能面的局部焓和转移概率，通过广义分裂技术处理时间分辨率与空间分辨率之间的问题，避免了需要指定核函数的传统扩散图方法。在单自由度谐振子、 Alanine dipeptide 和 met-enkephalin 系统中，GSTP 的结果与无偏数据一致，证明了其有效性。该方法为复杂系统中的动力学分析提供了一种通用框架。


<details>
  <summary>Details</summary>
Motivation: 在分子动力学模拟中，通过有偏抽样加速过程时，传统的动力学信息计算方法，如扩散图，遇到了挑战。为了更直观地分析动力学过程，如识别反应路径和计算反应速率，需要计算状态之间的转移概率。因此，开发一种能够从有偏分布中恢复无偏转移概率和动力学信息的新方法，对于科学发现和工程应用都具有重要意义。

Method: 该研究采用了核密度估计的方法，基于势能面的局部焓和转移概率，结合广义分裂技术，来解决时间分辨率和空间分辨率的权衡问题。他们选择了三个模型系统进行了验证：单自由度谐振子、 Alanine dipeptide 和在溶剂中共存的 met-enkephalin 系统。

Result: 实验结果表明，在三个模型系统中，GSTP 的计算结果与无偏数据进行比较，得到了一致的结果，证明了该方法的有效性和准确性。

Conclusion: 该研究提出了一种通用的方法 GSTP，能够从有偏分布中恢复无偏的转移概率、主动力学特征和网络结构，显著地减少了对现有计算资源的依赖，并且为分析更复杂系统中的动力学过程提供了便利。这种将传统动力学分析技术和机器学习工具相结合的方法，为解决动力学分析中的良好抽样平衡问题提供了一种创新的思路。因此，该方法在化学、生物学和材料科学等领域具有广泛的应用潜力。

Abstract: In molecular dynamics (MD) simulations, accessing transition probabilities
between states is crucial for understanding kinetic information, such as
reaction paths and rates. However, standard MD simulations are hindered by the
capacity to visit the states of interest, prompting the use of enhanced
sampling to accelerate the process. Unfortunately, biased simulations alter the
inherent probability distributions, making kinetic computations using
techniques such as diffusion maps challenging. Here, we use a coarse-grained
Markov chain to estimate the intrinsic pairwise transition probabilities
between states sampled from a biased distribution. Our method, which we call
the generalized sample transition probability (GSTP), can recover transition
probabilities without relying on an underlying stochastic process and
specifying the form of the kernel function, which is necessary for the
diffusion map method. The proposed algorithm is validated on model systems such
as a harmonic oscillator, alanine dipeptide in vacuum, and met-enkephalin in
solvent. The results demonstrate that GSTP effectively recovers the unbiased
eigenvalues and eigenstates from biased data. GSTP provides a general framework
for analyzing kinetic information in complex systems, where biased simulations
are necessary to access longer timescales.

</details>


### [81] [Benchmarking electronic-structure methods for the description of dark transitions in carbonyls at and beyond the Franck-Condon point](https://arxiv.org/abs/2508.04606)
*Jasmine Bone,Javier Carmona-García,Daniel Hollas,Basile F. E. Curchod*

Main category: physics.chem-ph

TL;DR: The paper evaluates several electronic-structure methods for describing dark transitions, particularly for molecules with carbonyl groups, and assesses their performance beyond the Franck-Condon point.


<details>
  <summary>Details</summary>
Motivation: The motivation is to understand how electronic-structure methods handle dark transitions, which are important for photochemistry, especially for molecules like atmospheric VOCs.

Method: The methods include various DFT and correlated techniques tested on 16 carbonyl-containing VOCs, evaluating their performance at equilibrium and beyond.

Result: The paper finds some methods perform well, while others show discrepancies, affecting photolysis half-life predictions.

Conclusion: Electronic-structure methods have varying accuracies for dark transitions; thus, selecting the right method is critical for accurate photolysis studies.

Abstract: Herein, we propose a comprehensive benchmark of electronic-structure methods
to describe dark transitions, that is, transitions to excited electronic states
characterized by a near-zero oscillator strength. This type of electronic state
is particularly important for the photochemistry of molecules containing
carbonyl groups, such as atmospheric volatile organic compounds (VOCs). The
oscillator strength characterizing a dark transition can change dramatically by
a slight alteration of the molecular geometry around its ground-state
equilibrium, the so-called non-Condon effects. Hence, testing the performance
of electronic-structure methods for dark transitions requires considering
molecules at their Franck-Condon point (i.e., equilibrium geometry), but also
beyond the Franck-Condon point. Our benchmark focuses on various
electronic-structure methods - LR-TDDFT(/TDA), ADC(2), CC2, EOM-CCSD, CC2/3,
XMS-CASPT2 - with CC3/aug-cc-pVTZ serving as a theoretical best estimate. These
techniques are tested against a set of 16 carbonyl-containing VOCs at their
equilibrium geometry. We then assess the performance of these methods to
describe the dark transition of acetaldehyde beyond its Franck-Condon point by
(i) distorting the molecule towards its S$_1$ minimum energy structure and (ii)
sampling an approximate ground-state quantum distribution for the molecule and
calculating photoabsorption cross-sections within the nuclear ensemble
approach. Based on the calculated cross-sections, we calculate the photolysis
half-life as depicted by the different electronic-structure methods -
highlighting the impact of the different electronic-structure methods on
predicted experimental photolysis observables.

</details>


### [82] [Variational free complement method with Gaussian complements](https://arxiv.org/abs/2508.04635)
*Cong Wang*

Main category: physics.chem-ph

TL;DR: 研究通过复制FC方法中的补函数，通过分解塞特拉轨道的高斯展开来构造，并用氦基态验证了准确性。


<details>
  <summary>Details</summary>
Motivation: 研究者希望验证FC方法在计算量子力学中的有效性，特别是通过补函数进行分析。

Method: 研究者通过分解塞特拉轨道（Slater orbitals）和塞特拉泛函（Slater geminals）的高斯展开式来构造补函数。

Result: 研究者使用氦基态进行了验证，结果显示补函数适用于FC方法的准确性。

Conclusion: 研究者得出结论，FC方法中的补函数构造方法有效且适用于复杂的量子体系。

Abstract: The complement functions in the free complement (FC) method are constructed
by decontracting the Gaussian expansions of the Slater orbitals and the Slater
geminals in the $g$ functions. The helium ground state is used to demonstrate
the accuracy.

</details>


### [83] [MARTINI-based force fields for predicting gas separation performances of MOF/polymer composites](https://arxiv.org/abs/2508.04672)
*Cecilia M. S. Alvares,Rocio Semino*

Main category: physics.chem-ph

TL;DR: The study investigates how the shape and size of MOF nanoparticles affect gas separation in ZIF-8/PVDF materials using computer simulations. Simulations show that smaller nanoparticles allow for better separation and that rhombic dodecahedron nanoparticles perform better than cubic ones. The research highlights the potential of using computer modeling to understand gas adsorption at the nanoparticle level, which can be applied to high-throughput methods for better experimental correlation.


<details>
  <summary>Details</summary>
Motivation: The paper addresses a gap in understanding the impact of MOF nanoparticle morphology and size on gas separation applications, aiming to provide insights through computer simulations. This is significant because MOFs are widely used in gas separation, yet their behavior at the nanoparticle level hasn't been systematically studied.

Method: Coarse-grained simulations were used to study gas adsorption in ZIF-8/PVDF at the nanoparticle level. The study examined different morphologies (cubic and rhombic dodecahedron) and sizes of nanoparticles, as well as the adsorption of CO2, N2, and CH4 across various extensions of both the nanoparticle and polymer phases.

Result: The simulations corroborate the expected preference for CO2 over N2 and CH4. Smaller nanoparticles showed better separation performance at ambient conditions, with rhombic dodecahedron nanoparticles outperforming cubic ones. The study emphasizes the utility of particle-based modeling for gas adsorption analysis and suggests the integration of such methods into high-throughput frameworks to align experimental outcomes more effectively.

Conclusion: The research provides a foundational understanding of how nanoparticle morphology and size influence gas separation in MOF/polymer composites. It highlights the potential of computational modeling to predict and optimize material properties, paving the way for further advancements in gas separation technologies using MOFs.

Abstract: MOF/polymer composites have been widely investigated in the past decade for
gas separation applications. However, the impact of MOF nanoparticle morphology
and size in gas separation have not yet been systematically studied by computer
simulation techniques. In this work, coarse grained simulations are deployed to
study gas adsorption in ZIF-8/PVDF at the nanoparticle level. Nanoparticles of
different morphologies and sizes are explored, and adsorption of CO2, N2 and
CH4 is investigated throughout the extension of the bulk and surface of the
nanoparticle as well as of the polymer phase. Results reproduce the expected
preference for CO2 over the other two gasses. Nanoparticles of smaller sizes
provide better separation performance at ambient conditions, while rhombic
dodecahedron nanoparticles perform better than cubic ones. This work presents a
perspective on the merits and limitations of modelling gas adsorption in
MOF/polymer composites at the nanoparticle level via particle-based coarse
graining approaches, and provides a methodological set-up which can be
integrated into high-throughput schemes, bringing us closer to reaching time-
and length scales that can be directly compared with experimental data.

</details>


<div id='nlin.CD'></div>

# nlin.CD [[Back]](#toc)

### [84] [Forecasting chaotic dynamic using hybrid system](https://arxiv.org/abs/2508.03707)
*Michele Baia,Tommaso Matteuzzi,Franco Bagnoli*

Main category: nlin.CD

TL;DR: This paper addresses parameter estimation challenges in chaotic systems, introducing a hybrid method combining neural networks with simulated systems. Results show improved predictability in chaotic systems similar to real-world atmosphere models.


<details>
  <summary>Details</summary>
Motivation: Understanding and predicting chaotic systems is crucial for various applications, especially when only partial information is available. This paper aims to enhance predictability by combining neural networks with simulated systems.

Method: The hybrid approach combines neural networks with simulated systems to refine parameter estimation and improve synchronization between simulated and actual dynamics.

Result: Testing on low-dimensional chaotic systems derived from atmospheric models shows enhanced predictability.

Conclusion: The proposed hybrid method offers a promising solution for improving predictability in chaotic systems with partial information, with potential applications in atmospheric models.

Abstract: The literature is rich with studies, analyses, and examples on parameter
estimation for describing the evolution of chaotic dynamical systems based on
measurements, even when only partial information is available through
observations.
  However, parameter estimation alone does not resolve prediction challenges,
particularly when only a subset of variables is known or when parameters are
estimated with significant uncertainty. In this paper, we introduce a hybrid
system specifically designed to address this issue. The method involves
training an artificial intelligent system to predict the dynamics of a measured
system by combining a neural network with a simulated system. By training the
neural network, it becomes possible to refine the model's predictions so that
the simulated dynamics synchronize with the actual system dynamics.
  After a brief contextualization of the problem, we introduce the hybrid
approach employed, describing the learning technique and testing the results on
two chaotic systems inspired by atmospheric dynamics in measurement contexts.
Although these systems are low-dimensional, they encompass all the fundamental
characteristics and predictability challenges that can be observed in more
complex real-world systems.

</details>


### [85] [Gradient of the Adiabatic Gauge Potential in Classical Systems](https://arxiv.org/abs/2508.03804)
*Nathan Rose,Nachiket Karve,David K. Campbell*

Main category: nlin.CD

TL;DR: The paper discusses the adiabatic gauge potential in classical systems and proposes a method to compute its gradient efficiently, showing it reproduces expected results in simple systems and relates to chaos in more complex ones.


<details>
  <summary>Details</summary>
Motivation: Understanding the adiabatic gauge potential in classical systems could lead to better insights into how quantum-like phase space transformations manifest classically, especially in systems moving between integrable and chaotic regimes.

Method: The authors propose using classical computing techniques to calculate the gradient of the AGP, focusing on efficient computation methods that maintain the structure of canonical transformations.

Result: The method successfully computes the AGP's gradient in simple systems and shows divergence related to Lyapunov times in chaotic systems, aligning with theoretical expectations.

Conclusion: Computing the AGP's gradient provides a bridge between quantum and classical adiabatic transformations, offering new tools for studying phase space dynamics in both contexts.

Abstract: The adiabatic gauge potential (AGP) is the generator of unitary
transformations which preserve the eigenbasis of a quantum Hamiltonian under
parametric variation. While its usefulness in quantum mechanics has been
thoroughly demonstrated in recent years, less attention has been given to its
behavior in classical systems, where the AGP is a phase space function and its
gradient defines special canonical transformations. In this paper we propose an
efficient method to compute the gradient of the AGP as a classical function. We
demonstrate that the obtained canonical transformation reproduces expected
results for simple orbits and integrable systems for which the adiabatic limit
is well-defined. In chaotic systems the gradient diverges in a way that is
related to Lyapunov times.

</details>


<div id='cond-mat.quant-gas'></div>

# cond-mat.quant-gas [[Back]](#toc)

### [86] [Dynamical generation of geometric squeezing in interacting Bose-Einstein condensates](https://arxiv.org/abs/2508.04126)
*Li Chen,Fei Zhu,Zheng Tang,Liang Zeng,Jae Joon Lee,Han Pu*

Main category: cond-mat.quant-gas

TL;DR: 该研究探讨了旋转谐振子势中非相互作用和相互作用玻色爱因斯坦凝聚（BEC）在频率快速变位后的行为，发现非相互作用情况下会发生几何压缩，而相互作用情况下不会出现压缩，而是周期性振荡。通过引入高效平衡机制，提出了通过动态调节方法来增强压缩效果的新方案。


<details>
  <summary>Details</summary>
Motivation: 研究的关键在于理解BEC在外部势能快速变化时的行为，特别是在不同相互作用情况下的量子涨缩效应，这对量子信息存储和量子计算有重要应用价值。

Method: 研究使用了理论分析和数值模拟相结合的方法，通过对坐标变换和Heisenberg方程的推导，分析了系统的动力学行为，发现影响压缩效果的主导因素，并提出了动态平衡方法。

Result: 研究发现，非相互作用条件下压缩效果显著，而相互作用下则不会出现压缩。通过动态平衡方法，能够显著提升压缩效率，所需时间远小于传统方法。

Conclusion: 该研究提出了利用动态平衡机制增强几何压缩的新思路，对BEC热力学行为和量子信息存储均有重要参考价值。

Abstract: When the rotating frequency of a non-interacting Bose-Einstein condensate
(BEC) confined in a weak anisotropic harmonic potential is suddenly quenched to
its trapping frequency, the condensate evolves from its ground state to a
single-mode squeezed state with exponentially growing quantum fluctuation
anisotropy. Such a squeezed state is called the geometrically squeezed state.
However, for interacting BECs with two-body collisions, a similar quench only
results in quantum fluctuations oscillating periodically without squeezing. In
this work, we identify superfluid stability as the key factor behind this
non-squeezing phenomenon, with the periodic oscillations arising from
collective excitations of a stable collective excitation mode. By strategically
breaking the stability criteria, we propose a dynamical approach for generating
squeezing that can exponentially suppress quantum fluctuations in a relatively
short time, surpassing the efficiency of existing experimental preparation
schemes.

</details>


### [87] [Four-mode quantum sensing and Fisher information in a spin-orbit-coupled Bose gas](https://arxiv.org/abs/2508.04140)
*Fei Zhu,Zheng Tang,Liang Zeng,Shu Wang,Li Chen*

Main category: cond-mat.quant-gas

TL;DR: 研究利用多模 squeezed 状态和纠缠资源在量子 metrology 中的重要性。研究对象是带有自旋轨道耦合的自旋-1/2 Bose-Einstein 气体，上文对两态系统的研究受到了限制。本文构建了一个四个态的模型，基于 Lie 代数 su(4)，该系统共有六个 SU(2) 子空间。使用自旋压缩参数和量子 Fisher 信息矩阵分析了相干自旋态的动态演化。结果表明，在多态模型中，自旋轨道耦合导致了更丰富的纠缠增强传感器的表现，能够达到 Heisenberg 极限。跨不同 SU(2) 子空间的方向选择可以通过调节单一系统参数（Ramannabbsi 频率）来实现。捕捉到关键信息：多态模型、Heisenberg 极限、entanglement 能否。主结论是构建四态模型增加了传感器性能。还有方向选择的能力。


<details>
  <summary>Details</summary>
Motivation: 研究量子 metrology 和传感中的关键资源，如 squeezed 状态和纠缠，有助于提升传感器性能。构建多态模型可能为更复杂的量子系统提供更好的工具，从而提高测量精度。

Method: 研究利用了 Lie 代数 su(4)，构造四态模型，分析了两初态和多模耦合的情况。计算了自旋压缩参数和量子 Fisher 信息矩阵，模拟了相干自旋态的动态演化。比较了多态与两态结果，以展示改进的性能。

Result: 多态系统中，自旋轨道耦合导致了更丰富的纠缠增强传感器的表现，实现了Heisenberg极限。通过调节单个参数可以优化测量方向。

Conclusion: 自旋轨道耦合的四态系统可以显著提升量子传感性能，实现Heisenberg极限。调节参数有助于选择测量方向，为实际应用提供了灵活的解决方案。

Abstract: Multi-mode squeezing and entanglement are important resources in quantum
metrology and sensing. For spin-1/2 Bose-Einstein condensates subject to
spin-orbit coupling (SOC), previous studies on spin squeezing have been limited
to two-mode systems. In this work, we demonstrate that such a system can
naturally construct a four-mode model spanning an $\mathfrak{su}(4)$ algebra
with six SU(2) subspaces. Using spin squeezing parameters and quantum Fisher
information matrices, we analyze the dynamical evolution of coherent spin
states. The results show that, beyond two-mode models, the SOC-induced
four-mode couplings give rise to richer entanglement-enhanced sensing
approaching the Heisenberg limit across various SU(2) subspaces. Additionally,
by tuning a single system parameter (the Raman Rabi frequency), one can
selectively control the optimal measurement directions across different
subspaces.

</details>


### [88] [Anomalous Doppler effect in two-component Bose-Einstein condensates](https://arxiv.org/abs/2508.04398)
*Tomasz Zawiślak,Sandro Stringari,Alessio Recati*

Main category: cond-mat.quant-gas

TL;DR: Two-component Bose-Einstein condensates with persistent currents and inter-species interactions show a unique Doppler shift effect. They used superfluid hydrodynamics to predict this effect, explain why experiments are hard but propose a protocol based on density response functions and Gross-Pitaevskii equations.


<details>
  <summary>Details</summary>
Motivation: Interesting phenomenon involving quantum gases and their properties under external conditions. The possibility of persistent currents and inter-component interactions adds a layer of complexity to the usual behavior of Bose-Einstein condensates.

Method: Analytic predictions through superfluid hydrodynamics; experimental protocol suggested using density-density response and coupled Gross-Pitaevskii equations.

Result: Theoretical analysis shows anomalous Doppler shifts, but experiments aren't done yet. Protocol for measuring Doppler shifts using density response and simulations with Gross-Pitaevskii equations.

Conclusion: This research paves the way for experiments to confirm the theoretical predictions, enhancing our understanding of quantum gases with persistent flows and interactions.

Abstract: We show that two-component Bose-Einstein condensed mixtures, in presence of a
persistent current, exhibit a non trivial Doppler shift of the sound
velocities. The peculiarity is due to the inter-species interaction and the
possibility of generating a counter-flow persistent current. Analytic
predictions are derived by using superfluid hydrodynamics. While the existence
of anomalous Doppler shifts at finite temperature has been discussed a long
time ago in the case of superfluid Helium-4, an experimental verification of
the effect is still missing. For this reason, we also propose a protocol for
the measurement of the Doppler shifts, based on the density-density response
function. The dynamical protocol is simulated by means of coupled
Gross-Pitaevskii equations.

</details>


### [89] [Reentrant topology and reverse pumping in a quasiperiodic flux ladder](https://arxiv.org/abs/2508.04452)
*Sanchayan Banerjee,Rajashri Parida,Tapan Mishra*

Main category: cond-mat.quant-gas

TL;DR: The paper explores a new type of topological phase transition in a topological ladder where quasiperiodic disorder, especially when accompanied by a staggered flux, induces a re-entrant transition. The disorder strength causes the system to go from one topological phase to a trivial phase and back to another topological phase, which can be detected via Thouless charge pumping.


<details>
  <summary>Details</summary>
Motivation: The study of topological phases of matter is a key area in condensed matter physics because these phases exhibit unique properties like topological invariants and edge states, which are crucial for potential applications in quantum computing and spintronics. This paper addresses the instability of topological phases against onsite disorder, a critical aspect as disorder is often present in real materials, mitigating their utility.

Method: The authors employ both analytical and numerical methods. Analytical methods are used to map the system into a suitable form to study its critical behavior and to identify the phase transitions. Numerical methods likely involve techniques such as exact diagonalization to find the many-body ground states and compute physical quantities like energy spectra and conductivities. They also perform charge pumping simulations to observe the Hall conductance changes in response to twisted boundary conditions.

Result: The paper reports the discovery of a re-entrant topological phase transition. When quasiperiodic onsite disorder is increased, the system transitions from an initial topological phase into a trivial gapless phase and then back into another topological phase. This behavior is attributed to the dissolution of edge states and their re-emergence under increased disorder strength. Their simulations show that the Hall conductance oscillates between quantized and zero values, indicating the presence of these topological phases.

Conclusion: This is the first demonstration of a disorder-induced re-entrant topological phase transition. Such a phenomenon opens new possibilities for controlling and manipulating topological phases through careful engineering of constitutive disorder and introducing staggered fluxes. The findings not only deepen the understanding of the interplay between disorder and topology but also suggest practical applications in topological insulators and quantum transport phenomena.

Abstract: Topological phases of matter are known to be unstable against strong onsite
disorder in one dimension. In this work, however, we propose that in the case
of a topological ladder, an onsite quasiperiodic disorder under proper
conditions, first destroys the initial topological phase and subsequently,
induces another topological phase through a gap-closing point. Remarkably, by
allowing a staggered flux piercing through the plaquettes of the ladder, the
gapless point bifurcates into two gapless critical lines, resulting in a
trivial gapped phase sandwiched between the two topological phases. This
results in a scenario where the system first undergoes a transition from one
topological phase to a trivial phase and then to the other topological phase as
a function of the quasiperiodic disorder strength. Such disorder induced
re-entrant topological phase transition reveals a phenomenon of direction
reversal in the topological transport, which we identify through Thouless
charge pumping.

</details>


<div id='cond-mat.mes-hall'></div>

# cond-mat.mes-hall [[Back]](#toc)

### [90] [Topological domain-wall states from Umklapp scattering in twisted bilayer graphene](https://arxiv.org/abs/2508.03761)
*Juncheng Li,Cong Chen,Wang Yao*

Main category: cond-mat.mes-hall

TL;DR: 研究分析了大角度间层旋转对二维材料电子行为的影响，发现了新的拓扑状态。


<details>
  <summary>Details</summary>
Motivation: 探索大角度旋转对材料电子性质的控制，提升材料 tailorability，可能用于现成或新应用。

Method: 通过$ k	op p$模型和分子动力学模拟来分析电子态和拓扑相变。

Result: 发现了间距和旋转角度对能带行为和拓扑性质的显著影响，如Chern数变化、新拓扑相的形成和domain wall的发生。

Conclusion: 提出了基于旋转对称性的模型，成功预测和验证了JACKière–Rebi mechanism下的拓扑态，为材料科学提供新工具。

Abstract: Twistronics, harnessing interlayer rotation to tailor electronic states in
van der Waals materials, has predominantly focused on small-angle regime. Here,
we unveil the pivotal role of intervalley Umklapp scattering in large-angle
twisted bilayer graphene, which governs low-energy physics and drives
unconventional band topology. By constructing symmetry-constrained effective
$k\cdot p$ models for $\pm 21.8^{\circ}$-twisted bilayers, we demonstrate how
structural chirality imprints distinct electronic responses. The $D_6$
configuration exhibits a gapped spectrum with chiral interlayer coupling, while
$D_3$ symmetric stacking configuration displays semimetallic behavior.
Crucially, chirality inversion creates topological domain-wall states, which
manifest as counterpropagating pseudospin modes at interfaces between
oppositely twisted regions. These states, absent in untwisted bilayers, emerge
from a Jackiw-Rebbi-like mechanism tied to chirality reversal. Atomistic
simulations confirm these topological states and demonstrate their robustness
against symmetry-breaking perturbations. The interplay between twist-induced
chirality and topology opens new pathways for engineering domain-wall states in
twisted materials.

</details>


### [91] [Absence of dissipation-free topological edge states in quadratic open fermions](https://arxiv.org/abs/2508.03821)
*Liang Mao*

Main category: cond-mat.mes-hall

TL;DR: 研究证明了二次开放型 fermionic Lindbladian 无法 hosts 稳定的无耗散边模式，主要基于adiabatic连通性质。


<details>
  <summary>Details</summary>
Motivation: 探索开放系统中的拓扑边模式的存在性，尤其是二次系统的限制。

Method: 通过 Lindbladian 的矩阵表示分析其adiabatic连通性，探讨拓扑边模式的可能性。

Result: 证明二次系统无法有稳定无耗散边模式，基于adiabatic连通性质。

Conclusion: 二次开放型 fermionics 没有稳定无耗散的拓扑边模式，构成存在拓扑现象的明确边界。

Abstract: We prove a no-go theorem that generic quadratic open fermionic systems,
governed by Lindblad master equations, cannot host dissipation-free topological
edge states. Drawing an analogy to topological insulators and superconductors,
we map the Lindbladian to a first-quantized matrix representation that encodes
the band structure, whose zero-energy topological edge modes are exactly
dissipation-free. This matrix, however, is always adiabatically connected to a
topologically trivial matrix, even under symmetry constraints. We formulate s
rigorous adiabatic path to demonstrate this property. Thus, there is no robust
dissipation-free edge modes protected by the bulk topology in quadratic open
fermions, under any unitary or anti-unitary symmetries. Our result applies to
generic quadratic fermionic Lindbladians, requiring only gapped bulk and
bounded spectrum for technical convenience. Our result establish a definitive
boundary for the existence of robust topological phenomena in open fermionic
systems.

</details>


### [92] [Hybrid metal-semiconductor quantum dots in InAs as a platform for quantum simulation](https://arxiv.org/abs/2508.03928)
*Praveen Sriram,Connie L. Hsueh,Karna A. Morey,Tiantian Wang,Candice Thomas,Geoffrey C. Gardner,Marc A. Kastner,Michael J. Manfra,David Goldhaber-Gordon*

Main category: cond-mat.mes-hall

TL;DR: Hybrid metal-semiconductor islands offer a scalable approach for quantum simulation using Coulomb interactions.


<details>
  <summary>Details</summary>
Motivation: The field of quantum computing and simulation is advancing rapidly, and new methods to enhance qubit systems and improve quantum coherence are highly sought after.

Method: The paper discusses a new method involving arrays of hybrid metal-semiconductor islands where the metallic component has quasi-continuous energy levels, allowing for uniform electronic properties across the array. The semiconductor part allows for gate-tunable couplings. The researchers fabricate these islands with a submicron metal contact transparently connecting a gate-confined region of an InAs quantum well. They tune the system to different limits, observing transition from single-electron transistor behavior to Coulomb blockade when increasing transmission to the ballistic regime.

Result: The fabrication method achieves highly uniform Coulomb peaks without a detectable excitation spectrum in Coulomb diamonds in the weak-coupling limit. As transmission increases, a dynamical Coulomb blockade is observed, indicating the system can transition from sub-microscopic scale coherent quantum transport to more macroscopic, correlated behavior.

Conclusion: This creates a scalable platform for simulating correlated electron systems driven by Coulomb interactions, showing potential for quantum simulation studies and coherent electron transport applications.

Abstract: Arrays of hybrid metal-semiconductor islands offer a new approach to quantum
simulation, with key advantages over arrays of conventional quantum dots.
Because the metallic component of these hybrid islands has a quasi-continuous
level spectrum, each site in an array can be effectively electronically
identical; in contrast, each conventional semiconductor quantum dot has its own
spectral fingerprint. Meanwhile, the semiconductor component retains
gate-tunability of intersite coupling. This combination creates a scalable
platform for simulating correlated ground states driven by Coulomb
interactions. We report the fabrication and characterization of hybrid
metal-semiconductor islands, featuring a submicron metallic component
transparently contacting a gate-confined region of an InAs quantum well with
tunable couplings to macroscopic leads. Tuning to the weak-coupling limit forms
a single-electron transistor with highly-uniform Coulomb peaks, with no
resolvable excitation spectrum in the Coulomb diamonds. Upon increasing the
transmissions toward the ballistic regime we observe an evolution to dynamical
Coulomb blockade.

</details>


### [93] [Transmon qubit using Sn as a junction superconductor](https://arxiv.org/abs/2508.04007)
*Amrita Purkayastha,Amritesh Sharma,Param J. Patel,An-Hsi Chen,Connor P. Dempsey,Shreyas Asodekar,Subhayan Sinha,Maxime Tomasian,Mihir Pendharkar,Christopher J. Palmstrøm,Moïra Hocevar,Kun Zuo,Michael Hatridge,Sergey M. Frolov*

Main category: cond-mat.mes-hall

TL;DR: The paper discusses the use of InAs semiconductor nanowires with beta-Sn shells to create transmon qubits with high coherence times.


<details>
  <summary>Details</summary>
Motivation: The study is motivated by exploring alternative materials for superconducting qubits beyond aluminum, aiming to improve qubit performance.

Method: The researchers used InAs nanowires coated with beta-Sn to create transmon qubits, adjusting the Josephson energy via gate voltage to tune qubit frequency. They measured T1 and T2 times and analyzed factors affecting coherence.

Result: The qubits achieved T1 of 27 microseconds and T2 of 1.8 microseconds, with the longest T1 at the lowest frequencies and T2 at higher frequencies. The study identified factors limiting coherence times and discussed material and design improvements.

Conclusion: Using beta-Sn shells on InAs nanowires shows promise for high-coherence transmon qubits, and the paper outlines steps to enhance their performance.

Abstract: Superconductor qubits typically use aluminum-aluminum oxide tunnel junctions
to provide the non-linear inductance. Junctions with semiconductor barriers
make it possible to vary the superconductor material and explore beyond
aluminum. We use InAs semiconductor nanowires coated with thin superconducting
shells of beta-Sn to realize transmon qubits. By tuning the Josephson energy
with a gate voltage, we adjust the qubit frequency over a range of 3 GHz. The
longest energy relaxation time, T1 = 27 microseconds, is obtained at the lowest
qubit frequencies, while the longest echo dephasing time, T2 = 1.8
microseconds, is achieved at higher frequencies. We assess the possible factors
limiting coherence times in these devices and discuss steps to enhance
performance through improvements in materials fabrication and circuit design.

</details>


### [94] [Straightforward Method to Orient Black Phosphorus from Bulk to Thin Layers using a Standard Green Laser](https://arxiv.org/abs/2508.04142)
*Etienne Carré,Frédéric Fossard,Jean-Sébastien Mérot,Denis Boivin,Nicolas Horezan,Victor Zatko,Florian Godel,Bruno Dlubak,Marie-Blandine Martin,Pierre Seneor,Etienne Gaufres,Julien Barjon,Annick Loiseau,Ingrid Stenger*

Main category: cond-mat.mes-hall

TL;DR: 该论文提出了一种利用单波长角分辨的极化拉aman光谱学方法来测定二维材料晶体取向，解决了传统方法如TEM和XRD操作复杂和成本高的问题。实验结果验证了该方法在不同厚度石墨烯和石墨中的适用性，且具有易于实现和低成本的优点。


<details>
  <summary>Details</summary>
Motivation: 二维材料（如石墨烯）在电子和材料科学中具有广泛的应用，其晶体取向会对物理性质和器件性能产生显著影响。然而，传统的表征方法（如TEM和XRD）操作复杂且成本高昂，限制了其在常规研究中的应用。因此，寻找一种简便、成本低廉且易于操作的方法来测定石墨烯等二维材料的晶体取向变得尤为重要。

Method: 该论文采用了一种基于单波长角分辨的极化拉aman光谱学方法。通过引入厚度相关干涉效应以及材料的晶体对光的折射率和光栅结构的影响，该方法能够可靠地测定各向异性二维材料的晶体取向，并且适用于不同厚度的样品。为了验证该方法的有效性，论文还结合了TEM和电子反散射衍射（EBSD）进行比较，证明了方法在厚薄材料中的适用性。

Result: 实验结果表明，该方法能够在不同厚度的石墨烯及其单层石墨中准确测定晶体取向，且结果与TEM和EBSD一致。此外，该方法操作简便，只需配备单波长的拉aman设备即可实现，无需复杂的前期设备准备。

Conclusion: 该研究提出了一种高效、实用的晶体取向测定方法，显著减少了传统方法的人力物力资源消耗。此方法对于研究者而言具有重要的参考价值，特别适用于需要快速、简便分析二维材料晶体取向的场景。

Abstract: The crystallographic orientation of anisotropic 2D materials plays a crucial
role in their physical properties and device performance. However, standard
orientation techniques such as transmission electron microscopy (TEM) or X-ray
diffraction (XRD) can be complex and less accessible for routine
characterization. In this study, we investigate the orientation of black
phosphorus (BP) from bulk crystals to thin layers using angle-resolved
polarized Raman spectroscopy (ARPRS) with a single-wavelength (514 nm) Raman
setup. By incorporating thickness-dependent interference effects and
anisotropic optical indices, this approach provides a reliable framework for
orientation determination across different BP thicknesses. The method is
validated through direct orientation measurements using TEM and Electron
Backscattering Diffraction (EBSD), confirming its applicability to both thick
and ultrathin samples. Given its simplicity and compatibility with widely
available Raman setups, this approach offers a practical solution for
characterizing BP orientation without requiring advanced structural
characterization techniques.

</details>


### [95] [Inelastic electron tunneling through adatoms and molecular nanomagnets](https://arxiv.org/abs/2508.04449)
*Daria Kyvala,Jindrich Kolorenc*

Main category: cond-mat.mes-hall

TL;DR: 研究了磁性纳米系统吸附在固体表面时使用 STM 测量的不弹性电子透射光谱（IETS），通过 Hubbard 模型分析，发现不同原子的较大轨道矩影响的能级跃迁规则，以及磁场在不同情况下的表现。


<details>
  <summary>Details</summary>
Motivation: 研究不弹性电子透射光谱在磁性纳米系统中的应用，有助于理解纳米材料的磁性特性。

Method: 使用 Hubbad 模型，分析测试原子的能级跃迁规则，特别是在不同氧化态和磁性下。

Result: 发现较大轨道矩的原子满足 ΔJ_z ≤ 2ℓ+1 的跃迁规则，而主导磁场的原子满足 ΔJ_z ≤1 的传统规则。

Conclusion: 该研究揭示了原子轨道矩大小对磁性纳米系统 IETS 的影响，有助于设计新功能纳米材料。

Abstract: We discuss a theoretical description of the inelastic electron tunneling
spectra (IETS) of a magnetic nanosystem (an atom or a molecule) adsorbed on a
solid surface measured in a scanning tunneling microscope (STM). We represent
the nanosystem by means of a cluster Hubbard model, which allows us to study
scenarios when the tunneling electrons sequentially interact with several
magnetic centers inside the nanosystem or when the magnetic centers are made
out of heavy atoms with a strong spin-orbit coupling and large orbital moments.
The sequential tunneling through multiple centers is illustrated on an adatom
probed by an STM tip with a nickelocene molecule attached to it. For atoms with
a large orbital moment, we find the transitions accessible by IETS to be
governed by the selection rule $\Delta J_z\leq 2\ell+1$, where $J_z$ is the
projection of the total angular momentum of the atom to the quantization axis
and $\ell$ is the orbital momentum quantum number of the partially filled
atomic shell carrying the magnetic moment. For atoms with magnetic moments
dominated by spin, the spectra are naturally dominated by transitions
fulfilling the traditional selection rule $\Delta J_z\leq 1$.

</details>


### [96] [Effect of screening on Seebeck coefficient in bilayer graphene/AlGaAs electron gas](https://arxiv.org/abs/2508.04184)
*Vo Van Tai,Nguyen Duy Vy,Truong Van Tuan,Nguyen Quoc Khanh*

Main category: cond-mat.mes-hall

TL;DR: 摘要中研究了双层石墨烯-GaAs异质结构中声子-screening效应对声子-克尔文系数的影响，发现随温度降低和材料参数变化，screening效应显著影响系数大小。需要详细分析具体的影响机制。


<details>
  <summary>Details</summary>
Motivation: 研究声子-screening效应在双层石墨烯-敲石墨烯/GaAs异质结构中的作用，可能为理解声子-克尔文系数和材料性能相关性提供新视角。

Method: 通过有限元模拟方法分析声子-screening效应在双层石墨烯-敲石墨烯/GaAs系统中的影响。

Result: 声子-screening效应随温度降低和材料参数变化显著影响声子-克尔文系数。

Conclusion: 研究结果表明，声子-screening效应在双层石墨烯-敲石墨烯/ GaAs系统中对声子-克尔文系数有重要影响。

Abstract: The knowledge of Seebeck coefficient is a key factor in optimization of
thermoelectric materials and finding right applications for it. A high
sensitivity to structural change makes thermopower measurements an excellent
technique for the study on the charge transport properties of a given material.
The phonondrag term dominates at low temperature in the Seebeck coefficient
This study examines the temperaturedependent screening effect on the
phonondraginduced Seebeck coefficient S^g in a bilayer graphene-
BLG-AlGaAs-quasi-twodimensional electron gas (q2DEG) system at the temperature
below 50 K. The BLG layer interacts with both deformation potential acoustic
phonons and stronger piezoelectric field acoustic phonons from AlGaAs/GaAs. We
compare the electronphonon interactions in BLG with and without screening by
q2DEG. The screening effect reduces particularly at low temperatures and shows
a strong dependence on the carrier density in the BLG layer. The doublelayer
screening function increases with layer separation d paralleling the monolayer
screening at large d. Additionally varying the GaAs quantum well width reveals
that increases with width less than 100 \AA under doublelayer screening but
remains unchanged beyond this threshold while monolayer screening decreases as
the width increases. Both screening functions enhance when the BLG carrier
density is lower than that of q2DEG though the magnitude difference between
them is minimal

</details>


### [97] [Structural and helix reversal defects of carbon nanosprings](https://arxiv.org/abs/2508.04490)
*Alexander V. Savin,Elena A. Korznikova,Sergey V. Dmitriev*

Main category: cond-mat.mes-hall

TL;DR: Carbon nanosprings, with their chiral structure, show promising properties for nanotechnology. The study uses molecular dynamics simulations to analyze their structural transformations from coronene and kekulene into spiral macromolecules. It investigates beyond tension/compression deformations, looking into bending and twisting, and the formation of structural and helix reversal defects. The findings reveal that nanosprings have a higher axial thermal expansion coefficient compared to metals, making them suitable for nanosensors with wide temperature ranges.


<details>
  <summary>Details</summary>
Motivation: The paper delves into the structural properties of carbon nanosprings, which have potential applications in nanotechnology. It analyzes their behavior under different deformation modes and identifies their thermal expansion properties, indicating their viability for use in temperature-sensitive devices. understanding these properties is essential for advancing nanotechnology and materials science applications.

Method: The study employs molecular dynamics simulations to model the structural transformations of carbon nanosprings derived from planar coronene and kekulene molecules. It focuses on analyzing their behavior under bending and twisting, as well as the formation of defects such as structural and helix reversal defects. The simulation approach allows for detailed examination of the mechanical properties and deformation mechanisms.

Result: The research reveals that carbon nanosprings exhibit a significantly higher coefficient of axial thermal expansion compared to metals and alloys. This characteristic makes them highly suitable for applications as nanosensors that can operate over a wide temperature range, which is crucial for various nanotechnology applications where temperature stability is essential.

Conclusion: The findings of this study enhance our understanding of the mechanical behavior and thermal expansion properties of carbon nanosprings. By exploring structural and helix reversal defects, the research provides insights into optimizing their properties for advanced nanosensors and other nanotechnology applications where high thermal expansion coefficients are advantageous.

Abstract: Due to their chiral structure, carbon nanosprings possess unique properties
that are promising for nanotechnology applications. The structural
transformations of carbon nanosprings in the form of spiral macromolecules
derived from planar coronene and kekulene molecules (graphene helicoids and
spiral nanoribbons) are analyzed using molecular dynamics simulations. While
the tension/compression of such nanosprings has been analyzed in the
literature, this study investigates other modes of deformation, including
bending and twisting. Depending on the geometric characteristics of the carbon
nanosprings, the formation of structural and helix reversal defects is
described. It is found that nanosprings demonstrate a significantly higher
coefficient of axial thermal expansion than many metals and alloys. These
results are useful for designing nanosensors that operate over a wide
temperature range.

</details>


### [98] [Density of States (Gate) - Controlled Andreev Molecule and Sensor](https://arxiv.org/abs/2508.04519)
*Xiaofan Shi,Ziwei Dou,Guoan Li,Dong Pan,Yuxiao Song,Anqi Wang,Zhiyuan Zhang,Xingchen Guo,Xiao Deng,Ruixuan Zhang,Liangqian Xu,Xiao Chen,Yupeng Li,Bingbing Tong,Xiaohui Song,Zhaozheng Lyu,Peiling Li,Fanming Qu,Guangtong Liu,Jianhua Zhao,Li Lu,Jie Shen*

Main category: cond-mat.mes-hall

TL;DR: The paper proposes a gate-controlled Andreev molecule for scalable topological quantum computing, avoiding the need for superconducting loops and high magnetic fields. The molecule can be used in a Kitaev chain and a sensor for single Cooper-pair parity readout, offering significant advancements in scalability and sensitivity.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the scalability and tunability issues in topological quantum computing by introducing a gate-controlled approach to Andreev molecules, which are key components for topological qubits and quantum sensing.

Method: The method involves engineering a gate-controlled Andreev molecule where electrostatic tuning alters the density of states, enhancing the critical current of neighboring sites, thus eliminating the need for superconducting loops and improving scalability.

Result: The result is the development of a scalable and high-sensitive quantum sensing platform utilizing Andreev molecules in a Kitaev chain and a sensor capable of single Cooper-pair parity readout, which has implications for topological qubits and quantum computing applications.

Conclusion: The conclusion is that this gate-controlled system overcomes limitations of previous approaches, offering a more scalable and tunable solution for topological quantum computing and quantum sensing applications. It paves the way for practical implementations of topological qubits and advanced quantum technologies.

Abstract: Topological quantum computing typically relies on topological Andreev bound
states (ABSs) engineered in hybrid superconductor-semiconductor devices, where
gate control offers key advantages. While strong Zeeman fields can induce such
states, an alternative approach emerges through Andreev molecules -- closely
spaced, coupled ABSs, also key building-block for Kitaev chain -- that enable
topological behavior without high magnetic fields. However, existing Andreev
molecules are controlled via magnetic flux in superconducting loops, limiting
scalability. Here, we introduce a gate-controlled Andreev molecule, where
electrostatic tuning of the density of states in one site nonlocally enhances
the critical current of another. This eliminates superconducting loops,
offering superior tunability, scalability, and sensitivity. We further extend
such an Andreev molecule to a multi-site Kitaev chain, and a noninvasive sensor
resolving single-Cooper-pair charge for parity readout. This platform bridges
the gap between scalable ABS engineering and high-sensitivity quantum sensing,
advancing the development for constructing and parity-readout in topological
ABSs and long Kitaev chains towards topological qubits.

</details>


### [99] [Localization structure of electronic states in the quantum Hall effect](https://arxiv.org/abs/2508.04528)
*Alioune Seye,Marcel Filoche*

Main category: cond-mat.mes-hall

TL;DR: 研究了使用磁局部化势能（MLL）方法分析整数量子霍尔效应（IQHE）中的电子态局域化。通过连续的薛定谔模型和有缺陷的电势，展示了MLL通过改进后的势能函数捕获了关键的局域化特征。数值模拟显示，能量低于临界值时，态在势能的最低点局域，高于时则在最高点聚集，边界效应在附近边界显著。MLL将半经典直觉与量子模型结合起来，提供了理解磁系统中传输和局域化的稳健框架，扩展了景况理论的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了深入理解量子霍尔效应中的电子态局域化，特别是在磁性系统中的行为，可能需要更精确和全面的工具来分析。探索现有方法的局限性，并开发新的理论框架能够为研究者提供更全面的工具，尤其是在传统半经典方法失效的情况下。

Method: 使用连续的薛定谔方程模型和有缺陷的电势场，结合改进的磁性局域化势能函数（MLL）来分析电子态的局域化。通过数值模拟和对势能分析体的理解，来预测态的能量分布以及局域化位置。

Result: 数值模拟结果表明，低于临界能量时电子态集中在势能的最低点，高于时则集中在势能的最大点。边界面效应在势能的边界区域显著。MLL提供了可靠的框架来理解局域化现象，特别是在半经典方法失效的情况下。

Conclusion: 该研究扩展了局域化势能方法的应用，提供了分析磁性量子霍尔效应中电子态局域化的有效工具。MLL在量化预测和理解材料边界效应方面具有良好的前景。因此，在未来的研究中，MLL可能被推广到更复杂的材料系统，以提供更深入的见解。

Abstract: We investigate the localization of electronic states in the Integer Quantum
Hall Effect (IQHE) using a magnetic localization landscape (MLL) approach. By
studying a continuum Schr\"odinger model with disordered electrostatic
potential, we demonstrate that the MLL, defined via a modified landscape
function incorporating magnetic effects, captures key features of quantum state
localization. The MLL effective potential reveals the spatial confinement
regions and provides predictions of eigenstate energies, particularly in
regimes where traditional semiclassical approximations break down. Numerical
simulations show that below a critical energy, states localize around minima of
the effective potential, while above it, they cluster around maxima-with edge
effects becoming significant near boundaries. Bridging the gap between
semiclassical intuition and full quantum models, the MLL offers a robust
framework to understand transport and localization in disordered quantum Hall
systems, and extends the applicability of landscape theory to magnetic systems.

</details>


### [100] [Light induced transitions of valley Chern numbers and flat bands in a non-twisted moire graphene-hexagonal boron nitride superlattice](https://arxiv.org/abs/2508.04620)
*Saud Alabdulal,Miftah Hadi Syahputra Anfa,Hocine Bahlouli,Michael Vogl*

Main category: cond-mat.mes-hall

TL;DR: This paper studies untwisted moire materials under light, showing that they exhibit rich topology and interesting band effects, similar to twisted moire materials that were recently highlighted. The work aims to ease experimental studies of light-matera interface by providing a more accessible platform. The key finding is that key phenomena, such as band flattening, are preserved in these untwisted systems, which remain highly tunable by light.


<details>
  <summary>Details</summary>
Motivation: The paper is motivated by interest in understanding the physics of moire materials coupled to light, particularly simplifying the materials for experimental elucidation. The desire is to develop an accessible platform that can help realize the potential applications of moire materials under light.

Method: The paper likely involves both theoretical analysis, using models and simulations to explore the electronic properties of untwisted moire materials under different light conditions, and possibly experimental work, such as growing and characterizing untwisted moire crystals or simulating their optical responses using techniques like angle-resolved photoemission spectroscopy (ARPES). They would analyze the band structure, identify the topological phases, and observe the effects of light on these materials, such as changes in the band gap, piezoelectric effects, and the generation of protected states.

Result: The findings show that untwisted moire materials exhibit rich topological phases and interesting band effects when subjected to light. They report the existence of band flattening, which could lead to robust edge currents similar to those seen in graphene, as well as potential for topological insulators. The materials also show tunability of electronic properties with light, which could have implications for optoelectronic devices. The work provides a blueprint for designing and studying light-matera interfaces without the complexity of twisted moire layers.

Conclusion: The research concludes that the behavior observed in twisted moire materials under light is indeed prevalent in untwisted counterparts, opening up a new avenue for studying and applying moire materials. This approach simplifies experimental realization and broadens the potential applications in optoelectronics and topological photonics. The findings advance the understanding of the fundamental physics of light-matera coupling in both twisted and untwisted moire systems, showing that they share common generic properties that can be exploited for various technological applications.

Abstract: Motivated by the rich topology and interesting quasi-band structure of
twisted moire materials subjected to light, we study a non-twisted moire
material under the influence of light. Our work is in part motivated by a
desire to find an easier-to-synthesize platform that can help experimentally
elucidate the interesting physics of moir\'e materials coupled to light.
Similar to twisted moire materials, we uncover rich topology and interesting
band flattening effects, which we summarize in relevant plots such as a
topological phase diagram. Our work demonstrates that much of the interesting
phenomenology of twisted moire materials under the influence of electromagnetic
waves seems to be generically present even in more experimentally accessible
untwisted moire platforms, which remain highly tunable by light.

</details>


<div id='physics.bio-ph'></div>

# physics.bio-ph [[Back]](#toc)

### [101] [Probing the statistics of sequence-dependent DNA conformations in solution using SAXS](https://arxiv.org/abs/2508.04358)
*Heidar J. Koning,Anuradha Pullakhandam,Andrew E. Whitten,Charles S. Bond,Michel Peyrard*

Main category: physics.bio-ph

TL;DR: The study uses SAXS to analyze DNA conformations, finds a simple model effectively describes DNA flexibility, and suggests SAXS can relate sequence features to DNA structure.


<details>
  <summary>Details</summary>
Motivation: Understanding DNA flexibility and its relation to its sequence is crucial for molecular biology, especially with large-scale genomic studies.

Method: SAXS of DNA duplexes, analysis with a polymer model to determine flexibility metrics like persistence length and torsional rigidity, and orientation of conformations based on sequence asymmetry.

Result: SAXS data provides accurate statistical distributions of local DNA conformations, revealing how sequence features influence DNA flexibility.

Conclusion: SAXS is a powerful tool for molecular biologists to study DNA structure and its relationship with sequence sequences in solution.

Abstract: SAXS studies of four 60 base-pair DNA duplexes with sequences closely
  related to part of the GAGE6 (G-antigen 6) promoter have been performed to
  study the role of DNA conformations in solution and their potential
  relationship to DNA-protein binding. We show that the SAXS data can be
  analysed using a simple polymer model which nevertheless quantitatively
  describes the average persistence length and torsional rigidity of the DNA
  double helix to determine the statistical distribution of local
  conformations of the DNA in solution to a high accuracy. Although the SAXS
  data is averaged over time and all spatial orientations of the molecules,
  for sequences which have some asymmetry in the data we show that the
  conformations can be oriented with respect to the sequence. This allows
  specific features detected by the analysis to be precisely related to the
  DNA sequence, opening up new opportunities for SAXS to investigate the
  properties of DNA in solution. The biological implications of these results
  are discussed.

</details>


<div id='hep-th'></div>

# hep-th [[Back]](#toc)

### [102] [On integrable structure of the null string in (anti-)de Sitter space](https://arxiv.org/abs/2508.04158)
*D. V. Uvarov*

Main category: hep-th

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Presently integrability turned the key property in the study of duality
between superconformal gauge theories and strings in anti-de Sitter
superspaces. Complexity of the study of integrable structure in string theory
is caused by complicated dependence of background fields of the Type II
supergravity multiplets, with which strings interact, on the superspace
coordinates. This explains an interest to study of limiting cases, in which
superstring equations simplify. In the present work considered is the limiting
case of zero tension corresponding to null string. It is obtained the
representation in the form of the Lax equation of null-string equations in
(anti-)de Sitter space realized as coset manifold. Proposed is twistor
interpretation of the Lagrangian of (null) string in anti-de Sitter space
expressed in terms of group variables.

</details>


### [103] [The Flat-Space Limit of AdS Coupled to a Bath](https://arxiv.org/abs/2508.03798)
*Dominik Neuenfeld*

Main category: hep-th

TL;DR: The paper discusses a flat-space limit of brane models in AdS coupled to a non-gravitating bath, using a triple-scaling limit. They apply Wigner-İnönü contraction to global symmetries and explore entanglement entropy in different scenarios. Page time behavior is analyzed in various dimensions.


<details>
  <summary>Details</summary>
Motivation: Understanding scaling limits in AdS/CFT correspondence, especially involving boundary theories and symmetry structures, is a key motivation for this research. It explores the connection between bulk and boundary physics, particularly in the context of entanglement and horizon behavior.

Method: The authors use a triple-scaling limit approach by taking the boundary degrees and coupling to infinity while approaching a lightcone. They employ Wigner-İnönü contraction to analyze symmetry algebras. Entanglement entropy is computed in two scenarios: including modes that left through I± and not including them, leading to vanishing and non-trivial Page curves. Additionally, they examine Page time in topological black holes across different dimensions, finding finite Page time in 2D but divergence in higher dimensions.

Result: In the flat-space limit, the global boundary symmetry algebra reduces to Poincaré algebra through contraction. Entanglement entropy computations show vanishing Page curve when including outgoing modes and a non-trivial Page curve when excluding them. Page time remains finite in 2D black holes but diverges in higher dimensions.

Conclusion: The flat-space limit provides a useful tool for studying AdS black hole thermodynamics and entanglement properties, with implications for understanding horizons and Page time behavior in different dimensions.

Abstract: We explain how to take a well-defined flat-space limit of brane models of AdS
coupled to a non-gravitating bath. In the dual BCFT this amounts to a
triple-scaling limit where both the number of boundary degrees of freedom and
the boundary coupling are taken to infinity while the BCFT boundary piecewise
approaches a lightcone. We show how this procedure acts on the conformal
generators as a Wigner-\.In\"on\"u contraction, reducing the global BCFT
symmetry algebra to the global symmetry algebra of flat space.
  We discuss two natural notions of entanglement entropy of the flat-space
dual. These are distinguished by whether modes that have left through $\mathcal
I^\pm$ are included or not and give rise to a vanishing and non-trivial Page
curve, respectively. Taking the flat-space limit of topological black holes we
show that the Page time remains finite in two-dimensions. In $d > 2$ the Page
time diverges in the flat limit, since AdS topological black holes become
flat-space Rindler horizons.

</details>


### [104] [Almost local integrable models from supersymmetry algebras](https://arxiv.org/abs/2508.04315)
*Somnath Maity,Pramod Padmanabhan,Jarmo Hietarinta,Vladimir Korepin*

Main category: hep-th

TL;DR: The paper investigates the use of supersymmetry algebras to construct invertible Yang-Baxter operators (braid group generators) and extends previous work on non-invertible solutions. The constructed models' regularity and non-invertibility vary depending on SUSY generator representations, but they still support integrable models across all Hilbert space dimensions. The authors also demonstrate new spin 1/2 systems and their higher spin analogs using an algebraic method. The study contributes to understanding the connections between supersymmetry, Yang-Baxter equations, and integrable models.


<details>
  <summary>Details</summary>
Motivation: The paper explores the intersection of supersymmetry and integrable systems by utilizing Yang-Baxter operators to construct solutions for Hamiltonian-based integrable models. The motivation is to advance our understanding by extending beyond existing non-invertible solutions and examining the implications of different SUSY representations on model properties.

Method: The approach involves constructing invertible Yang-Baxter solutions from supersymmetry algebras, exploring their regularity conditions, and analyzing the resulting integrable models for varying SUSY generator representations. The method is algebraic and representation-independent, allowing for the discovery of new models and their properties.

Result: The paper successfully constructs invertible Yang-Baxter solutions using SUSY algebras, identifies conditions for their regularity and non-invertibility, and demonstrates their applicability in constructing integrable models. New spin 1/2 and higher spin systems are identified, highlighting the advantages of an algebraic approach.

Conclusion: The research synthesizes supersymmetry with integrable systems, providing a novel method to construct and analyze Yang-Baxter operators and integrable models. The findings include both regular and near-regular, invertible/non-invertible models, which are applicable in any local Hilbert space dimension and include new spin systems.

Abstract: Supersymmetry algebras can be used to obtain algebraic expressions for
constant Yang-Baxter solutions, also known as braid group generators. This was
done for non-invertible braid operators in \cite{maity2025non}. In this work we
extend this construction for the invertible ones. The resulting expressions are
then shown to obey relations analogous to those satisfied by quotients of braid
groups. Examples of the latter include the Iwahori-Hecke algebra and the
Birman-Murakami-Wenzl (BMW) algebra. As a result, we can Baxterize the constant
Yang-Baxter solutions to yield spectral parameter dependent $R$-matrices. The
regularity of these $R$-matrices depend on the representation of SUSY
generators. In some cases they are regular in the usual sense and in the
remaining they are `almost' regular. In the latter case they are also
non-invertible. Nevertheless we show that they can still help us construct
integrable models in all dimensions of the local Hilbert space. These models
can be described by Hamiltonian densities that are either local or non-local,
depending on the representation chosen for the SUSY generators. We demonstrate
this for all constant $4\times 4$ invertible Yang-Baxter solutions. Apart from
finding new nearest-neighbor interaction spin $\frac{1}{2}$ systems, we also
find their higher spin analogs due to the algebraic [representation
independent] approach.

</details>


### [105] [Viability of perturbative expansion for quantum field theories on neurons](https://arxiv.org/abs/2508.03810)
*Srimoyee Sen,Varun Vaidya*

Main category: hep-th

TL;DR: This paper explores a novel neural network architecture for simulating QFTs, reporting promising results with improved convergence for finite N.


<details>
  <summary>Details</summary>
Motivation: Developing novel computational methods for simulating complex physical theories like QFTs is crucial for advancing theoretical physics and potentially for practical applications in areas like quantum computing.

Method: The authors use scalar φ⁴ theory in d-dimensional Euclidean space to test their NN architecture, examining the impact of finite neuron numbers on the convergence of two- and four-point correlators and proposing modifications to enhance convergence.

Result: The suggested modifications to the NN architecture show potential to improve convergence for finite N, offering a new computational approach for perturbative QFT calculations.

Conclusion: The study provides evidence for the viability of NN-based methods in simulating QFTs, setting a foundation for further investigation into their applicability to more complex theories and scenarios.

Abstract: Neural Network (NN) architectures that break statistical independence of
parameters have been proposed as a new approach for simulating local quantum
field theories (QFTs). In the infinite neuron number limit, single-layer NNs
can exactly reproduce QFT results. This paper examines the viability of this
architecture for perturbative calculations of local QFTs for finite neuron
number $N$ using scalar $\phi^4$ theory in $d$ Euclidean dimensions as an
example. We find that the renormalized $O(1/N)$ corrections to two- and
four-point correlators yield perturbative series which are sensitive to the
ultraviolet cut-off and therefore have a weak convergence. We propose a
modification to the architecture to improve this convergence and discuss
constraints on the parameters of the theory and the scaling of N which allow us
to extract accurate field theory results.

</details>


### [106] [A Hidden Permutation Symmetry of Squared Amplitudes in ABJM Theory](https://arxiv.org/abs/2508.03813)
*Song He,Canxin Shi,Yichao Tang,Yao-Qi Zhang*

Main category: hep-th

TL;DR: The paper discusses the square amplitudes in ABJM theory, showing how they can be unified in a generating function that includes fixed n and L. This function has permutation symmetries and can be represented using specific graph structures. The results were verified for several cases and suggest a unifying structure akin to SYM. The analysis draws parallels to SYM to propose graphical rules and derive new results for ABJM. The findings imply a promising framework for further calculations in the theory.


<details>
  <summary>Details</summary>
Motivation: The paper aims to simplify the understanding of square amplitudes in ABJM theory by presenting a unified generating function. By drawing analogies with SYM theory, it provides a novel approach to calculating and analyzing these amplitudes, potentially leading to new insights and simplifications in the field of theoretical physics.

Method: The authors define the square amplitudes in ABJM theory and construct a generating function that combines n-point and L-loop integrands for fixed N = n + L. They identify permutation symmetries and represent the function using planar f-graphs. Verification is done for specific cases, and they propose graphical rules to derive new results.

Result: The study unifies various square amplitudes into a single generating function. It identifies hidden symmetries and provides representations using f-graphs. Verified cases support the validity of the function, and the analysis suggests new results for higher n and L in ABJM theory.

Conclusion: The paper concludes that ABJM theory has a unifying structure for square amplitudes, akin to SYM. By leveraging permutation symmetries and f-graphs, the findings offer a powerful framework for simplifying calculations and predicting new results in the theory.

Abstract: We define the square amplitudes in planar Aharony-Bergman-Jafferis-Maldacena
theory (ABJM), analogous to that in $\mathcal{N}{=}4$ super-Yang-Mills theory
(SYM). Surprisingly, the $n$-point $L$-loop integrands with fixed $N{:=}n{+}L$
are unified in a single generating function. Similar to the SYM four-point
half-BPS correlator integrand, the generating function enjoys a hidden $S_N$
permutation symmetry in the dual space, allowing us to write it as a linear
combination of weight-3 planar $f$-graphs. Remarkably, through Gram identities
it can also be represented as a linear combination of bipartite $f$-graphs
which manifest the important property that no odd-multiplicity amplitude exists
in the theory. The generating function and these properties are explicitly
checked against squared amplitudes for all $n$ with $N{=}4,6,8$. By drawing
analogies with SYM, we conjecture some graphical rules the generating function
satisfy, and exploit them to bootstrap a unique $N{=}10$ result, which provides
new results for $n{=}10$ squared tree amplitudes, as well as integrands for
$(n,L){=}(4,6),(6,4)$. Our results strongly suggest the existence of a
"bipartite correlator" in ABJM theory that unifies all squared amplitudes and
satisfies physical constraints underlying these graphical rules.

</details>


### [107] [From Tensor Algebras to Hyperbolic Kac-Moody Algebras](https://arxiv.org/abs/2508.03815)
*Axel Kleinschmidt,Hannes Malcha,Hermann Nicolai*

Main category: hep-th

TL;DR: The abstract introduces a new method for studying hyperbolic Kac-Moody algebras, specifically the Feingold-Frenkel algebra, by analyzing tensor algebras and exploiting coset Virasoro symmetries. It provides detailed decompositions for levels up to five and suggests future research directions.


<details>
  <summary>Details</summary>
Motivation: The paper appears to delve into advanced algebraic structures, potentially offering new insights or methodologies for studying Kac-Moody algebras, which are important in mathematical physics and representation theory.

Method: The method involves considering the tensor algebra of level-one states, converting tensor products into multiple commutators, and utilizing coset Virasoro symmetries to decompose the algebra for different levels up to five.

Result: The study presents complete decompositions and maximal tensor ground states, allowing generation of algebra elements through affine and coset Virasoro actions and DDF states. It also suggests exploring these methods further.

Conclusion: The paper proposes a promising approach using coset Virasoro symmetries for studying hyperbolic Kac-Moody algebras, providing a detailed analysis for low levels and outlining future research directions.

Abstract: We propose a novel approach to study hyperbolic Kac-Moody algebras, and more
specifically, the Feingold-Frenkel algebra $\mathfrak{F}$, which is based on
considering the tensor algebra of level-one states before descending to the Lie
algebra by converting tensor products into multiple commutators. This method
enables us to exploit the presence of mutually commuting coset Virasoro
algebras, whose number grows without bound with increasing affine level. We
present the complete decomposition of the tensor algebra under the affine and
coset Virasoro symmetries for all levels $\ell\leq 5$, as well as the maximal
tensor ground states from which all elements of $\mathfrak{F}$ up to level five
can be (redundantly) generated by the joint action of the affine and coset
Virasoro generators, and subsequent conversion to multi-commutators, which are
then expressed in terms of transversal and longitudinal DDF states. We outline
novel directions for future work.

</details>


### [108] [A New Action for Superstring Field Theory](https://arxiv.org/abs/2508.03902)
*Chris Hull*

Main category: hep-th

TL;DR: The paper presents a background-independent reformulation of Sen's superstring field theory, introducing a new action that addresses the unique features of Sen's theory, including symmetry issues and the presence of two superstring fields. The new action ensures background independence and diffeomorphism invariance, providing a more consistent framework for understanding the symmetries involved.


<details>
  <summary>Details</summary>
Motivation: The paper aims to address the challenges faced by Sen's superstring field theory, particularly its lack of background independence and unique symmetries, seeking a more robust theoretical framework for superstring interactions.

Method: The authors likely introduced a new action functional that incorporates a shift symmetry to achieve background independence. This action modifies the original Sen's action by including terms that introduce self-interactions for the second superstring, ensuring physical amplitudes match those of Sen's theory while restoring proper symmetries.

Result: A new background-independent action is proposed that resolves the symmetry issues in Sen's theory, allowing for both superstrings to maintain diffeomorphism invariance. The effective action for the two gravitons demonstrates background independence and diffeomorphism symmetry, explaining the origin of additional symmetries within the framework.

Conclusion: The paper contributes a refined version of superstring field theory that overcomes previous limitations, providing a clearer understanding of the symmetries and interactions within the theory, which could lead to further advancements in string theory applications and interpretations.

Abstract: Sen's superstring field theory successfully formulates perturbative
superstring theory but has a number of unusual features. The action is not
background independent and the resulting effective field theory does not appear
to have standard diffeomorphsim symmetry - instead there is an exotic gauge
symmetry that acts on some fields but not others. A new action is found that
reduces to Sen's action in a certain limit and gives the same results as Sen's
theory for physical superstring amplitudes. However, the new theory is
background independent: there is a shift symmetry so that a change in the
background can be compensated for by a corresponding shift in the string
fields. Sen's theory has two string fields leading to the physical interacting
superstring plus a free superstring that decouples from the physical
superstring. The new terms in the action give self-interactions to the second
superstring which remains decoupled from the physical superstring. The two
superstrings each have a graviton and the effective action for the two
gravitons coupled to a background metric is studied and shown to be background
independent and diffeomorphism invariant, and the origin of further
diffeomorphism-like symmetries is explained.

</details>


### [109] [D-ideal of generic mass banana integrals in dimensional regularization](https://arxiv.org/abs/2508.04309)
*Wojciech Flieger*

Main category: hep-th

TL;DR: 研究论文提出了ℓ+3个简单微分算子，证明它们可以消除ℓ环一般质量香蕉图积分，并通过Macaulay矩阵法计算了直至ℓ=8时的霍尔尼卡秩，结果与预期一致。


<details>
  <summary>Details</summary>
Motivation: 研究高质量微分算子及其对物理积分的影响，有助于简化量子场论中的复杂计算，提升研究效率。

Method: 引入ℓ+3个微分算子，证明其消元作用，应用Macaulay矩阵法计算霍尔尼卡秩。

Result: 发现霍尔尼卡秩为2^{ℓ+1}-1，这与已知结果一致，验证了算子的有效性。

Conclusion: 得出结论，这些算子确实能生成消除目标积分的消元理想。

Abstract: We present a set of $\ell + 3$ simple differential operators and prove that
they annihilate an $\ell$-loop generic mass banana integral in dimensional
regularization. We study the singular locus of the ideal generated by these
operators and show that it is contained in the set of Landau singularities of
the first and second type. Through the Macaulay matrix method, we calculate the
corresponding holonomic rank up to $\ell = 8$, obtaining $2^{\ell +1}-1$, which
agrees with the number of master integrals for the generic mass banana
integrals. Based on these findings, we conjecture that the proposed operators
generate the annihilating ideal for the generic mass banana integrals in
dimensional regularization.

</details>


### [110] [Singularity-Free Feynman Integral Bases](https://arxiv.org/abs/2508.04394)
*Stefano De Angelis,David A. Kosower,Rourou Ma,Zihao Wu,Yang Zhang*

Main category: hep-th

TL;DR: 该论文提出了两种算法以消除积分积分-部分（IBP）约化中的ε奇异性，从而更清楚地揭示散射幅度的结构。


<details>
  <summary>Details</summary>
Motivation: 作者希望简化计算并更清楚地理解散射幅度的结构。

Method: 提出了基于D=4 IBP和高斯消元的两个算法。

Result: 两种算法应用于双环积分族，简化了散射幅度的表示。

Conclusion: 提出了两种算法以消除IBP约化的奇异性，促进了高效计算。

Abstract: Standard integration-by-parts (IBP) reduction methods typically yield Feynman
integral bases where the reduction of some integrals gives rise to coefficients
singular as the dimensional regulator $\epsilon\rightarrow 0$. These singular
coefficients can also appear in scattering amplitudes, obscuring their
structure, and rendering their evaluation more complicated. We investigate the
use of bases in which the reduction of any integral is free of singular
coefficients. We present two general algorithms for constructing such bases.
The first is based on sequential $D=4$ IBP reduction. It constructs a basis
iteratively by projecting onto the finite part of the set of IBP relations. The
second algorithm performs Gaussian elimination within a local ring forbidding
division by $\epsilon$ while permitting division by polynomials in $\epsilon$
finite at $\epsilon=0$. We study the application of both algorithms to a pair
of two-loop examples, the planar and nonplanar double-box families of
integrals. We also explore the incorporation of finite Feynman integrals into
these bases. In one example, the resulting basis provides a simpler and more
compact representation of a scattering amplitude.

</details>


### [111] [Covariant quantization of field theories on T-Minkowski noncommutative spacetimes](https://arxiv.org/abs/2508.04527)
*Giuseppe Fabiano,Flavio Mercati*

Main category: hep-th

TL;DR: The paper discusses quantum field theory on non-commutative spacetimes called T-Minkowski. It finds that for a specific subclass, the theory remains covariant and standard results like Wightmann functions and Green's functions behave as expected, without typical non-commutative issues like IR/UV mixing.


<details>
  <summary>Details</summary>
Motivation: Non-commutative spacetimes are explored in quantum field theory, and this paper evaluates a particular structure, T-Minkowski, to understand the implications of such spacetime models on quantum theory.

Method: The authors use mathematical analysis to define quantization schemes ensuring covariance under T-Poincaré transformations. They apply the Wightmann axioms and prove a Wick theorem, extending these to Green and N-point functions to rule out non-standard mixing effects.

Result: For selected T-Minkowski spacetime models, the results align with commutative QFT, showing no IR/UV mixing and preserving standard quantum field theory properties despite non-commutative spacetime structures.

Conclusion: This study suggests that certain non-commutative spacetime models do not introduce unexpected quantum effects, supporting the viability of such spacetimes in quantum field theory.

Abstract: We develop a quantization scheme for the quantum theory of a real scalar
field on a class of non-commutative spacetime models collectively known as
T-Minkowski. Requiring the theory to be covariant under T-Poincar\'e
transformations, we find that for a subclass of models the Wightmann functions
are equal to their commutative counterparts, and we are able to prove a Wick
theorem for Wightmann functions that is structurally equivalent to the one
encountered in commutative QFT. For some of these models we further extend the
result to Green functions and to N-point functions of interacting QFT, which we
also find to be commutative, leaving no space for IR/UV mixing effects
advocated in other approaches to noncommutative QFT.

</details>


### [112] [Perturbations of Black Holes in Einstein-Maxwell-Dilaton-Axion (EMDA) Theories](https://arxiv.org/abs/2508.04589)
*C. N. Pope,D. O. Rohrer,B. F. Whiting*

Main category: hep-th

TL;DR: The paper extends previous work on black hole perturbations in EMD theories to include an axion, finding mode stability when b=1 and potential instabilities for larger b values through a transformation linking axial and polar perturbations.


<details>
  <summary>Details</summary>
Motivation: Analyzing black hole perturbations helps understand their stability and potential instabilities which are crucial for testing theories of gravity and quantum mechanics.

Method: Mathematical analysis of linear perturbations in EMDA theories with an axion field, establishing when the perturbations are stable based on parameter b.

Result: Only when $b=1$ is the theory supported by supersymmetry and mode stability; larger b may lead to instability challenges.

Conclusion: The perturbation analysis shows the importance of the parameter b in determining stability, particularly through a Chandrasekhar-like transformation.

Abstract: We extend our earlier work on the linearised perturbations of static black
holes in Einstein-Maxwell-Dilaton (EMD) theories to the case where the black
holes are solutions in an enlarged theory including also an axion. We study the
perturbations in a 3-parameter family of such EMDA theories. %The analysis is
more involved now, because of the %couplings of the gravitational and
electromagnetic modes %to both the dilaton and axion fields. The systems of
equations describing the linearised perturbations can always be separated, but
they can only be decoupled when the three parameters are restricted to a
1-parameter family of EMDA theories, characterised by a parameter $b$ that
determines the coupling of the axion to the $\epsilon^{\mu\nu\rho\sigma}\,
F_{\mu\nu}\, F_{\rho\sigma}$ term. In the specific case when $b=1$, the theory
is related to an ${\cal N}=2$ supergravity. In this one case we find that the
perturbations in the axial and the polar sectors are related by a remarkable
transformation, which generalises one found by Chandrasekhar for the
perturbations of Reissner-Nordstr\"om in Einstein-Maxwell theory. This
transformation is of a form found in supersymmetric quantum mechanical models.
The existence of such mappings between the axial and polar perturbations
appears to correlate with those cases where there is an underlying supergravity
supporting the solution, even though the black hole backgrounds are
non-extremal and therefore not supersymmetric. We prove the mode stability of
the static black hole solutions in the supersymmetric EMDA theory. For other
values of the parameter $b$ in the EMDA theories that allow decoupling of the
modes, we find that one of the radial potentials can be negative outside the
horizon if $b$ is sufficiently large, raising the possibility of there being
perturbative mode instabilities in such a case.

</details>


<div id='physics.atom-ph'></div>

# physics.atom-ph [[Back]](#toc)

### [113] [Compact and robust optical frequency reference module based on reproducible and redistributable optical design](https://arxiv.org/abs/2508.04103)
*Jiwon Wi,Taehee Kim,Junki Kim*

Main category: physics.atom-ph

TL;DR: 摘要介绍了一个19英寸的模块化光频率参考系统模块，通过网页设计流程易于复制和再现，并确保了高稳定性与抗振动性能。


<details>
  <summary>Details</summary>
Motivation: 该模块化系统旨在提高原子光子学、通信和精密测量领域的设备效率和可靠性，特别是微型化和易于维护方面。

Method: 该模块使用了网页设计流程并通过建模激光路径精确放置光学元件，确保了高精度和稳定性。此外，该系统能长期稳定运行并抗性强振动，且提供了公开设计文件以便于复制和调整。

Result: 主要成果包括模块化设计、高精度光学系统以及抗干扰能力强的性能，结果被广泛应用于相关领域。

Conclusion: 该系统显著提升了光频率参考系统的可用性和可靠性，特别是在模块化和抗干扰方面。该系统可作为参考和进一步改进的基础。

Abstract: Stabilized optical frequency references (OFRs) are indispensable for
atom-based quantum technologies, optical communications, and precision
metrology. As these systems become more sophisticated, demands for compactness,
robustness, and straightforward reproduction have grown. In this work, we
present a robust 19-inch rack-mountable OFR module designed via a web-based CAD
workflow that allows straightforward redistribution and reproduction. Its
optical subsystem, designed based on a modeled laser beam path, places optical
elements with sub-millimeter accuracy on a custom-machined aluminum plate,
allowing straightforward assembly without extensive alignment and providing
high mechanical stability. The module maintains frequency-stable operation for
several months without user intervention and exhibits high robustness to
mechanical vibrations up to 4g. All design files, including mechanical and
optical metadata, are openly shared for straightforward reproduction and
adaptation.

</details>


### [114] [Analyzing the optical pumping on the $5s4d\,{}^1D_2-5s8p\,{}^1P_1$ transition in a magneto-optical trap of Sr atoms](https://arxiv.org/abs/2508.04109)
*Naohiro Okamoto,Takatoshi Aoki,Yoshio Torii*

Main category: physics.atom-ph

TL;DR: The paper investigates optimizing the optical pumping efficiency in a magneto-optical trap (MOT) for strontium atoms by selecting a specific transition, achieving a 12-fold increase in trapped atoms compared to a previous method. The study identifies decay pathways leading to atom loss and measures their rates. Additionally, they discover that a narrow MOT beam size enhances losses but show that 448 nm pumping minimizes this issue.


<details>
  <summary>Details</summary>
Motivation: Laser cooling and trapping of atoms, particularly rare gas isotopes like strontium, are crucial for quantum computing and precision metrology. Enhancing pump efficiency in MOTs would improve these technologies.

Method: The authors used a magneto-optical trap with strontium atoms, analyzing the 5s4d⁠¹D₂-5s8p⁠¹P₁ transition pumped at 448 nm. They measured the number of trapped atoms, identified decay pathways, and determined their rates using intensity mapping and single-atom fluorescence detection.

Result: Pumping at 448 nm leads to 12 times more trapped atoms due to decay pathways involving 5s5p states. The decay rates of these pathways are measured, and the trapping method shows resilience against atom loss, aiding in applications like quantum computing.

Conclusion: The research demonstrates an efficient method to enhance atom trapping in MOTs by optimizing the pumping transition and understanding decay mechanisms, promising advancements in laser cooling and fluorescence microscopy.

Abstract: We explore the efficacy of optical pumping on the $5s4d\,{}^1D_2 -
5s8p\,{}^1P_1$ ($448\,\mathrm{nm}$) transition in a magneto-optical trap (MOT)
of Sr atoms. The number of trapped atoms is enhanced by a factor of $12.0(6)$,
which is six times as large as that obtained using the pumping transition
$5s4d\,{}^1D_2 - 5s6p\,{}^1P_1$ ($717\,\mathrm{nm}$). This enhancement is
limited by decay pathways that bypass the $5s4d\,{}^1D_2$ state, namely
$5s5p\,{}^1P_1 \to 5s4d\,{}^3D_1 \to 5s5p\,{}^3P_0$ and $5s5p\,{}^1P_1 \to
5s4d\,{}^3D_2 \to 5s5p\,{}^3P_2$, which account for 8\% of the total loss of
the trapped atoms. We determine the decay rates for the $5s5p\,{}^1P_1 \to
5s4d\,{}^3D_1$ and $5s5p\,{}^1P_1 \to 5s4d\,{}^3D_2$ transitions to be
$66(6)\,\mathrm{s^{-1}}$ and $2.4(2)\times10^2\,\mathrm{s^{-1}}$, respectively.
Furthermore, we experimentally demonstrate for the first time that, when the
trap beam diameter is small, escape of atoms in the $5s4d\,{}^1D_2$ state,
which has a relatively long lifetime of $400\,\mathrm{\mu s}$, becomes a
dominant loss mechanism, and that the $448\,\mathrm{nm}$ pumping light
effectively suppresses this escape. Our findings will contribute to improved
laser cooling and fluorescence imaging in cold strontium atom platforms, such
as quantum computers based on optical tweezer arrays.

</details>


### [115] [Precision calculation of the bound-electron $g$ factor in molecular hydrogen ions](https://arxiv.org/abs/2508.04242)
*Ossama Kullie,Hugo D. Nogueira,Jean-Philippe Karr*

Main category: physics.atom-ph

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: We calculate the bound-electron $g$ factor for a wide range of rovibrational
states of the molecular hydrogen ions H$_2^+$ and HD$^+$. Relativistic and QED
corrections of orders up to $\alpha^5$ are taken into account. All
contributions are calculated in a nonrelativistic QED framework, except for
relativistic corrections of order $(Z\alpha)^4$ and above, which are obtained
by calculating the relativistic $g$ factor using a precise minmax finite
element solution of the two-center Dirac equation. A relative accuracy of $4-5
\times 10^{-11}$ is achieved for the scalar $g$ factor component, which
represents an improvement by more than three orders of magnitude over previous
calculations. These results are useful for internal state identification and
rovibraional spectroscopy of single molecular hydrogen ions in Penning traps,
and open a new avenue towards precision tests of QED.

</details>
